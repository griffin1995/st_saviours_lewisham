TITLE: Full NGINX Plus Configuration for Nested JWT Extraction
DESCRIPTION: This complete NGINX Plus server block demonstrates the full setup for handling Nested JWTs. It configures NGINX Plus to decrypt the JWE, verify the enclosed JWS, and then forward the decrypted payload to an upstream API server, offloading cryptographic operations from the application.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-jwt-authentication.md#_snippet_17

LANGUAGE: nginx
CODE:
```
upstream api_server {
    server 10.0.0.1;
    server 10.0.0.2;
}

http {
    server {
        listen 80;

        auth_jwt          "API";
        auth_jwt_type     nested;
        auth_jwt_key_file conf/api_secret.jwk;

        proxy_pass       http://api_server;
        proxy_set_header Authorization "Bearer $jwt_payload";
    }
}
```

----------------------------------------

TITLE: Proxy HTTP Requests to NGINX Upstream Group
DESCRIPTION: This `server` block configures a virtual server in NGINX. The `location /` directive captures all incoming requests, and the `proxy_pass http://backend;` directive forwards these requests to the `backend` upstream group defined elsewhere. This sets up the basic mechanism for load balancing traffic to the specified group of servers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-load-balancer.md#_snippet_1

LANGUAGE: nginx
CODE:
```
server {
    location / {
        proxy_pass http://backend;
    }
}
```

----------------------------------------

TITLE: NGINX: Configure DNS Resolution for Dynamic Upstream Servers
DESCRIPTION: To enable dynamic reconfiguration of upstream servers using DNS, add the `resolver` directive in the `http` block pointing to your DNS server. Then, include the `resolve` parameter in the `server` directive within the `upstream` block to instruct NGINX Plus to periodically re-resolve the domain name.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_36

LANGUAGE: nginx
CODE:
```
# In the 'http' block
resolver <IP-address-of-DNS-server>;

upstream nodejs {
    zone nodejs 64k;
    server example.com resolve;
}
```

----------------------------------------

TITLE: Defining NGINX Cache Path and Zone
DESCRIPTION: This snippet defines the `proxy_cache_path` directive within the `http` context. It specifies `/data/nginx/cache` as the local filesystem path for cached content and `mycache:10m` for the `keys_zone`, which creates a 10MB shared memory zone named 'mycache' to store metadata about cached items. This is the foundational step to enable caching.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/content-cache/content-caching.md#_snippet_0

LANGUAGE: nginx
CODE:
```
http {
    # ...
    proxy_cache_path /data/nginx/cache keys_zone=mycache:10m;
}
```

----------------------------------------

TITLE: Apply Advanced Traffic Splitting with SMI TrafficSplit and HTTPRouteGroup
DESCRIPTION: This YAML configuration demonstrates how to implement advanced traffic splitting in NGINX Service Mesh using the SMI TrafficSplit and HTTPRouteGroup resources. It shows how to define matches within an HTTPRouteGroup (e.g., for /metrics path or x-test header) and associate them with a TrafficSplit to conditionally route traffic to different service backends based on request attributes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/guides/smi-traffic-policies.md#_snippet_0

LANGUAGE: YAML
CODE:
```
apiVersion: split.smi-spec.io/v1alpha3
kind: TrafficSplit
metadata:
  name: target
spec:
  service: target-svc
  backends:
  - service: target-v1
    weight: 0
  - service: target-v2
    weight: 1
  - service: target-v3
    weight: 0
  matches:
  - kind: HTTPRouteGroup
    name: target-route-group
---
 apiVersion: specs.smi-spec.io/v1alpha3
 kind: HTTPRouteGroup
 metadata:
   name: target-route-group
   namespace: default
 spec:
   matches:
   - name: metrics
     pathRegex: "/metrics"
     methods:
     - GET
  - name: test-header
    headers:
      x-test: "^true$"
```

----------------------------------------

TITLE: Configure NGINX Plus for SSL/TLS Termination
DESCRIPTION: This NGINX Plus configuration demonstrates how to terminate SSL/TLS connections at the NGINX load balancer, decrypting traffic before forwarding it to backend HTTP servers. It uses an upstream block to define backend servers and a server block to listen on HTTPS, handle SSL certificates, and proxy pass to the upstream pool.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/migrate-hardware-adc/f5-big-ip-configuration.md#_snippet_4

LANGUAGE: nginx
CODE:
```
upstream ssl_test_pool {
     server 10.10.10.10:443;
     server 10.10.10.20:443;
}

server {
     listen 192.168.10.10:443 ssl;
     ssl_certificate     /etc/nginx/ssl/test.crt;
     ssl_certificate_key /etc/nginx/ssl/test.key;

     location / {
         proxy_pass http://ssl_test_pool;
     }
}
```

----------------------------------------

TITLE: Configure NGINX SSL Certificate and Protocols
DESCRIPTION: Specifies the paths to the SSL certificate and private key files for the HTTPS server. It also disables less secure protocols, allowing only TLSv1.2 and TLSv1.3 for enhanced security. These directives belong in the HTTPS `server` block.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_34

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
ssl_certificate     /etc/nginx/ssl/company.com.crt;
ssl_certificate_key /etc/nginx/ssl/company.com.key;
ssl_protocols       TLSv1.2 TLSv1.3;
```

----------------------------------------

TITLE: Configure NGINX to Use Chained SSL Certificate
DESCRIPTION: This NGINX server block configuration shows how to specify the combined server and intermediate certificate file using the ssl_certificate directive. This ensures that NGINX sends the complete certificate chain to clients, preventing browser complaints.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/terminating-ssl-http.md#_snippet_8

LANGUAGE: nginx
CODE:
```
server {
    listen              443 ssl;
    server_name         www.example.com;
    ssl_certificate     www.example.com.chained.crt;
    ssl_certificate_key www.example.com.key;
    #...
}
```

----------------------------------------

TITLE: Deploying Primary NGINXaaS for Azure with Terraform HCL and Nginx Configuration
DESCRIPTION: This Terraform HCL snippet defines the deployment of a primary NGINXaaS instance in Azure, including its network interface configuration. It also embeds the Nginx configuration that sets up the NGINXaaS service to listen on port 80, reverse proxy requests to a set of backend servers, and includes a health check endpoint for traffic management.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/disaster-recovery.md#_snippet_6

LANGUAGE: HCL
CODE:
```
resource "azurerm_nginx_deployment" "primary_nginxaas_deployment" {
  name                = var.primary_deployment_name
  resource_group_name = var.primary_resource_group
  location            = "eastus"
  # ...
  network_interface {
    subnet_id = azurerm_subnet.primary_subnet_1.id
  }
}

resource "azurerm_nginx_configuration" "primary_nginxaas_config" {
  nginx_deployment_id = azurerm_nginx_deployment.primary_nginxaas_deployment.id
  root_file           = "/etc/nginx/nginx.conf"

  config_file {
    content = base64encode(<<-EOT
user nginx;
worker_processes auto;
worker_rlimit_nofile 8192;
pid /run/nginx/nginx.pid;

events {
    worker_connections 4000;
}

error_log /var/log/nginx/error.log error;

http {
    upstream backend_servers {
        server <Upstream-1-private-ip>:80;
        server <Upstream-2-private-ip>:80;
        keepalive 16;
    }
    server {
        listen 80 default_server;
        # /health will be used for Azure Traffic Manager Profile
        location /health {
            return 200 'nginx proxy alive';
        }
        location / {
            proxy_pass http://backend_servers;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_next_upstream error timeout http_500;
            proxy_http_version 1.1;
            proxy_set_header   "Connection" "";
        }
    }
}
EOT
    )
    virtual_path = "/etc/nginx/nginx.conf"
  }
}
```

LANGUAGE: Nginx Conf
CODE:
```
user nginx;
worker_processes auto;
worker_rlimit_nofile 8192;
pid /run/nginx/nginx.pid;

events {
    worker_connections 4000;
}

error_log /var/log/nginx/error.log error;

http {
    upstream backend_servers {
        server <Upstream-1-private-ip>:80;
        server <Upstream-2-private-ip>:80;
        keepalive 16;
    }
    server {
        listen 80 default_server;
        # /health will be used for Azure Traffic Manager Profile
        location /health {
            return 200 'nginx proxy alive';
        }
        location / {
            proxy_pass http://backend_servers;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_next_upstream error timeout http_500;
            proxy_http_version 1.1;
            proxy_set_header   "Connection" "";
        }
    }
}
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: This command reloads the NGINX configuration file, applying any changes without stopping the NGINX service. It's a standard way to update NGINX settings after modifications.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/keycloak.md#_snippet_10

LANGUAGE: bash
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Test and Reload NGINX Plus Configuration
DESCRIPTION: After making configuration changes, it is crucial to test the NGINX configuration for syntax errors and then reload NGINX Plus to apply the changes without service interruption.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/monitoring/live-activity-monitoring.md#_snippet_5

LANGUAGE: shell
CODE:
```
sudo nginx -t && sudo nginx -s reload
```

----------------------------------------

TITLE: Configure NGINX Virtual Server to Redirect HTTP to HTTPS
DESCRIPTION: This NGINX server block listens on port 80 for HTTP requests to 'example.com'. It contains a location block that issues a permanent (301) redirect to the corresponding HTTPS URL, ensuring all traffic is secured.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_13

LANGUAGE: nginx
CODE:
```
# In the 'http' block
server {
    listen 80;
    server_name example.com;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}
```

----------------------------------------

TITLE: NGINX TCP and UDP Load Balancing Configuration
DESCRIPTION: This NGINX configuration demonstrates how to set up load balancing for both TCP and UDP traffic within the `stream` module. It defines two `upstream` blocks for different backend groups (`stream_backend` for TCP and `dns_servers` for UDP) and three `server` blocks to handle incoming connections on various ports, applying `least_conn` and other proxy settings for efficient traffic distribution and timeout management.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/tcp-udp-load-balancer.md#_snippet_24

LANGUAGE: nginx
CODE:
```
stream {
    upstream stream_backend {
        least_conn;
        server backend1.example.com:12345 weight=5;
        server backend2.example.com:12345 max_fails=2 fail_timeout=30s;
        server backend3.example.com:12345 max_conns=3;
    }

    upstream dns_servers {
        least_conn;
        server 192.168.136.130:53;
        server 192.168.136.131:53;
        server 192.168.136.132:53;
    }

    server {
        listen        12345;
        proxy_pass    stream_backend;
        proxy_timeout 3s;
        proxy_connect_timeout 1s;
    }

    server {
        listen     53 udp;
        proxy_pass dns_servers;
    }

    server {
        listen     12346;
        proxy_pass backend4.example.com:12346;
    }
}
```

----------------------------------------

TITLE: Test NGINX Plus configuration syntax
DESCRIPTION: This command checks the syntax of the NGINX Plus configuration file (`nginx.conf`) for errors and validates its overall structure before applying changes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/image-filter.md#_snippet_7

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: NGINX Basic Load Balancing Configuration with HTTP/HTTPS and WebSocket
DESCRIPTION: This NGINX configuration snippet demonstrates a basic load balancing setup for Wildfly application servers. It includes a proxy cache path definition, a map for WebSocket upgrades, an upstream group with IP hash for session persistence, HTTP to HTTPS redirection, and specific locations for web application and WebSocket proxying.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_27

LANGUAGE: nginx
CODE:
```
proxy_cache_path /tmp/NGINX_cache/ keys_zone=backcache:10m;

map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

upstream jboss {
    # Use IP Hash for session persistence
    ip_hash;

    # List of Wildfly application servers
    server 192.168.33.11:8080;
    server 192.168.33.12:8080;
}

server {
    listen 80;
    server_name example.com;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}

server {
    listen 443 ssl;
    http2  on;

    server_name example.com;

    ssl_certificate     /etc/nginx/ssl/<certificate-name>;
    ssl_certificate_key /etc/nginx/ssl/<private-key>;
    ssl_session_cache   shared:SSL:1m;
    ssl_prefer_server_ciphers on;

    # Load balance requests for '/webapp/' across Wildfly application servers
    location /webapp/ {
        proxy_pass http://jboss;
        proxy_cache backcache;
    }

    # Return a temporary redirect to '/webapp/' when user requests '/'
    location = / {
        return 302 /webapp/;
    }

    # WebSocket configuration
    location /wstunnel/ {
        proxy_pass https://jboss;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }
}
```

----------------------------------------

TITLE: NGINX Configuration for Dual Web Entry Points with Oracle EBS
DESCRIPTION: This comprehensive NGINX configuration sets up two distinct web entry points, `oracle-one.company.com` and `oracle-two.company.com`, each serving Oracle EBS applications. It includes global settings, proxy cache paths, custom logging, upstream definitions for production and disaster recovery EBS servers with session persistence, HTTP to HTTPS redirection, SSL/TLS configuration, and health checks. It also enables live activity monitoring.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_42

LANGUAGE: nginx
CODE:
```
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log info;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type text/html;
    proxy_cache_path /var/oracle-cache-one
                     keys_zone=cache_oracle_one:50m max_size=500m;
    proxy_cache_path /var/oracle-cache-two
                     keys_zone=cache_oracle_two:50m max_size=500m;

    # Custom logging configuration
    log_format main '$remote_addr - $remote_user [$time_local]
                    "$request" $status $body_bytes_sent "$http_referer"
                    "$http_user_agent" $upstream_addr';
    access_log /var/log/nginx/access.log main;

    upstream oracle_one {
        zone oracle_one 64k;

        # Production servers
        server 172.31.11.210:8000 max_fails=0;
        server 172.31.0.146:8000 max_fails=0;

        # Disaster recovery servers
        server 172.33.111.210:8000 max_fails=0 backup;
        server 172.33.100.146:8000 max_fails=0 backup;

        # Session persistence
        sticky cookie ngxcookie;
    }

    upstream oracle_two {
        zone oracle_two 64k;

        # Production servers
        server 172.31.11.211:8000 max_fails=0;
        server 172.31.0.147:8000 max_fails=0;

        # Disaster recovery servers
        server 172.33.111.211:8000 max_fails=0 backup;
        server 172.33.100.147:8000 max_fails=0 backup;

        # Session persistence
        sticky cookie ngxcookie;
    }

    server {
        listen 80;
        status_zone oracle-http-redirect;
        return 302 https://$http_host$request_uri;
    }

    server {
        listen 192.168.210.10:443 ssl;
        http2  on;
        server_name oracle-one.company.com;
        ssl_certificate     /etc/nginx/ssl/server_one.crt;
        ssl_certificate_key /etc/nginx/ssl/server_one.key;
        ssl_protocols       TLSv1.2;
        status_zone oracle-ssl-one;
        proxy_cache cache_oracle_one;

        location / {
            proxy_pass http://oracle_one;
            proxy_set_header Host $host;
            proxy_cache_valid any 1h;
        }

        location @health_check {
            internal;
            proxy_connect_timeout 3s;
            proxy_read_timeout 3s;
            proxy_pass http://oracle_one;
            proxy_set_header Host "oracle-one.company.com";
            health_check match=oracleok interval=4s
                         uri=/OA_HTML/AppsLocalLogin.jsp;
        }
    }

    server {
        listen 192.168.210.11:443 ssl;
        http2  on;
        server_name oracle-two.company.com;
        ssl_certificate     /etc/nginx/ssl/server_two.crt;
        ssl_certificate_key /etc/nginx/ssl/server_two.key;
        ssl_protocols       TLSv1.2;
        status_zone oracle-ssl-two;
        proxy_cache cache_oracle_two;

        location / {
            proxy_pass http://oracle_two;
            proxy_set_header Host $host;
            proxy_cache_valid any 1h;
        }

        location @health_check {
            internal;
            proxy_connect_timeout 3s;
            proxy_read_timeout 3s;
            proxy_pass http://oracle_two;
            proxy_set_header Host "oracle-two.company.com";
            health_check match=oracleok interval=4s
                         uri=/OA_HTML/AppsLocalLogin.jsp;
        }
    }

    match oracleok {
        status 200-399;
        header X-ORACLE-DMS-ECID;
    }

    # Live activity monitoring configuration
    server {
        # Status zone required for live activity monitoring. Enable it for
        # every 'server' block in other configuration files.
        status_zone status-page;

        # If NGINX Plus is listening on multiple IP addresses, uncomment this
        # directive to restrict access to the live activity monitoring
        # dashboard to a single IP address (substitute the appropriate
        # address).
        # listen 10.2.3.4:8080;
        # Live activity monitoring is enabled on port 8080 by default.
        listen 8080;

        # HTTP Basic authentication is enabled by default. Use an htpasswd
```

----------------------------------------

TITLE: Test NGINX Configuration Syntax
DESCRIPTION: This snippet demonstrates how to use the `nginx -t` command to test the syntax of the NGINX configuration file. A successful test indicates that the configuration is syntactically valid and ready for deployment.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_10

LANGUAGE: Shell
CODE:
```
root# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: Execute the `nginx -s reload` command to apply the new configuration changes to NGINX Plus without stopping the service, ensuring continuous operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/spnego.md#_snippet_4

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Test NGINX Plus Configuration Syntax
DESCRIPTION: Command to verify the syntax of the NGINX Plus configuration file before reloading the service.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/set-misc.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Tuning NGINX Listen Directive Backlog
DESCRIPTION: This NGINX configuration snippet shows how to set the `backlog` parameter of the `listen` directive to match the increased `somaxconn` kernel parameter. This allows NGINX to utilize the operating system's larger connection queue, preventing connection drops under heavy load.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/serving-static-content.md#_snippet_16

LANGUAGE: nginx
CODE:
```
server {
    listen 80 backlog=4096;
    # ...
}
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: Run the `nginx -s reload` command to apply changes to the NGINX Plus configuration, enabling newly configured modules like NDK without service interruption.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/ndk.md#_snippet_3

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: NGINX Configuration for WebSocket Proxying
DESCRIPTION: This NGINX configuration demonstrates how to correctly proxy WebSocket traffic. It includes a `map` block to dynamically set the `Connection` header based on the presence of an `Upgrade` header, and a `location` block that sets `proxy_http_version` to 1.1 and explicitly forwards the `Upgrade` and `Connection` headers, which are crucial for WebSocket handshake and persistent communication.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_18

LANGUAGE: nginx
CODE:
```
# In the 'http' block
map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

# In the 'server' block for HTTPS traffic
location /wstunnel/ {
    proxy_pass http://tomcat;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;
}
```

----------------------------------------

TITLE: Test NGINX Configuration Syntax
DESCRIPTION: Command to test the syntactic validity of the NGINX configuration file. Running `nginx -t` helps identify errors before reloading, ensuring a stable server operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_6

LANGUAGE: none
CODE:
```
root# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

----------------------------------------

TITLE: Test NGINX Configuration Syntax
DESCRIPTION: Command to test the syntactic validity of the NGINX configuration file before applying changes, ensuring no errors are present.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_10

LANGUAGE: none
CODE:
```
root# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

----------------------------------------

TITLE: Test NGINX Configuration Syntax
DESCRIPTION: Command to test the syntax of the NGINX Plus configuration file for errors before reloading.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/headers-more.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Build NGINX Plus and App Protect Docker Image
DESCRIPTION: This Dockerfile defines the steps to create a Docker image containing NGINX Plus and the NGINX App Protect WAF module. It uses `amazonlinux:2` as the base image and leverages Docker build secrets (`nginx-crt`, `nginx-key`) to securely access the NGINX Plus repositories. The build process installs required packages, configures yum repositories for NGINX Plus and App Protect, installs the `app-protect-module-plus`, and sets up logging to stdout/stderr. Finally, it exposes port 80 and defines the default command to run NGINX in the foreground.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/v5/build-nginx-image-plus/build-amazon.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Base image
FROM amazonlinux:2

# Install NGINX Plus and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    amazon-linux-extras enable epel \
    && yum clean metadata \
    && yum -y install wget ca-certificates epel-release shadow-utils \
    && wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/nginx-plus-amazon2.repo \
    && echo "[app-protect-x-plus]" > /etc/yum.repos.d/app-protect-7-x-plus.repo \
    && echo "name=nginx-app-protect repo" >> /etc/yum.repos.d/app-protect-7-x-plus.repo \
    && echo "baseurl=https://pkgs.nginx.com/app-protect-x-plus/centos/7/\$basearch/" >> /etc/yum.repos.d/app-protect-7-x-plus.repo \
    && echo "sslclientcert=/etc/ssl/nginx/nginx-repo.crt" >> /etc/yum.repos.d/app-protect-7-x-plus.repo \
    && echo "sslclientkey=/etc/ssl/nginx/nginx-repo.key" >> /etc/yum.repos.d/app-protect-7-x-plus.repo \
    && echo "gpgcheck=0" >> /etc/yum.repos.d/app-protect-7-x-plus.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/app-protect-7-x-plus.repo \
    && yum -y install app-protect-module-plus \
    && yum clean all \
    && rm -rf /var/cache/yum \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: Nginx Unit JSON Configuration for Overwriting Protocol Scheme with X-Forwarded-Proto
DESCRIPTION: Demonstrates a JSON configuration for the 'forwarded' object in Nginx Unit, setting 'protocol' to 'X-Forwarded-Proto' and defining 'source' IP ranges. This configuration allows Unit to overwrite the incoming request's protocol scheme (e.g., from http to https) based on the specified header field from trusted sources.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/configuration.md#_snippet_21

LANGUAGE: json
CODE:
```
{
    "forwarded": {
        "protocol": "X-Forwarded-Proto",
        "source": [
            "192.0.2.0/24",
            "198.51.100.0/24"
        ]
    }
}
```

----------------------------------------

TITLE: OpenTelemetry (OTEL) Configuration Parameters Reference
DESCRIPTION: Detailed documentation for the OpenTelemetry (OTEL) configuration parameters within NGINX Unit's settings. This section describes each parameter's purpose, type, requirements, and valid values for configuring trace collection.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/news/2024/unit-1.34.0-released.md#_snippet_2

LANGUAGE: APIDOC
CODE:
```
telemetry:
  endpoint:
    description: The endpoint for the OpenTelemetry (OTEL) Collector. Required.
    type: URL (gRPC or HTTP)
  protocol:
    description: Determines the protocol used to communicate with the endpoint. Required.
    values: "http", "grpc"
  batch_size:
    description: Number of spans to cache before triggering a transaction with the configured endpoint. Optional.
    type: positive integer
  sampling_ratio:
    description: Percentage of requests to trace (0% to 100%). Optional.
    type: positive floating point number
```

----------------------------------------

TITLE: NGINX Unit Configuration for Symfony Application
DESCRIPTION: JSON configuration for NGINX Unit to serve a Symfony application, including listener setup, routing for PHP scripts and static assets, and defining application targets for direct script access and index-based routing.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/howto/frameworks/symfony.md#_snippet_1

LANGUAGE: json
CODE:
```
{
   "listeners": {
      "*:80": {
         "pass": "routes"
      }
   },
   "routes": [
      {
         "match": {
            "uri": [
               "*.php",
               "*.php/*"
            ],
            "uri_comment": "Handles all direct script-based requests"
         },
         "action": {
            "pass": "applications/symfony/direct"
         }
      },
      {
         "action": {
            "share": "/path/to/app/public$uri",
            "share_comment": "Serves static files",
            "fallback": {
               "pass": "applications/symfony/index",
               "pass_comment": "Uses the index.php at the root as the last resort"
            }
         }
      }
   ],
   "applications": {
      "symfony": {
         "type": "php",
         "targets": {
            "direct": {
               "root": "/path/to/app/public/",
               "root_comment": "Path to the application directory; use a real path in your configuration"
            },
            "index": {
               "root": "/path/to/app/public/",
               "root_comment": "Path to the application directory; use a real path in your configuration",
               "script": "index.php",
               "script_comment": "All requests are handled by a single script"
            }
         }
      }
   }
}
```

----------------------------------------

TITLE: Implement NGINX Plus Server Slow Start for Upstream Recovery
DESCRIPTION: This NGINX configuration snippet illustrates how to implement the `slow_start` feature for an upstream server, exclusive to NGINX Plus. The `slow_start` parameter ensures that a recently recovered server gradually receives traffic, preventing it from being overwhelmed and potentially failing again, allowing it to gracefully recover its weight.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-health-check.md#_snippet_1

LANGUAGE: nginx
CODE:
```
upstream backend {
    server backend1.example.com slow_start=30s;
    server backend2.example.com;
    server 192.0.0.1 backup;
}
```

----------------------------------------

TITLE: Configure NGINX Plus Health Check in Location Block
DESCRIPTION: This snippet demonstrates how to enable health checks for a specific application path within the NGINX `location` block. It configures NGINX Plus to send out-of-band requests to the /benefits URI every 5 seconds and uses a custom `match` parameter for health check tests.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_23

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
location /weblogic-app/ {
    proxy_pass http://weblogic;
    proxy_cache backcache;
    health_check uri=/benefits match=health_check;
}
```

----------------------------------------

TITLE: Deploy Sample Coffee Application (Deployment and Service)
DESCRIPTION: This shell command applies a multi-resource YAML manifest to Kubernetes. It defines a Deployment for a 'coffee' application with two replicas and a Service to expose it internally, making the application accessible within the cluster.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/monitoring/tracing.md#_snippet_10

LANGUAGE: shell
CODE:
```
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coffee
spec:
  replicas: 2
  selector:
    matchLabels:
      app: coffee
  template:
    metadata:
      labels:
        app: coffee
    spec:
      containers:
      - name: coffee
        image: nginxdemos/nginx-hello:plain-text
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: coffee
spec:
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  selector:
    app: coffee
EOF
```

----------------------------------------

TITLE: Verify NGINX Configuration Syntax
DESCRIPTION: Execute this command to check the NGINX configuration files for any syntax errors before applying the changes, ensuring a smooth reload.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/admin-guide/authentication/oidc/microsoft-entra-setup.md#_snippet_4

LANGUAGE: bash
CODE:
```
sudo nginx -t
```

----------------------------------------

TITLE: List Kubernetes Pods and Their Status
DESCRIPTION: This command shows the current status of pods in the Kubernetes cluster, demonstrating that `gateway`, `target-v2-1`, and `target-v3-0` pods are running after deployment.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/trafficsplit-deployments.md#_snippet_21

LANGUAGE: Bash
CODE:
```
$ kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
gateway-58c6c76dd-4mmht         2/2     Running   0          2m
target-v2-1-6f69fc48f6-mzcf2    2/2     Running   0          2m
target-v3-0-5f6fc9cf99-tps6k    2/2     Running   0          2m
```

----------------------------------------

TITLE: Full NGINX Configuration for JWT Authentication with Key Caching
DESCRIPTION: This comprehensive NGINX configuration demonstrates a complete setup for JWT authentication, including an upstream backend and key caching for optimal performance. It defines an `http` block with an `upstream` group for load balancing. The main `location` block enables JWT authentication, specifies both local and remote JWK sources, and activates `auth_jwt_key_cache` for a specified duration. An `internal` location is used to securely fetch JWKS keys via a subrequest.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/security-controls/jwt.md#_snippet_1

LANGUAGE: nginx
CODE:
```
http {
   upstream my_backend {
      server 10.0.0.1;
      server 10.0.0.2;
   }

   server {
      listen 80;

      location / {
         auth_jwt "API";
         auth_jwt_key_file conf/key.jwk;
         auth_jwt_key_request /_jwks_uri;
         auth_jwt_key_cache 1h;
         proxy_pass http://my_backend;
      }

      location = /_jwks_uri {
         internal;
         proxy_method GET;
         proxy_pass https://login.microsoftonline.com/common/discovery/keys;
         subrequest_output_buffer_size 12k;
      }
   }
}
```

----------------------------------------

TITLE: Configure NGINX Plus for Arbitrary JWT Claims Validation
DESCRIPTION: This NGINX Plus configuration demonstrates how to validate arbitrary JWT claims such as 'audience', 'issuer', and 'scope' using the 'map' module and 'auth_jwt_require' directive. It ensures that tokens are issued for specific applications, by trusted identity providers, and have required scopes before granting access to API endpoints.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-jwt-authentication.md#_snippet_13

LANGUAGE: nginx
CODE:
```
upstream api_server {
    server 10.0.0.1;
    server 10.0.0.2;
}

map $jwt_claim_aud $valid_app_id {    #map rule 1:
    "~api\d.example.com" 1;           #token issued only for target apps
}

map $jwt_claim_iss $valid_issuer {    #map rule 2:
    "https://idp.example.com/sts" 1;  #token issued by trusted CA
}

map $jwt_claim_scope $valid_scope {   #map rule 3:
    "access_as_admin" 1;              #access as admin only
}

server {
    listen 80;

    location /products/ {
        auth_jwt          "API";
        auth_jwt_key_file conf/api_secret.jwk;
        auth_jwt_require  $valid_app_id $valid_issuer $valid_scope;
        proxy_pass        http://api_server;
    }
}
```

----------------------------------------

TITLE: NGINX Dynamic Module Types Overview
DESCRIPTION: This section outlines the different categories of dynamically loadable modules available for NGINX Plus, detailing their descriptions, distribution methods, and NGINX support levels.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/installing-nginx/installing-nginx-plus.md#_snippet_22

LANGUAGE: APIDOC
CODE:
```
Type: NGINX-authored
  Description: Developed and distributed by NGINX
  Distribution Method: Packaged binaries from `nginx-plus` official repo
  F5 NGINX Support: Full support
Type: NGINX-certified Community
  Description: Tested and distributed by NGINX
  Distribution Method: Packaged binaries from `nginx-plus` official repo
  F5 NGINX Support: Installation and basic configuration support
Type: NGINX Certified Partner
  Description: Partner-built modules verified through NGINX’s certification
  Distribution Method: Provided by partners
  F5 NGINX Support: Provided by partners
Type: Community
  Description: Developed and distributed by third‑party contributors
  Distribution Method: Self-compiled
  F5 NGINX Support: No support
```

----------------------------------------

TITLE: Reloading NGINX Configuration via systemctl
DESCRIPTION: This command reloads the NGINX service, applying any changes made to its configuration file without interrupting active connections. It's essential to run this command after modifying the NGINX configuration to ensure the new settings take effect.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/licensing-and-reporting/configure-nginx-plus-report-to-nim.md#_snippet_1

LANGUAGE: bash
CODE:
```
systemctl reload nginx
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: This snippet reloads the NGINX Plus configuration, applying the newly added OWASP CRS rules without interrupting active connections. This ensures the WAF is updated with the latest security policies and protections.
SOURCE: https://github.com/nginx/documentation/blob/main/content/modsec-waf/admin-guide/nginx-plus-modsecurity-waf-owasp-crs.md#_snippet_4

LANGUAGE: none
CODE:
```
sudo nginx -s reload
```

----------------------------------------

TITLE: Test NGINX Configuration File Syntax
DESCRIPTION: This command tests the NGINX configuration file for syntactic validity. It helps identify errors before reloading the server, ensuring that new configurations will not break the NGINX service. The output indicates if the syntax is 'ok' and the test is 'successful'.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_6

LANGUAGE: none
CODE:
```
root# nginx -t
```

----------------------------------------

TITLE: Verify and Reload NGINX Configuration
DESCRIPTION: These commands are used to verify the syntax of the NGINX configuration files (`nginx -t`) and then gracefully reload the NGINX service (`nginx -s reload`) to apply any changes without downtime.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/amazon-web-services/route-53-global-server-load-balancing.md#_snippet_11

LANGUAGE: shell
CODE:
```
nginx -t
nginx -s reload
```

----------------------------------------

TITLE: Verify NGINX Configuration and Module Load
DESCRIPTION: Run this command to test the NGINX configuration file syntax and confirm that the ModSecurity module loads successfully, as indicated by the output.
SOURCE: https://github.com/nginx/documentation/blob/main/content/modsec-waf/admin-guide/nginx-plus-modsecurity-waf-installation-logging.md#_snippet_3

LANGUAGE: shell
CODE:
```
$ sudo nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

----------------------------------------

TITLE: Test NGINX Configuration Syntax
DESCRIPTION: Command to perform a syntax check on the NGINX Plus configuration file. This step is crucial to identify any errors before applying changes, preventing service disruptions.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/encrypted-session.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Enable Basic Active Health Checks in NGINX
DESCRIPTION: This NGINX configuration snippet enables basic active health checks for an upstream group named 'backend'. By default, NGINX Plus sends requests to '/' every five seconds, marking servers unhealthy if communication errors or non-2xx/3xx status codes occur. Unhealthy servers are temporarily removed from rotation until they pass a check.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-health-check.md#_snippet_2

LANGUAGE: nginx
CODE:
```
server {
    location / {
        proxy_pass http://backend;
        health_check;
    }
}
```

----------------------------------------

TITLE: Send Signals to NGINX Master Process
DESCRIPTION: Demonstrates how to send control signals to the NGINX master process using the `nginx` executable with the `-s` argument. Signals include `quit` (graceful shutdown), `reload` (configuration reload), `reopen` (reopen log files), and `stop` (immediate shutdown).
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/basic-functionality/runtime-control.md#_snippet_0

LANGUAGE: none
CODE:
```
nginx -s <SIGNAL>
```

----------------------------------------

TITLE: Redirect NGINX HTTP to HTTPS for example.com
DESCRIPTION: This NGINX configuration sets up a server block listening on port 80 to redirect all incoming HTTP requests for 'example.com' to their HTTPS equivalents. A 301 permanent redirect is used to ensure clients always use the secure connection.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_9

LANGUAGE: nginx
CODE:
```
# In the 'http' block
server {
    listen 80;
    server_name example.com;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}
```

----------------------------------------

TITLE: Verify SSL Certificate Chain Using OpenSSL s_client
DESCRIPTION: This openssl command connects to a specified host and port to retrieve and display its SSL certificate chain. It's useful for verifying that the server is sending the complete chain, including intermediate certificates, to clients.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/terminating-ssl-http.md#_snippet_10

LANGUAGE: shell
CODE:
```
openssl s_client -connect www.godaddy.com:443
...
Certificate chain
 0 s:/C=US/ST=Arizona/L=Scottsdale/1.3.6.1.4.1.311.60.2.1.3=US
     /1.3.6.1.4.1.311.60.2.1.2=AZ/O=GoDaddy.com, Inc
     /OU=MIS Department/CN=www.GoDaddy.com
     /serialNumber=0796928-7/2.5.4.15=V1.0, Clause 5.(b)
   i:/C=US/ST=Arizona/L=Scottsdale/O=GoDaddy.com, Inc.
     /OU=http://certificates.godaddy.com/repository
     /CN=Go Daddy Secure Certification Authority
     /serialNumber=07969287
 1 s:/C=US/ST=Arizona/L=Scottsdale/O=GoDaddy.com, Inc.
     /OU=http://certificates.godaddy.com/repository
     /CN=Go Daddy Secure Certification Authority
     /serialNumber=07969287
   i:/C=US/O=The Go Daddy Group, Inc.
     /OU=Go Daddy Class 2 Certification Authority
 2 s:/C=US/O=The Go Daddy Group, Inc.
     /OU=Go Daddy Class 2 Certification Authority
   i:/L=ValiCert Validation Network/O=ValiCert, Inc.
     /OU=ValiCert Class 2 Policy Validation Authority
     /CN=http://www.valicert.com//emailAddress=info@valicert.com
...
```

----------------------------------------

TITLE: Defining a Virtual Server in NGINX
DESCRIPTION: This snippet demonstrates the basic structure for defining a virtual server within the NGINX configuration. The `server` directive is placed inside the `http` context and acts as a container for server-specific configurations, such as listening ports and server names.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/web-server.md#_snippet_0

LANGUAGE: nginx
CODE:
```
http {
    server {
        # Server configuration
    }
}
```

----------------------------------------

TITLE: Identify Unsuccessful HTTP Response Codes with PromQL
DESCRIPTION: This PromQL query filters for HTTP responses with 3xx, 4xx, or 5xx status codes, indicating unsuccessful application responses. It can be extended for more complex queries like success rate.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/guides/prometheus-metrics.md#_snippet_1

LANGUAGE: PromQL
CODE:
```
nginxplus_upstream_server_responses{code=~"3xx|4xx|5xx"}
```

----------------------------------------

TITLE: Test NGINX Configuration File Syntax
DESCRIPTION: This command tests the NGINX configuration file for syntactic validity. Running `nginx -t` checks for errors and reports whether the configuration file is syntactically correct and the test is successful, helping to prevent issues before reloading NGINX.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_13

LANGUAGE: none
CODE:
```
root# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

----------------------------------------

TITLE: Validate and Reload NGINX Plus Service
DESCRIPTION: Execute these commands to perform a syntax check on the NGINX Plus configuration files and then gracefully reload the NGINX Plus service. This ensures that any new configurations are applied without interrupting active connections, maintaining service availability.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/google-cloud-platform/high-availability-all-active.md#_snippet_9

LANGUAGE: shell
CODE:
```
nginx -t
nginx -s reload
```

----------------------------------------

TITLE: Validate NGINX Configuration (Shell)
DESCRIPTION: This command validates the NGINX configuration files for syntax errors and ensures they are correctly structured before applying them. It's a crucial step to prevent service interruptions due to misconfigurations.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/admin-guide/authentication/oidc/getting-started.md#_snippet_0

LANGUAGE: Shell
CODE:
```
sudo nginx -t
```

----------------------------------------

TITLE: NGINX Directive: proxy_pass
DESCRIPTION: The `proxy_pass` directive sets the address of the proxied server. It can point to an upstream group or a specific URL.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_22

LANGUAGE: APIDOC
CODE:
```
Directive: proxy_pass
Context: location, if in location, limit_except
Purpose: Forwards requests to a proxied server or upstream group.
Usage: proxy_pass <url> | <upstream_name>;
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: Command to gracefully reload the NGINX Plus configuration, applying changes without interrupting active connections. This is used to enable newly configured modules or settings.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/rtmp.md#_snippet_3

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Configuring NGINX Server Names for Host Matching
DESCRIPTION: This example illustrates how to define exact server names using the `server_name` directive within a `server` block. NGINX uses these names to match the `Host` header of incoming HTTP requests, allowing it to route requests for specific domains (e.g., example.org, www.example.org) to the correct virtual server.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/web-server.md#_snippet_2

LANGUAGE: nginx
CODE:
```
server {
    listen      80;
    server_name example.org www.example.org;
    #...
}
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: These commands instruct NGINX Plus to reload its configuration, applying any changes made to the configuration files without stopping the NGINX process. This ensures continuous service availability while new settings take effect.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_23

LANGUAGE: none
CODE:
```
root# nginx -s reload
```

LANGUAGE: none
CODE:
```
root# service nginx reload
```

----------------------------------------

TITLE: Define NGINX Gateway Resource (YAML)
DESCRIPTION: This YAML manifest defines a Kubernetes Gateway resource, which is provisioned by NGINX Gateway Fabric. It sets up the entry point for external traffic to the cluster, specifying listeners and allowed routes for incoming connections.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/get-started.md#_snippet_8

LANGUAGE: yaml
CODE:
```
apiVersion: gateway.networking.k8s.io/v1beta1
kind: Gateway
metadata:
  name: gateway
spec:
  gatewayClassName: nginx
  listeners:
  - name: http
    protocol: HTTP
    port: 80
    allowedRoutes:
      namespaces:
        from: All
```

----------------------------------------

TITLE: Deploy HTTPRoute for Tea Services
DESCRIPTION: Defines and applies an HTTPRoute resource for the 'tea' and 'tea-post' services. It routes POST requests to '/tea' to 'tea-post-svc' and GET requests to '/tea' to 'tea-svc', reusing the existing 'cafe' gateway.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/advanced-routing.md#_snippet_8

LANGUAGE: yaml
CODE:
```
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: tea
spec:
  parentRefs:
  - name: cafe
  hostnames:
  - cafe.example.com
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /tea
      method: POST
    backendRefs:
    - name: tea-post-svc
      port: 80
  - matches:
    - path:
        type: PathPrefix
        value: /tea
      method: GET
    backendRefs:
    - name: tea-svc
      port: 80
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: This command is used to reload the NGINX configuration file after making changes. It applies the new configuration without stopping the NGINX service, ensuring continuous operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/okta.md#_snippet_8

LANGUAGE: nginx
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Test NGINX Plus Configuration Syntax
DESCRIPTION: Run the `nginx -t` command to check the syntax of the NGINX Plus configuration file for errors before reloading, ensuring a smooth application of changes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/spnego.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Configure NGINX Plus Backend Servers and Health Checks
DESCRIPTION: This NGINX configuration block defines an `upstream` group for backend servers and a `server` block. The `server` block includes a default location for proxying requests and a special `@healthcheck` location. The `@healthcheck` location configures NGINX Plus to perform active health checks on the backend servers, specifying the health check URI, interval, and proxy timeouts. Unhealthy servers are automatically removed from the load-balancing rotation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/amazon-web-services/route-53-global-server-load-balancing.md#_snippet_3

LANGUAGE: nginx
CODE:
```
upstream backend-servers {
    server <public DNS name of Backend 1>; # Backend 1
    server <public DNS name of Backend 2>; # Backend 2
    zone backend-servers 64k;
}

server {
    location / {
        proxy_pass http://backend-servers;
    }

    location @healthcheck {
        proxy_pass http://backend-servers;
        proxy_connect_timeout 1s;
        proxy_read_timeout 1s;
        health_check uri=/ interval=1s;
    }
}
```

----------------------------------------

TITLE: Testing NGINX Configuration Syntax
DESCRIPTION: This shell command is used to test the syntax of the NGINX Plus configuration file. Running `nginx -t` helps identify any errors or misconfigurations before reloading NGINX, ensuring service stability.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/opentelemetry.md#_snippet_16

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Testing NGINX Plus Configuration - Shell
DESCRIPTION: This command tests the syntax of the NGINX Plus configuration file and verifies its validity. It is crucial to run this command after making any changes to the configuration to ensure stability before reloading.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/uninstall.md#_snippet_5

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Test NGINX Plus Configuration Syntax
DESCRIPTION: Verify the syntax of the NGINX Plus configuration file using the `nginx -t` command. This command checks for errors and confirms successful parsing.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/passenger-open-source.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: NGINX: Reloading Configuration
DESCRIPTION: This command reloads the NGINX configuration without stopping the server, applying any changes made to the configuration files. It's a standard practice after modifying NGINX settings to ensure they take effect.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-oidc.md#_snippet_10

LANGUAGE: nginx
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: This Bash command reloads the NGINX configuration without stopping the service, applying any changes made to the NGINX configuration files. It is a standard and safe way to activate new settings after modifications.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/admin-guides/config-agent/configure-metrics-collection.md#_snippet_3

LANGUAGE: bash
CODE:
```
service nginx reload
```

----------------------------------------

TITLE: Reloading NGINX Configuration
DESCRIPTION: This shell command reloads the NGINX Plus configuration gracefully. It applies any changes made to the configuration file without stopping the NGINX service, ensuring continuous operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/opentelemetry.md#_snippet_18

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Resolve 413 Request Entity Too Large Error
DESCRIPTION: Explains the HTTP 413 error, which occurs when a client's request body exceeds the `client_max_body_size` limit configured in NGINX. It provides examples of the error as an HTML page and in NGINX logs, and directs users to configure `client_max_body_size` via the `ClientSettingsPolicy` API.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/troubleshooting.md#_snippet_18

LANGUAGE: html
CODE:
```
<html>
<head><title>413 Request Entity Too Large</title></head>
<body>
<center><h1>413 Request Entity Too Large</h1></center>
<hr><center>nginx/1.25.5</center>
</body>
</html>
```

LANGUAGE: text
CODE:
```
2024/05/30 21:48:22 [error] 138#138: *43 client intended to send too large body: 112 bytes, client: 127.0.0.1, server: cafe.example.com, request: "POST /coffee HTTP/1.1", host: "cafe.example.com:8080"
```

----------------------------------------

TITLE: Complete NGINX HTTP Load Balancing Configuration
DESCRIPTION: This combined NGINX configuration demonstrates a full setup for HTTP load balancing using the default Round Robin algorithm. It defines an `upstream` block named `backend` with two active servers and one backup server. A `server` block then proxies all incoming HTTP requests to this `backend` group, distributing traffic across the defined servers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-load-balancer.md#_snippet_2

LANGUAGE: nginx
CODE:
```
http {
    upstream backend {
        server backend1.example.com;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }

    server {
        location / {
            proxy_pass http://backend;
        }
    }
}
```

----------------------------------------

TITLE: Combine Multiple Match Types in NGINX Configuration
DESCRIPTION: This comprehensive JSON example demonstrates how to combine various NGINX matching types, including host, method, URI, arguments (AND logic), cookies (OR logic), and headers (mixed AND/OR logic). It illustrates complex conditional routing based on multiple request properties.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/configuration.md#_snippet_37

LANGUAGE: json
CODE:
```
{
    "match": {
        "host": "pattern",
        "method": "!pattern",
        "uri": [
            "pattern",
            "!pattern"
        ],

        "arguments": {
            "arg1": "pattern",
            "arg2": "!pattern"
        },

        "cookies": [
            {
                "cookie1": "pattern"
            },
            {
                "cookie2": "pattern"
            }
        ],

        "headers": [
            {
                "header1": "pattern"
            },
            {
                "header2": "pattern",
                "header3": "pattern"
            }
        ]
    },

    "action": {
    "pass": "...",
    "_comment_pass": "Any acceptable 'pass' value may go here; see the 'Listeners' section for details"
    }
}
```

----------------------------------------

TITLE: NGINX: Complete OIDC Integration Example
DESCRIPTION: This comprehensive NGINX configuration demonstrates a full OpenID Connect integration. It includes defining a DNS resolver, configuring an OIDC provider with issuer and client credentials, setting up SSL for the main server, protecting a location with OIDC, forwarding claims, and defining a simple backend application to receive these claims.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-oidc.md#_snippet_11

LANGUAGE: nginx
CODE:
```
http {
    # Use a public DNS resolver for Issuer discovery, etc.
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider my_idp {
        # The 'issuer' typically matches your IdP's base URL
        issuer https://<idp-server>/idp;

        # Provide a CA bundle for certificate validation
        ssl_trusted_certificate /etc/ssl/certs/ca-certificates.crt;

        # Replace with your actual IdP's client_id and secret
        client_id <client_id>;
        client_secret <client_secret>;

        # If the .well-known endpoint cannot be derived automatically,
        # specify config_url:
        # config_url https://<idp-server>/auth/realms/main/.well-known/openid-configuration;
    }

    server {
        listen 443 ssl;
        server_name demo.example.com;
x
        ssl_certificate     /etc/ssl/certs/fullchain.pem;
        ssl_certificate_key /etc/ssl/private/key.pem;

        location / {
            # Protect this location with OIDC
            auth_oidc my_idp;

            # Forward OIDC claims as headers if desired
            proxy_set_header sub   $oidc_claim_sub;
            proxy_set_header email $oidc_claim_email;
            proxy_set_header name  $oidc_claim_name;

            proxy_pass http://127.0.0.1:8080;
        }
    }

    server {
        # simple test oidc-protected application
        listen 8080;

        location / {
            return 200 "Hello, $http_name!\nEmail: $http_email\nIdP sub: $http_sub\n";
            default_type text/plain;
        }
    }
}
```

----------------------------------------

TITLE: Configure NGINX Plus Server Block for OIDC Protection
DESCRIPTION: Sets up an NGINX server block listening on HTTPS (port 443) for `demo.example.com`, including SSL certificate paths. It defines a location block that proxies requests to the OIDC-protected application at `http://127.0.0.1:8080`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/cognito.md#_snippet_4

LANGUAGE: nginx
CODE:
```
http {

    # ...

    server {
        listen      443 ssl;
        server_name demo.example.com;

        ssl_certificate     /etc/ssl/certs/fullchain.pem;
        ssl_certificate_key /etc/ssl/private/key.pem;

        location / {

            # ...

            proxy_pass http://127.0.0.1:8080;
        }
    }
    # ...
}
```

----------------------------------------

TITLE: Include NGINX Configuration Files with Wildcard
DESCRIPTION: Shows how to use a wildcard in the `include` directive within the `http` block to reference multiple configuration files that follow a specific naming convention (e.g., `*-http.conf`), allowing for flexible organization.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_9

LANGUAGE: nginx
CODE:
```
http {
    include conf.d/*-http.conf;
}
```

----------------------------------------

TITLE: NGINX Stream Proxy Pass to Single Server with Hostname Resolution
DESCRIPTION: Illustrates how to configure NGINX stream to proxy traffic to a single backend server identified by a hostname. When the hostname resolves to multiple IP addresses, NGINX automatically load balances traffic using the Round Robin algorithm. It's crucial to specify the port in `proxy_pass` and omit the protocol.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/tcp-udp-load-balancer.md#_snippet_12

LANGUAGE: nginx
CODE:
```
stream {
    # ...
    server {
        listen     12345;
        proxy_pass backend.example.com:12345;
    }
}
```

----------------------------------------

TITLE: Configure TrafficSplit to Associate with HTTPRouteGroup in YAML
DESCRIPTION: This YAML configuration updates a TrafficSplit resource named `target-ts`. It routes all traffic to `target-v3-0` (100% weight) and associates this split with the `target-hrg` HTTPRouteGroup, meaning this split only applies to traffic matching the conditions defined in `target-hrg`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/trafficsplit-deployments.md#_snippet_19

LANGUAGE: YAML
CODE:
```
apiVersion: split.smi-spec.io/v1alpha3
kind: TrafficSplit
metadata:
  name: target-ts
spec:
  service: target-svc
  backends:
  - service: target-v2-1
    weight: 0
  - service: target-v3-0
    weight: 100
  matches:
  - kind: HTTPRouteGroup
    name: target-hrg
```

----------------------------------------

TITLE: Preventing Caching in NGINX
DESCRIPTION: This snippet employs the `proxy_no_cache` directive to prevent NGINX Plus from caching responses under specific conditions. If the `$http_pragma` or `$http_authorization` variables are non-empty and not '0', the response will not be stored in the cache, useful for sensitive or dynamic content.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/content-cache/content-caching.md#_snippet_9

LANGUAGE: Nginx
CODE:
```
proxy_no_cache $http_pragma $http_authorization;
```

----------------------------------------

TITLE: Configure Nginx Unit Named Routes (JSON Object)
DESCRIPTION: This JSON configuration illustrates how to define Nginx Unit routes using a named object structure. Listeners can then pass requests to specific named route arrays (e.g., "routes/main", "routes/route66"), allowing for more organized and modular routing configurations compared to the simple array mode.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/configuration.md#_snippet_26

LANGUAGE: json
CODE:
```
{
   "listeners": {
      "*:8300": {
         "pass": "routes/main"
      }
   },
   "routes": {
      "main": {
         "value": [
            "..."
         ],
         "comment": "Any acceptable route array may go here; see the 'Route Steps' section for details"
      },
      "comment_main": "Named route, referred to as 'routes/main'",
      "route66": {
         "value": [
            "..."
         ],
         "comment": "Any acceptable route array may go here; see the 'Route Steps' section for details"
      },
      "comment_route66": "Named route, referred to as 'routes/route66'"
   }
}
```

----------------------------------------

TITLE: Define NGINX Web Server Block for App
DESCRIPTION: Create `app.conf` to define a new NGINX server block. It listens on port 80, sets the server name, root directory, and configures error logging. It also uses `sub_filter` directives to dynamically inject server and request information into the served HTML page.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/setting-up-nginx-demo-environment.md#_snippet_2

LANGUAGE: nginx
CODE:
```
server {
    listen 80 default_server;
    server_name app_server;

    root /usr/share/nginx/html;
    error_log /var/log/nginx/app-server-error.log notice;
    index demo-index.html index.html;
    expires -1;

    sub_filter_once off;
    sub_filter 'server_hostname' '$hostname';
    sub_filter 'server_address'  '$server_addr:$server_port';
    sub_filter 'server_url'      '$request_uri';
    sub_filter 'remote_addr'     '$remote_addr:$remote_port';
    sub_filter 'server_date'     '$time_local';
    sub_filter 'client_browser'  '$http_user_agent';
    sub_filter 'request_id'      '$request_id';
    sub_filter 'nginx_version'   '$nginx_version';
    sub_filter 'document_root'   '$document_root';
    sub_filter 'proxied_for_ip'  '$http_x_forwarded_for';
}
```

----------------------------------------

TITLE: Full NGINX Configuration for Basic Load Balancing with WebLogic
DESCRIPTION: This comprehensive NGINX configuration provides a complete setup for basic load balancing, including proxy caching, WebSocket handling, and redirecting HTTP traffic to HTTPS. It defines an upstream group for WebLogic servers, sets up SSL/TLS, and configures locations for load balancing specific application paths and WebSocket tunnels. This example demonstrates a robust NGINX reverse proxy setup.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_20

LANGUAGE: nginx
CODE:
```
proxy_cache_path /tmp/NGINX_cache/ keys_zone=backcache:10m;

# WebSocket configuration
map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

upstream weblogic {
    # Use IP Hash for session persistence
    ip_hash;

    # List of WebLogic Server application servers
    server 192.168.25.33:7001;
    server 192.168.25.69:7001;
}

server {
    listen 80;
    server_name example.com;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}

server {
    listen 443 ssl;
    http2  on;

    server_name example.com;

    ssl_certificate     /etc/nginx/ssl/certificate-name;
    ssl_certificate_key /etc/nginx/ssl/private-key;
    ssl_session_cache shared:SSL:1m;
    ssl_prefer_server_ciphers on;

    # Load balance requests for '/weblogic-app/' across WebLogic Server
    # application servers
    location /weblogic-app/ {
        proxy_pass http://weblogic;
        proxy_cache backcache;
    }

    # Return a temporary redirect to '/weblogic-app/' when user requests '/'
    location = / {
        return 302 /weblogic-app/;
    }

    # WebSocket configuration
    location /wstunnel/ {
        proxy_pass https://weblogic;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }
}
```

----------------------------------------

TITLE: Create a basic 'Hello, World!' FastAPI application
DESCRIPTION: This Python code snippet defines a minimal FastAPI application. It initializes a FastAPI instance and creates a root endpoint ('/') that returns a JSON message 'Hello, World!'. This file should be saved as 'asgi.py' for Unit to locate it.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/howto/frameworks/fastapi.md#_snippet_1

LANGUAGE: python
CODE:
```
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
async def root():
    return {"message": "Hello, World!"}
```

----------------------------------------

TITLE: Test NGINX Plus Configuration Syntax
DESCRIPTION: This command tests the syntax of the NGINX Plus configuration file (`nginx.conf`) for errors. It's crucial to run this before reloading NGINX to prevent service interruptions due to misconfigurations. A successful output confirms the configuration is valid.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/geoip.md#_snippet_5

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Validate Upstream Server Certificates in NGINX
DESCRIPTION: This NGINX configuration block enables validation of upstream server SSL certificates. It specifies the trusted CA certificate file and sets the verification level and depth, enhancing security against man-in-the-middle attacks.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/securing-tcp-traffic-upstream.md#_snippet_3

LANGUAGE: nginx
CODE:
```
server {
    ...
    proxy_ssl_trusted_certificate /etc/ssl/certs/trusted_ca_cert.crt;
    proxy_ssl_verify       on;
    proxy_ssl_verify_depth 2;
}
```

----------------------------------------

TITLE: Add OAuth2 JWT Assertion Policy via REST API
DESCRIPTION: This snippet details how to add an OAuth2 JWT Assertion policy to an API Proxy by sending a POST request to the specified endpoint. It includes a sample JSON request body for configuring the policy, detailing parameters like 'jwksURI', 'cacheKeysDuration', 'tokenName', and error return conditions. A warning is provided that local JWK usage is recommended for testing only, with 'jwksURI' preferred for production environments.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/how-to/policies/jwt-assertion.md#_snippet_1

LANGUAGE: APIDOC
CODE:
```
Method: POST
Endpoint: /services/workspaces/<SERVICE_WORKSPACE_NAME>/proxies
```

LANGUAGE: json
CODE:
```
{
	"policies": {
		"oauth2-jwt-assertion": [
			{
				"action": {
					"jwksURI": "https://idp.io:8443/oauth/certs",
					"cacheKeysDuration": "12h",
					"jwksKeys": [
						{
							"k": "bXlzZWNyZXQ",
							"kid": "0001",
							"kty": "oct"
						}
					],
					"tokenName": "Authorization",
					"tokenSuppliedIn": "HEADER",
					"errorReturnConditions": {
						"notSupplied": {
							"returnCode": 401
						},
						"noMatch": {
							"returnCode": 403
						}
					}
				}
			}
		]
	}
}
```

LANGUAGE: APIDOC
CODE:
```
Field: jwksURI
  Type: string
  Possible Values: Example: https://idp.io:8443/oauth/certs
  Description: URI endpoint that contains public keys used to verify the JWT signature. Not required if jwksKeys[] is populated.
  Required: Semi-optional
  Default value: N/A

Field: cacheKeysDuration
  Type: string
  Possible Values: Example: 12h
  Description: Specifies how long the keys will be cached. Keys will be refreshed from the URI endpoint after the duration. Only valid for jwksURI, not applicable for jwksKeys[]. Follows NGINX configuration time measurement units syntax.
  Required: No
  Default value: "12h"

Field: jwksKeys[]
  Type: array of JSON Web Keys
  Possible Values: Example in policy request body.
  Description: Keys to be used to verify JWT signatures. User should supply key data in valid JSON Web Key format. See related standards for JWK, JWK Set Format, and the jwksKeys parameter. Not required if jwksURI is populated.
  Required: Semi-optional
  Default value: N/A

Field: tokenName
  Type: string
  Possible Values: Example: Authorization
  Description: The name of the header or query parameter where the JWT will be located in the API request. In the case of default case of Authorization Header, the JWT token is required to adhere to the Bearer Token usage standard. Example: Authorization: Bearer <access token> where <access token>} is the Base64 encoded Client JWT.
  Required: No
  Default value: "Authorization"

Field: tokenSuppliedIn
  Type: string
  Possible Values: One of: ["HEADER", "QUERY"]
  Description: Specifies where the access token is supplied in the incoming user request.
  Required: No
  Default value: "HEADER"

Field: errorReturnConditions.notSupplied.returnCode
  Type: int
  Possible Values: In range 400-599
  Description: The error code that is returned from the API Proxy when an JWT is not supplied.
  Required: No
  Default value: 401

Field: errorReturnConditions.noMatch.returnCode
  Type: int
  Possible Values: In range 400-599
  Description: The error code that is returned from the API Proxy when an invalid JWT is supplied.
  Required: No
  Default value: 403
```

----------------------------------------

TITLE: Restart NGINX Web Server Post-Installation
DESCRIPTION: Command to restart the NGINX web server after the initial installation of API Connectivity Manager to ensure all changes are applied.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/how-to/install-acm.md#_snippet_2

LANGUAGE: bash
CODE:
```
sudo systemctl restart nginx
```

----------------------------------------

TITLE: Restart NGINX Service
DESCRIPTION: This command restarts the NGINX service, applying any changes made to the NGINX configuration files, including newly loaded modules or updated directives for App Protect WAF or DoS.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/deployment-guide/installing-nginx-plus-with-dos-and-waf-on-amazon-web-services.md#_snippet_13

LANGUAGE: shell
CODE:
```
sudo systemctl restart nginx
```

----------------------------------------

TITLE: NGINX: Complete Amazon Cognito OIDC Integration Example
DESCRIPTION: This comprehensive NGINX configuration demonstrates a full setup for integrating with Amazon Cognito as an OIDC provider. It includes defining the OIDC provider, configuring SSL, protecting a location with auth_oidc, forwarding claims, and setting up a simple backend application. This example summarizes all essential settings.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/cognito.md#_snippet_9

LANGUAGE: nginx
CODE:
```
http {
    # Use a public DNS resolver for Issuer discovery, etc.
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider cognito {
        # Typically your Cognito issuer is something like:
        # https://cognito-idp.<region>.amazonaws.com/<UserPoolID>
        issuer https://cognito-idp.us-east-2.amazonaws.com/us-east-2_abCdEfGhI;

        # Your Cognito "App client id" and "App client secret"
        client_id <client_id>;
        client_secret <client_secret>;
    }

    server {
        listen 443 ssl;
        server_name demo.example.com;

        ssl_certificate /etc/ssl/certs/fullchain.pem;
        ssl_certificate_key /etc/ssl/private/key.pem;

        location / {
            # Protect this path with Cognito OIDC
            auth_oidc cognito;

            # Forward OIDC claims as headers if desired
            proxy_set_header sub $oidc_claim_sub;
            proxy_set_header email $oidc_claim_email;
            proxy_set_header name $oidc_claim_name;

            proxy_pass http://127.0.0.1:8080;
        }
    }

    server {
        listen 8080;

        location / {
            return 200 "Hello, $http_name!\nEmail: $http_email\nSub: $http_sub\n";
            default_type text/plain;
        }
    }
}
```

----------------------------------------

TITLE: Configure Basic Rate Limiting SnippetsFilter
DESCRIPTION: This `SnippetsFilter` defines two Snippets to configure rate limiting. The first Snippet injects the value: `limit_req_zone \$binary_remote_addr zone=rate-limiting-sf:10m rate=1r/s;` into the `http` context. The second Snippet injects the value: `limit_req zone=rate-limiting-sf burst=3;` into the location(s) generated for whichever route(s) reference this `SnippetsFilter`. This `SnippetsFilter` will limit the request processing rate to 1 request per second.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/snippets.md#_snippet_9

LANGUAGE: yaml
CODE:
```
kubectl apply -f - <<EOF
apiVersion: gateway.nginx.org/v1alpha1
kind: SnippetsFilter
metadata:
  name: rate-limiting-sf
spec:
  snippets:
    - context: http
      value: limit_req_zone \$binary_remote_addr zone=rate-limiting-sf:10m rate=1r/s;
    - context: http.server.location
      value: limit_req zone=rate-limiting-sf burst=3;
EOF
```

----------------------------------------

TITLE: NGINX Default SSL Protocols and Ciphers (v1.23.4+)
DESCRIPTION: This configuration shows the default `ssl_protocols` and `ssl_ciphers` settings used by NGINX since version 1.23.4. It emphasizes the use of strong TLS versions (1.2 and 1.3) and high-strength ciphers, recommending disabling older, vulnerable ciphers for modern deployments.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/terminating-ssl-http.md#_snippet_2

LANGUAGE: nginx
CODE:
```
ssl_protocols TLSv1.2 TLSv1.3;
ssl_ciphers   HIGH:!aNULL:!MD5;
```

----------------------------------------

TITLE: Configure Gzip Compression for Proxied Requests in NGINX
DESCRIPTION: By default, NGINX does not compress responses to proxied requests. To configure compression of these responses, use the gzip_proxied directive. This example sets parameters to compress responses that will not be cached on the proxy server, checking Cache-Control and Expires headers, and the presence of the Authorization header.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/compression.md#_snippet_3

LANGUAGE: nginx
CODE:
```
gzip_proxied no-cache no-store private expired auth;
```

----------------------------------------

TITLE: Update HTTPRoute with ResponseHeaderModifier Filter
DESCRIPTION: This YAML snippet updates the existing Kubernetes HTTPRoute to include a `ResponseHeaderModifier` filter. This filter demonstrates setting, adding, and removing specific HTTP response headers for requests matching the '/headers' path prefix.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/request-response-headers.md#_snippet_12

LANGUAGE: yaml
CODE:
```
kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: headers
spec:
  parentRefs:
  - name: gateway
    sectionName: http
  hostnames:
  - "cafe.example.com"
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /headers
    filters:
    - type: ResponseHeaderModifier
      responseHeaderModifier:
        set:
        - name: X-Header-Set
          value: overwritten-value
        add:
        - name: X-Header-Add
          value: this-is-the-appended-value
        remove:
        - X-Header-Remove
    backendRefs:
    - name: headers
      port: 80
EOF
```

----------------------------------------

TITLE: Example Decoded Microsoft Entra Access Token Payload
DESCRIPTION: Presents the payload (claims) section of a decoded access token from Microsoft Entra ID, containing information about the token's audience (aud), issuer (iss), issuance and expiration times (iat, exp), application ID (appid), and assigned roles (roles). The roles claim is particularly important for authorization decisions within the NGINX Management Suite API.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/admin-guide/authentication/oidc/microsoft-entra-automation.md#_snippet_4

LANGUAGE: json
CODE:
```
{
    "aud": "api://f834b49c-a56e-4fde-9caa-641-bOc26fb8a",
    "iss": "https://sts.windows.net/d3dfd2f-6a3b-40d1-9beO-b8f327d81c50/",
    "iat": 1593640000,
    "nbf": 1593640000,
    "exp": 1593643600,
    "aio": "42+E2ZYHBXei7VKmxxHzn7h1",
    "appid": "374cc05e-aaa1-408f-9348-a83d6b4d8ea6",
    "appidacr": "1",
    "idp": "https://sts.windows.net/d3dfd2f-6a3b-40d1-9beO-b8f327d81c5/",
    "oid": "2db3db56-f58b-455a-9ff5-4e1e8b17a171",
    "rh": "0.AQABA_893Ttq0UCb4L0QwQ-DJ9QgcILmngha-4Q",
    "roles":    [
        "28a3143e-4217-485e-9fOf-092abc01239b01"
    ],
    "sub": "2db3db56-f58b-455a-9ff5-4e1e8b17a1a71",
    "tid": "dd3dfd2f-6a3b-40d1-9bee-bfaqw27d81c5e",
    "uti": "EmqiFiTC-kACZqN5vrKd8AQ"
}
```

----------------------------------------

TITLE: Configure NGINX Service Mesh with AWS Secrets Manager Upstream Authority
DESCRIPTION: Minimal YAML configuration for NGINX Service Mesh to use AWS Secrets Manager as an upstream authority. This setup loads CA credentials by specifying the AWS region and the ARNs of the certificate and key files stored in Secrets Manager.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/guides/secure-traffic-mtls.md#_snippet_3

LANGUAGE: yaml
CODE:
```
apiVersion: "v1"
upstreamAuthority: "awssecret"
config:
    region: "us-west-2"
    cert_file_arn: "arn:aws:acm-pca::123456789012:certificate-authority/test"
    key_file_arn: "arn:aws:acm-pca::123456789012:certificate-authority/test-key"
```

----------------------------------------

TITLE: Create Kubernetes Gateway Resource for NGINX Gateway Fabric
DESCRIPTION: This snippet defines and applies a Kubernetes Gateway resource named 'cafe' using `kubectl`. It specifies 'nginx' as the gatewayClassName, indicating it will be managed by NGINX Gateway Fabric, and configures an HTTP listener on port 80.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/basic-routing.md#_snippet_3

LANGUAGE: yaml
CODE:
```
kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: cafe
spec:
  gatewayClassName: nginx
  listeners:
  - name: http
    port: 80
    protocol: HTTP
EOF
```

----------------------------------------

TITLE: Include Specific NGINX Configuration File
DESCRIPTION: Demonstrates how to use the `include` directive within the `http` context of the main `nginx.conf` file to incorporate specific configuration files, such as `tomcat-basic.conf` or `tomcat-enhanced.conf`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_8

LANGUAGE: nginx
CODE:
```
http {
    include conf.d/tomcat-(basic|enhanced).conf;
}
```

----------------------------------------

TITLE: Illustrating NGINX Configuration Contexts and Virtual Servers
DESCRIPTION: This comprehensive example demonstrates the hierarchical structure of an NGINX configuration file using multiple top-level contexts: `main`, `events`, `http`, and `stream`. It shows how `server` blocks define virtual servers within `http` and `stream` contexts, and how `location` blocks further refine HTTP request processing for specific URIs.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/basic-functionality/managing-configuration-files.md#_snippet_2

LANGUAGE: nginx
CODE:
```
user nobody; # a directive in the 'main' context

events {
    # configuration of connection processing
}

http {
    # Configuration specific to HTTP and affecting all virtual servers

    server {
        # configuration of HTTP virtual server 1
        location /one {
            # configuration for processing URIs starting with '/one'
        }
        location /two {
            # configuration for processing URIs starting with '/two'
        }
    }

    server {
        # configuration of HTTP virtual server 2
    }
}

stream {
    # Configuration specific to TCP/UDP and affecting all virtual servers
    server {
        # configuration of TCP virtual server 1
    }
}
```

----------------------------------------

TITLE: Configure Cookie-Based Session Persistence
DESCRIPTION: This section provides configuration examples for implementing cookie-based session persistence (affinity) for load balancing. It covers both F5 BIG-IP LTM and NGINX Plus, demonstrating how the load balancer inserts a cookie to maintain client-to-server affinity across requests.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/migrate-hardware-adc/f5-big-ip-configuration.md#_snippet_6

LANGUAGE: none
CODE:
```
# create persistence cookie test_bigip_cookie cookie-name BIGIP_COOKIE_PERSIST expiration 1:0:0
# modify virtual test_virtual { persist replace-all-with { test_bigip_cookie } }
# save /sys config
```

LANGUAGE: none
CODE:
```
# create persistence cookie test_bigip_cookie cookie-name BIGIP_COOKIE_PERSIST expiration 1:0:0
# modify virtual test_ssl_virtual { persist replace-all-with { test_bigip_cookie } }
# save /sys config
```

LANGUAGE: nginx
CODE:
```
upstream test_pool {
     server 10.10.10.10:80;
     server 10.10.10.20:80;
     sticky cookie mysession expires=1h;
}
```

LANGUAGE: nginx
CODE:
```
upstream ssl_test_pool {
     server 10.10.10.10:443;
     server 10.10.10.20:443;
     sticky cookie mysession expires=1h;
}
```

----------------------------------------

TITLE: Implement Spin SDK HTTP Component in Rust
DESCRIPTION: Replace the content of 'src/lib.rs' with Rust code that defines an HTTP component using the Spin SDK. This example creates a simple component that responds to HTTP requests with a 'Hello, World' message, demonstrating basic request handling and response construction.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/news/2024/fermyon-spin-rust-sdk.md#_snippet_3

LANGUAGE: rust
CODE:
```
use spin_sdk::http::{IntoResponse, Request, Response};
use spin_sdk::http_component;

#[http_component]
fn handle_hello_world(_req: Request) -> anyhow::Result<impl IntoResponse> {
    let body_string = String::from("Hello, this is a Wasm Component using Spin SDK");

    Ok(Response::builder()
        .status(200)
        .header("Content-Type", "text/plain")
        .header("Content-Lenght", body_string.len().to_string())
        .body(body_string)
        .build())
}
```

----------------------------------------

TITLE: Combined NGINX Caching Configuration Example
DESCRIPTION: Illustrates a multi-faceted NGINX caching setup within an `http` block. It defines a cache zone, applies it to a server, and demonstrates different caching behaviors for two distinct location paths (`/` and `/some/path`), including cache validation, minimum uses, and bypass conditions.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/content-cache/content-caching.md#_snippet_21

LANGUAGE: Nginx
CODE:
```
http {
    # ...
    proxy_cache_path /data/nginx/cache keys_zone=mycache:10m loader_threshold=300
                     loader_files=200 max_size=200m;

    server {
        listen 8080;
        proxy_cache mycache;

        location / {
            proxy_pass http://backend1;
        }

        location /some/path {
            proxy_pass http://backend2;
            proxy_cache_valid any 1m;
            proxy_cache_min_uses 3;
            proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;
        }
    }
}
```

----------------------------------------

TITLE: Keepalived Configuration for Passive Node in Active-Active-Passive HA
DESCRIPTION: This configuration defines two VRRP instances (VI_1 and VI_2) for a passive keepalived node. It sets up health checks for the NGINX service and specifies unicast peers for active-active communication, ensuring failover for two virtual IP addresses (192.168.10.100 and 192.168.10.101).
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/high-availability/ha-keepalived-nodes.md#_snippet_5

LANGUAGE: keepalived configuration
CODE:
```
vrrp_script chk_nginx_service {
    script   "/usr/lib/keepalived/nginx-ha-check"
    interval 3
    weight   50
}

vrrp_instance VI_1 {
    interface         eth0
    state             BACKUP
    priority          99
    virtual_router_id 51
    advert_int        1
    accept
    unicast_src_ip    192.168.10.12

    unicast_peer {
        192.168.10.10
        192.168.10.11
    }

    virtual_ipaddress {
        192.168.10.100
    }

    track_script {
        chk_nginx_service
    }

    notify "/usr/lib/keepalived/nginx-ha-notify"
}

vrrp_instance VI_2 {
    interface         eth0
    state             BACKUP
    priority          99
    virtual_router_id 61
    advert_int        1
    accept
    unicast_src_ip    192.168.10.12

    unicast_peer {
        192.168.10.10
        192.168.10.11
    }

    virtual_ipaddress {
        192.168.10.101
    }

    track_script {
        chk_nginx_service
    }

    notify "/usr/lib/keepalived/nginx-ha-notify"
}
```

----------------------------------------

TITLE: Nginx Unit JSON Configuration for Django ASGI Application
DESCRIPTION: This JSON snippet defines the application configuration for Nginx Unit, specifying the project's virtual environment home, the ASGI module path (e.g., 'project.asgi'), and critical environment variables required for a Django application, such as DJANGO_SETTINGS_MODULE and database connection details (DB_ENGINE, DB_NAME, DB_HOST, DB_PORT). It also includes inline comments for better understanding of each configuration parameter.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/howto/frameworks/django.md#_snippet_2

LANGUAGE: json
CODE:
```
{
               "_comment_path": "Project directory; use a real path in your configuration",
               "home": "/path/to/venv/",
               "_comment_home": "Virtual environment directory; use a real path in your configuration",
               "module": "project.asgi",
               "_comment_module": "Note the qualified name of the ASGI module; use a real project directory name in your configuration",
               "environment": {
                  "DJANGO_SETTINGS_MODULE": "project.settings",
                  "DB_ENGINE": "django.db.backends.postgresql",
                  "DB_NAME": "project",
                  "DB_HOST": "127.0.0.1",
                  "DB_PORT": "5432"
               },
               "_comment_environment": "App-specific environment variables"
         }
```

----------------------------------------

TITLE: NGINX: Pass OIDC Claims as Proxy Headers
DESCRIPTION: This NGINX configuration shows how to extract specific OIDC claims (subject, email, name) from the ID token returned by Amazon Cognito and pass them as custom HTTP headers to the backend application. The $oidc_claim_ variables are used for this purpose, enabling the application to receive user information.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/cognito.md#_snippet_6

LANGUAGE: nginx
CODE:
```
location / {
     auth_oidc cognito;

     proxy_set_header sub   $oidc_claim_sub;
     proxy_set_header email $oidc_claim_email;
     proxy_set_header name  $oidc_claim_name;

     proxy_pass http://127.0.0.1:8080;
}
```

----------------------------------------

TITLE: NGINX Configuration for Passing OIDC Claims as Headers
DESCRIPTION: This NGINX configuration snippet demonstrates how to use the `proxy_set_header` directive to pass OIDC claims (subject, email, name) extracted from the Okta ID token as HTTP headers to the backend application. It ensures that authenticated user information is available to the proxied service.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/okta.md#_snippet_6

LANGUAGE: nginx
CODE:
```
# ...
location / {
     auth_oidc okta;

     proxy_set_header sub   $oidc_claim_sub;
     proxy_set_header email $oidc_claim_email;
     proxy_set_header name  $oidc_claim_name;

     proxy_pass http://127.0.0.1:8080;
}
# ...
```

----------------------------------------

TITLE: Define Extended NGINX Access Log Format for Metrics
DESCRIPTION: This NGINX configuration snippet defines a new log format named `main_ext`. It includes an extended set of NGINX variables such as `$remote_addr`, `$time_local`, `$request`, `$status`, `$body_bytes_sent`, `$request_time`, and upstream details, which are crucial for collecting detailed metrics with NGINX Amplify Agent.
SOURCE: https://github.com/nginx/documentation/blob/main/content/amplify/metrics-metadata/nginx-metrics.md#_snippet_5

LANGUAGE: NGINX Config
CODE:
```
log_format  main_ext  '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for" '
                        '"$host" sn="$server_name" '
                        'rt=$request_time '
                        'ua="$upstream_addr" us="$upstream_status" '
                        'ut="$upstream_response_time" ul="$upstream_response_length" '
                        'cs=$upstream_cache_status' ;
```

----------------------------------------

TITLE: NGINX Proxy Pass and Client Body Size Configuration
DESCRIPTION: Configures NGINX to allow large client request body sizes (0 for unlimited) and proxy traffic to a backend server. This snippet is typically part of a server or location block in an NGINX configuration file.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v5/configuration-guide/configuration.md#_snippet_39

LANGUAGE: nginx
CODE:
```
client_max_body_size 0;
default_type text/html;
# Pass traffic to backend
proxy_pass http://127.0.0.1:8080/;
```

----------------------------------------

TITLE: NGINX: Synchronize Rate Limit Zones Across Cluster Instances
DESCRIPTION: This configuration demonstrates how to enable synchronization of shared memory zones for rate limiting across multiple NGINX instances in a cluster. By adding the `sync` parameter to `limit_req_zone`, NGINX instances can share state, provided the `zone_sync` functionality is also configured. This ensures consistent rate limiting across distributed environments.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/controlling-access-proxied-http.md#_snippet_10

LANGUAGE: nginx
CODE:
```
http {
    #...
    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s sync;
}
```

----------------------------------------

TITLE: Configure NGINX HTTPS Server Block
DESCRIPTION: Configures a server block to listen on port 443 for HTTPS traffic, enables SSL/TLS, and creates a status zone entry for monitoring. This block should be placed within the top-level `http` configuration.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_32

LANGUAGE: nginx
CODE:
```
# In the 'http' block
server {
    listen      443 ssl;
    status_zone exchange-combined;
}
```

----------------------------------------

TITLE: Restart NGINX Service for Full Reinitialization
DESCRIPTION: The `restart` command fully stops and then starts the NGINX service. This action terminates all active connections, clears in-memory states, and reloads all modules and configurations. It is typically used for major software upgrades or when a complete service reinitialization is required, but it will cause temporary service interruption.
SOURCE: https://github.com/nginx/documentation/blob/main/templates/style-guide.md#_snippet_34

LANGUAGE: bash
CODE:
```
sudo systemctl restart nginx
```

----------------------------------------

TITLE: NGINX: Specify SSL Protocols and Ciphers for Upstream
DESCRIPTION: This NGINX configuration snippet allows specifying the SSL/TLS protocols and ciphers to be used when NGINX connects to upstream servers. This enhances security by restricting connections to strong, modern encryption standards and disabling weaker ones.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/securing-http-traffic-upstream.md#_snippet_4

LANGUAGE: nginx
CODE:
```
location /upstream {
        #...
        proxy_ssl_protocols TLSv1.2 TLSv1.3;
        proxy_ssl_ciphers   HIGH:!aNULL:!MD5;
}
```

----------------------------------------

TITLE: Configure NGINX OIDC Provider Credentials
DESCRIPTION: Specify the `issuer` URL, `client_id`, and `client_secret` within the `oidc_provider {}` context for the AD FS OIDC provider. Ensure NGINX trusts the IdP's certificate, using `ssl_trusted_certificate` if needed.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/active-directory-federation-services.md#_snippet_4

LANGUAGE: nginx
CODE:
```
http {
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider adfs {
        issuer        https://adfs.example.com/adfs;
        client_id     <client_id>;
        client_secret <client_secret>;
    }

    # ...
}
```

----------------------------------------

TITLE: Comprehensive NGINX Configuration Example with PROXY Protocol and Logging
DESCRIPTION: This extensive NGINX configuration example demonstrates a complete setup for handling client IP addresses via the PROXY protocol. It includes defining custom log_format directives for both HTTP and Stream, configuring server blocks to listen with the proxy_protocol parameter, managing SSL termination, and setting proxy_set_header for HTTP and proxy_protocol on for Stream to ensure client IP forwarding to backends. This setup is ideal when NGINX is behind a load balancer that supports the PROXY protocol.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/using-proxy-protocol.md#_snippet_8

LANGUAGE: Nginx
CODE:
```
http {
    log_format combined '$proxy_protocol_addr - $remote_user [$time_local] '
                        '"$request" $status $body_bytes_sent '
                        '"$http_referer" "$http_user_agent"';
    #...

    server {
        server_name localhost;

        listen 80   proxy_protocol;
        listen 443  ssl proxy_protocol;

        ssl_certificate      /etc/nginx/ssl/public.example.com.pem;
        ssl_certificate_key  /etc/nginx/ssl/public.example.com.key;

        location /app/ {
            proxy_pass       http://backend1;
            proxy_set_header Host            $host;
            proxy_set_header X-Real-IP       $proxy_protocol_addr;
            proxy_set_header X-Forwarded-For $proxy_protocol_addr;
        }
    }
}

stream {
    log_format basic '$proxy_protocol_addr - $remote_user [$time_local] '
                     '$protocol $status $bytes_sent $bytes_received '
                     '$session_time';
    #...
    server {
        listen              12345 ssl proxy_protocol;

        ssl_certificate     /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/cert.key;

        proxy_pass          backend.example.com:12345;
        proxy_protocol      on;
    }
}
```

----------------------------------------

TITLE: NGINX HTTPRoute Configuration to Fully Switch to New Version
DESCRIPTION: This HTTPRoute YAML configuration illustrates how to complete a canary release by fully switching all traffic to the new application version. By setting the 'my-app-old' backend's weight to 0 and the 'my-app-new' backend's weight to 1, all requests are directed to the new version, effectively phasing out the old one.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/how-to/upgrade-apps-without-downtime.md#_snippet_2

LANGUAGE: yaml
CODE:
```
- matches:
    - path:
        type: PathPrefix
        value: /
  backendRefs:
    - name: my-app-old
      port: 80
      weight: 0
    - name: my-app-new
      port: 80
      weight: 1
```

----------------------------------------

TITLE: Nginx Full Configuration for Single Web Entry Point
DESCRIPTION: This Nginx configuration sets up a robust web entry point. It includes worker process management, detailed error and access logging, MIME type handling, and proxy caching. An 'upstream' block defines a group of Oracle backend servers, distinguishing between production and disaster recovery instances, and implements session persistence with sticky cookies. The configuration redirects HTTP traffic to HTTPS, handles SSL termination, and includes a health check mechanism. Additionally, it configures a live activity monitoring dashboard with API access, allowing for real-time metrics collection and status viewing.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_41

LANGUAGE: nginx
CODE:
```
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log info;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type text/html;
    proxy_cache_path /var/oracle-cache keys_zone=cache_oracle:50m max_size=500m;

    # Custom logging configuration
    log_format main '$remote_addr - $remote_user [$time_local]
                    "$request" $status $body_bytes_sent "$http_referer"
                    "$http_user_agent" $upstream_addr';
    access_log /var/log/nginx/access.log main;

    upstream oracle {
        zone oracle 64k;

        # Production servers
        server 172.31.11.210:8000 max_fails=0;
        server 172.31.0.146:8000 max_fails=0;

        # Disaster recovery servers
        server 172.33.111.210:8000 max_fails=0 backup;
        server 172.33.100.146:8000 max_fails=0 backup;

        # Session persistence
        sticky cookie ngxcookie;
    }

    server {
        listen 80;
        status_zone oracle-http-redirect;
        return 302 https://$http_host$request_uri;
    }

    server {
        listen 443 ssl;
        http2  on;
        server_name company.com;
        ssl_certificate     /etc/nginx/ssl/certificate-name.crt;
        ssl_certificate_key /etc/nginx/ssl/private-key.key;
        ssl_protocols       TLSv1.2;
        status_zone oracle-ssl;
        proxy_cache cache_oracle;

        location / {
            proxy_pass http://oracle;
            proxy_set_header Host $host;
            proxy_cache_valid any 1h;
        }

        location @health_check {
            internal;
            proxy_connect_timeout 3s;
            proxy_read_timeout 3s;
            proxy_pass http://oracle;
            proxy_set_header Host "oracle.company.com";
            health_check match=oracleok interval=4s
                         uri=/OA_HTML/AppsLocalLogin.jsp;
        }
    }

    match oracleok {
        status 200-399;
        header X-ORACLE-DMS-ECID;
    }

    # Live activity monitoring configuration
    server {
        # Status zone required for live activity monitoring. Enable it for
        # every 'server' block in other configuration files.
        status_zone status-page;

        # If NGINX Plus is listening on multiple IP addresses, uncomment this
        # directive to restrict access to the live activity monitoring
        # dashboard to a single IP address (substitute the appropriate
        # address).
        # listen 10.2.3.4:8080;
        # Live activity monitoring is enabled on port 8080 by default.
        listen 8080;

        # HTTP Basic authentication is enabled by default. Use an htpasswd
        # generator to add users, or command-line and other management tools are
        # readily available online. If you have Apache HTTP Server installed, you
        # can reuse its htpasswd file.
        #auth_basic on;
        #auth_basic_user_file /etc/nginx/users;

        # Limit access to the dashboard to users on admin networks only.
        # Uncomment the "allow" directive and change the IP address.
        #allow 10.0.0.0/8;
        deny all;

        # Enable the NGINX Plus API for metrics collection.
        location /api {
            api write=on;
            access_log off;
        }

        # NGINX Plus includes a built-in dashboard.
        location = /dashboard.html {
            root /usr/share/nginx/html;
        }

        # Redirect requests made to the pre-R14 dashboard.
        location = /status.html {
            return 301 /dashboard.html;
        }

        # Standard HTTP features are fully supported with the dashboard.
        # Redirect request for '/' to '/dashboard.html'.
        location = / {
            return 301 /dashboard.html;
        }
    }
}
```

----------------------------------------

TITLE: Nginx Unit Access Log Format Configuration
DESCRIPTION: This configuration defines a custom log format for Nginx Unit access logs. It logs the timestamp, remote IP address, URI, and all request headers in a key-value pair format, providing detailed request analysis capabilities.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/scripting.md#_snippet_6

LANGUAGE: json
CODE:
```
{
    "path": "/var/log/unit/access_kv.log",
    "format": "`@timestamp=${new Date().toISOString()} ip=${remoteAddr} uri=${uri} ${Object.keys(headers).map(k => 'req.' + k + '=\"' + headers[k] + '\"').join(' ')}\n`"
}
```

----------------------------------------

TITLE: Redirect NGINX HTTP to HTTPS
DESCRIPTION: Configures a separate server block to listen on port 80 (HTTP) and permanently redirects all incoming requests to the HTTPS server (port 443). This ensures all traffic is secured via HTTPS. This block should be placed within the top-level `http` configuration.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_37

LANGUAGE: nginx
CODE:
```
# In the 'http' block
server {
    listen 80;
    location / {
        return 301 https://$host$request_uri;
    }
}
```

----------------------------------------

TITLE: NGINX Full Configuration for Enhanced Load Balancing with WildFly
DESCRIPTION: This NGINX configuration provides a complete setup for load balancing WildFly application servers. It includes `proxy_cache_path` for caching, `map` for WebSocket upgrades, `match` for application health checks, and an `upstream` block for `jboss` servers with session persistence and shared memory zones. It defines two `server` blocks: one for HTTP to HTTPS redirection and another for HTTPS traffic, handling SSL, HTTP/2, load balancing to `/webapp/`, WebSocket tunneling, and secured access to the NGINX Plus API.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_44

LANGUAGE: nginx
CODE:
```
proxy_cache_path /tmp/NGINX_cache/ keys_zone=backcache:10m;

# WebSocket configuration
map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

# Application health checks
match jboss_check {
    status 200;
    header Content-Type = text/html;
    body ~ "Your WildFly 9 is running";

}

upstream jboss {
    # Shared memory zone for application health checks, live activity
    # monitoring, and dynamic reconfiguration
    zone jboss 64k;

    # List of Wildfly application servers
    server 192.168.33.11:8080 slow_start=30s;
    server 192.168.33.12:8080 slow_start=30s;

    # Session persistence based on JSESSIONID
    sticky learn create=$upstream_cookie_JSESSIONID
                 lookup=$cookie_JSESSIONID
                 zone=client_sessions:1m;
}

server {
    listen 80;
    server_name example.com;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}

server {
    listen 443 ssl;
    http2  on;

    server_name example.com;

    # Required for live activity monitoring of HTTPS traffic
    status_zone jboss;
    ssl_certificate            /etc/nginx/ssl/<certificate-name>;
    ssl_certificate_key        /etc/nginx/ssl/<private-key>;
    ssl_session_cache          shared:SSL:1m;
    ssl_prefer_server_ciphers  on;

    # Load balance requests for '/webapp/' across Wildfly application servers
    location /webapp/ {
        proxy_pass http://jboss;
        proxy_cache backcache;

        # Active health checks
        health_check match=jboss_check;
    }

    # Return a 302 redirect to '/webapp/' when user requests '/'
    location = / {
        return 302 /webapp/;
    }

    # WebSocket configuration
    location /wstunnel/ {
        proxy_pass http://jboss;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Secured access to the NGINX Plus API
    location /api {
        api write=on;
        allow 127.0.0.1; # Permit access from localhost
        deny all;        # Deny access from everywhere else
    }
}
```

----------------------------------------

TITLE: Install NGINX Service Mesh via Helm with Observability Integration
DESCRIPTION: This Helm command adds the NGINX stable repository, updates it, and then installs NGINX Service Mesh. It configures the mesh to connect to Prometheus and OpenTelemetry Collector, setting the respective addresses and a telemetry sampler ratio of 1. The installation creates the `nginx-mesh` namespace.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/observability.md#_snippet_2

LANGUAGE: bash
CODE:
```
helm repo add nginx-stable https://helm.nginx.com/stable
helm repo update

helm install nsm nginx-stable/nginx-service-mesh --namespace nginx-mesh --create-namespace --wait --set prometheusAddress=prometheus.nsm-monitoring.svc:9090 --set telemetry.exporters.otlp.host=otel-collector.nsm-monitoring.svc --set telemetry.exporters.otlp.port=4317 --set telemetry.samplerRatio=1
```

----------------------------------------

TITLE: Example NGINX Root Configuration for OIDC with Localhost Upstream
DESCRIPTION: Provides a complete example of an `nginx.conf` file demonstrating how to integrate OpenID Connect authentication. It includes loading the `ngx_http_js_module.so`, defining an upstream for a backend application (using localhost for testing), setting a custom log format, and configuring a frontend server with SSL/TLS and OIDC includes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/security-controls/oidc.md#_snippet_4

LANGUAGE: nginx
CODE:
```
load_module modules/ngx_http_js_module.so;

http {

    # This is the backend application we are protecting with OpenID Connect
    upstream my_backend {
        zone my_backend 64k;
        # Reuse the localhost as a upstream server
        # Modify to the real upstream server address if you have
        server 127.0.0.1;
    }

    # A local server block representing the upstream server for testing only
    # Remove if you have the real upstream servers
    server {
        listen 80;
        default_type text/html;
        return 200 '<!DOCTYPE html><h2>This is a site protected by OIDC!</h2>\n';
    }

    # Custom log format to include the 'sub' claim in the REMOTE_USER field
    log_format main_jwt '$remote_addr - $jwt_claim_sub [$time_local] "$request" $status '
                        '$body_bytes_sent "$http_referer" "$http_user_agent" "$http_x_forwarded_for"';

    # The frontend server - reverse proxy with OpenID Connect authentication
    #
    include conf.d/openid_connect_configuration.conf;
    server {
        include conf.d/openid_connect.server_conf; # Authorization code flow and Relying Party processing
        error_log /var/log/nginx/error.log debug;  # Reduce severity level as required

        listen 443 ssl; # Use SSL/TLS in production
        ssl_certificate /etc/nginx/ssl/my-cert.crt;
        ssl_certificate_key /etc/nginx/ssl/my-cert.key;

        location / {
```

----------------------------------------

TITLE: Deploy NGINX Gateway API HTTPRoute for Coffee Application
DESCRIPTION: This YAML snippet defines an HTTPRoute resource that attaches to the previously created 'cafe' Gateway. It routes traffic for 'cafe.example.com' to different 'coffee' service versions based on path prefixes, header values (exact and regex), and query parameters (exact and regex). It demonstrates conditional routing to `coffee-v1-svc`, `coffee-v2-svc`, and `coffee-v3-svc`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/advanced-routing.md#_snippet_3

LANGUAGE: yaml
CODE:
```
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: coffee
spec:
  parentRefs:
  - name: cafe
    sectionName: http
  hostnames:
  - cafe.example.com
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /coffee
    backendRefs:
    - name: coffee-v1-svc
      port: 80
  - matches:
    - path:
        type: PathPrefix
        value: /coffee
      headers:
      - name: version
        value: v2
    - path:
        type: PathPrefix
        value: /coffee
      queryParams:
      - name: TEST
        value: v2
    backendRefs:
    - name: coffee-v2-svc
      port: 80
  - matches:
    - path:
        type: PathPrefix
        value: /coffee
      headers:
      - name: headerRegex
        type: RegularExpression
        value: "header-[a-z]{1}"
    - path:
        type: PathPrefix
        value: /coffee
      queryParams:
      - name: queryRegex
        type: RegularExpression
        value: "query-[a-z]{1}"
    backendRefs:
    - name: coffee-v3-svc
      port: 80
```

----------------------------------------

TITLE: NGINX SSL: ssl Directive Deprecation
DESCRIPTION: The `ssl` directive, which was deprecated in NGINX Plus Release 16, has been completely removed in R30. Users should now configure SSL by using the `ssl` parameter directly within the `listen` directive for server blocks.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/releases.md#_snippet_13

LANGUAGE: NGINX Config
CODE:
```
# Deprecated and removed in R30:
# ssl on;

# Recommended alternative (use 'ssl' parameter with 'listen' directive):
listen 443 ssl;
```

----------------------------------------

TITLE: Complete Nginx Configuration for Basic Load Balancing
DESCRIPTION: This comprehensive Nginx configuration demonstrates basic load balancing. It includes proxy cache path definition, a map for WebSocket connection upgrades, an upstream block with IP hash for session persistence, HTTP to HTTPS redirection, and a secure server block handling load balancing for a Tomcat application and WebSocket tunneling.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_23

LANGUAGE: nginx
CODE:
```
proxy_cache_path /tmp/NGINX_cache/ keys_zone=backcache:10m;

map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

upstream tomcat {
    # Use IP Hash for session persistence
    ip_hash;
    # List of Tomcat application servers
    server 10.100.100.11:8080;
    server 10.100.100.12:8080;
}

server {
    listen 80;
    server_name example.com;
    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}

server {
    listen 443 ssl;
    http2  on;

    server_name example.com;
    ssl_certificate     /etc/nginx/ssl/example.com.crt;
    ssl_certificate_key /etc/nginx/ssl/example.com.key;
    ssl_session_cache   shared:SSL:1m;
    ssl_prefer_server_ciphers on;

    # Load balance requests for '/tomcat-app/' across Tomcat application
    # servers
    location /tomcat-app/ {
        proxy_pass http://tomcat;
        proxy_cache backcache;
    }

    # Return a temporary redirect to '/tomcat-app/' when user requests '/'
    location = / {
        return 302 /tomcat-app/;
    }

    # WebSocket configuration
    location /wstunnel/ {
        proxy_pass https://tomcat;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }
}
```

----------------------------------------

TITLE: Nginx: Combine IP Restriction and Basic Auth with satisfy all
DESCRIPTION: This Nginx configuration snippet shows how to combine IP-based access restriction with HTTP basic authentication using the `satisfy all` directive. Access is granted only if both the IP address is allowed AND the user is successfully authenticated against the specified htpasswd file. This ensures a higher level of security.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-http-basic-authentication.md#_snippet_6

LANGUAGE: nginx
CODE:
```
location /api {
    #...
    satisfy all;

    deny  192.168.1.2;
    allow 192.168.1.1/24;
    allow 127.0.0.1;
    deny  all;

    auth_basic           "Administrator’s Area";
    auth_basic_user_file conf/htpasswd;
}
```

----------------------------------------

TITLE: Optimizing HTTP Response Headers with `tcp_nopush` and `sendfile` in NGINX
DESCRIPTION: This NGINX configuration combines `sendfile` with `tcp_nopush` for the `/mp3` location. When `tcp_nopush` is enabled alongside `sendfile`, NGINX sends HTTP response headers in one packet immediately after the initial chunk of data has been obtained by `sendfile()`, improving network efficiency.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/serving-static-content.md#_snippet_8

LANGUAGE: nginx
CODE:
```
location /mp3 {
    sendfile   on;
    tcp_nopush on;
    #...
}
```

----------------------------------------

TITLE: Reload NGINX Configuration (nginx -s reload)
DESCRIPTION: This command instructs NGINX to gracefully reload its configuration. It reloads the new configuration without dropping active connections, making it suitable for applying changes in a production environment.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_7

LANGUAGE: none
CODE:
```
root# nginx -s reload
```

----------------------------------------

TITLE: Include Specific NGINX Configuration File
DESCRIPTION: Demonstrates how to use the `include` directive within the `http` block of the main `nginx.conf` file to incorporate a specific load balancing configuration file (either basic or enhanced).
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_8

LANGUAGE: nginx
CODE:
```
http {
    include conf.d/nodejs-(basic|enhanced).conf;
}
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: This command reloads the NGINX Plus configuration, applying any changes made to `nginx.conf` without stopping the NGINX service. This is the standard way to activate new configurations after testing them.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/geoip.md#_snippet_6

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Configure NGINX HTTPS Virtual Server for example.com
DESCRIPTION: This NGINX configuration defines a server block to handle HTTPS traffic on port 443 for 'example.com'. It specifies the SSL certificate and key paths, and includes recommended directives for SSL session caching and cipher preference to enhance security.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_8

LANGUAGE: nginx
CODE:
```
# In the 'http' block
server {
    listen 443 ssl;
    server_name example.com;

    ssl_certificate           /etc/nginx/ssl/server.crt;
    ssl_certificate_key       /etc/nginx/ssl/server.key;
    ssl_session_cache         shared:SSL:1m;
    ssl_prefer_server_ciphers on;
}
```

----------------------------------------

TITLE: Configuring OIDC Domain in NGINX for Microsoft Entra
DESCRIPTION: This NGINX configuration snippet updates the `oidc_domain` setting in `/etc/nms/nginx/oidc/openid_configuration.conf` to include your Microsoft Entra tenant domain. It maps the host to the OIDC domain, defaulting to a specified domain (e.g., 'f5.com') if no specific FQDN is matched. This is crucial for OIDC authentication with Microsoft Entra.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/admin-guide/authentication/oidc/microsoft-entra-automation.md#_snippet_0

LANGUAGE: Nginx
CODE:
```
...map $host $oidc_domain {
    SERVER_FQDN OIDC_DOMAIN;
    # replace with OIDC specific setting
    default "f5.com";
}
...
```

----------------------------------------

TITLE: NGINX Unit: Filter share by MIME types with negation and wildcards
DESCRIPTION: This configuration demonstrates how to filter files served by an NGINX Unit share based on their MIME types. It uses negation patterns to block JavaScript and CSS files, while allowing all other text-based MIME types via a wildcard. Additionally, specific video file types (.3gpp, .3gpp2) are permitted using a regex pattern.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/configuration.md#_snippet_85

LANGUAGE: json
CODE:
```
{
    "share": "/www/data/static$uri",
    "types": [
        "!text/javascript",
        "!text/css",
        "text/*",
        "~video/3gpp2?"
    ]
}
```

----------------------------------------

TITLE: Modifying OWASP CRS Rule for XSS Blocking
DESCRIPTION: Configuration snippet showing how to modify rules 941160 and 941320 in REQUEST-941-APPLICATION-ATTACK-XSS.conf to include REQUEST_URI for blocking XSS attempts in the URL.
SOURCE: https://github.com/nginx/documentation/blob/main/content/modsec-waf/admin-guide/nginx-plus-modsecurity-waf-owasp-crs.md#_snippet_12

LANGUAGE: nginx
CODE:
```
SecRule REQUEST_URI|REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/ ...
```

----------------------------------------

TITLE: Configure NGINX App Protect WAF Bot Anomaly Mitigation
DESCRIPTION: This JSON configuration snippet demonstrates how to override the default scores and actions for bot anomaly detection within an NGINX App Protect WAF policy. It sets specific score thresholds and actions for 'Suspicious HTTP Headers' and 'Invalid HTTP Headers' to customize bot defense behavior.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/common/anti-automation.md#_snippet_3

LANGUAGE: json
CODE:
```
{
    "policy": {
        "name": "bot_anomalies_and_signatures",
        "template": {
            "name": "POLICY_TEMPLATE_NGINX_BASE"
        },
        "applicationLanguage": "utf-8",
        "enforcementMode": "blocking",
        "bot-defense": {
            "mitigations": {
                "anomalies": [
                    {
                        "name": "Suspicious HTTP Headers",
                        "action": "alarm",
                        "scoreThreshold": 50
                    },
                    {
                        "name": "Invalid HTTP Headers",
                        "action": "block",
                        "scoreThreshold": 99
                    }
                ]
            }
        }
    }
}
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: This command is used to gracefully reload the NGINX configuration after making changes to the configuration file. It applies new settings without stopping the NGINX service.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/entra-id.md#_snippet_11

LANGUAGE: bash
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: JavaScript Module for Blue/Green Deployment Client Splitting
DESCRIPTION: This JavaScript module, `split.js`, exports a function `clients` that determines whether a client should be directed to a 'green' or 'blue' application variant. It uses an MD5 hash of a `variant` string and a `proportion` to distribute clients, facilitating blue/green deployments based on client addresses.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/news/2023/unit-1.30.0-released.md#_snippet_7

LANGUAGE: javascript
CODE:
```
function clients(variant, proportion) {
    var c = require('crypto');
    var i = c.createHash('md5').update(variant).digest().readInt16BE() + 32768;
    return (proportion * 65536) > i ? 'green' : 'blue';
}

export default { clients }
```

----------------------------------------

TITLE: NGINX Unit Route Actions Configuration Example
DESCRIPTION: This JSON configuration demonstrates how to define routes in NGINX Unit, applying different actions based on URI patterns. It includes examples for URI rewriting and passing to an application, serving static files with a fallback proxy, direct proxying to an HTTP server, and issuing HTTP redirects with a location.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/configuration.md#_snippet_57

LANGUAGE: json
CODE:
```
{
    "routes": [
        {
            "match": {
                "uri": [
                    "/v1/*",
                    "/v2/*"
                ]
            },

            "action": {
                "rewrite": "/app/$uri",
                "pass": "applications/app"
            }
        },
        {
            "match": {
                "uri": "~\\.jpe?g$"
            },

            "action": {
                "share": [
                    "/var/www/static$uri",
                    "/var/www/static/assets$uri"
                 ],

                "fallback": {
                     "pass": "upstreams/cdn"
                }
            }
        },
        {
            "match": {
                "uri": "/proxy/*"
            },

            "action": {
                "proxy": "http://192.168.0.100:80"
            }
        },
        {
            "match": {
                "uri": "/return/*"
            },

            "action": {
                "return": 301,
                "location": "https://www.example.com"
            }
        }
    ]
}
```

----------------------------------------

TITLE: Define NGINX Upstream Server Group
DESCRIPTION: This configuration defines an `upstream` block named `backend` within the `http` context. It lists three backend servers, `backend1.example.com` with a weight of 5, `backend2.example.com` with default weight, and `192.0.0.1` as a backup server. This group is used to distribute incoming HTTP traffic among these servers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-load-balancer.md#_snippet_0

LANGUAGE: nginx
CODE:
```
http {
    upstream backend {
        server backend1.example.com weight=5;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }
}
```

----------------------------------------

TITLE: Configuring HTTP Headers for Original IP Logging in NGINX
DESCRIPTION: This NGINX HTTP configuration snippet demonstrates how to set the X-Real-IP and X-Forwarded-For headers using the $proxy_protocol_addr variable. This ensures that the client's original IP address, received via the PROXY protocol, is correctly passed to upstream HTTP servers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/using-proxy-protocol.md#_snippet_4

LANGUAGE: Nginx
CODE:
```
http {
    proxy_set_header X-Real-IP       $proxy_protocol_addr;
    proxy_set_header X-Forwarded-For $proxy_protocol_addr;
}
```

----------------------------------------

TITLE: Configuring Azure Traffic Manager for NGINXaaS Failover (Terraform)
DESCRIPTION: This Terraform snippet configures an Azure Traffic Manager profile with a "Priority" routing method to direct traffic to either a primary or secondary NGINXaaS deployment. It defines a DNS configuration and a health monitor that probes the `/health` endpoint of the NGINXaaS instances, along with external endpoints for both primary and secondary deployments. This setup enables automatic DNS-based failover for high availability.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/disaster-recovery.md#_snippet_8

LANGUAGE: HCL
CODE:
```
resource "azurerm_traffic_manager_profile" "nginxaas_failover_monitor" {
  ...
  traffic_routing_method = "Priority" # Chooses one deployment or the other

  dns_config {
    # relative_name needs to be globally unique
    # <relative_name>.trafficmanager.net resolves to the public IP of either NGINXaaS deployment
    relative_name = "nginxaas-global-record"
    ttl           = 60
  }

  monitor_config {
    protocol                     = "HTTP"
    port                         = 80
    path                         = "/health" #endpoint implemented in NGINXaaS configuration
    interval_in_seconds          = 30
    timeout_in_seconds           = 9
    tolerated_number_of_failures = 3
  }
}

resource "azurerm_traffic_manager_external_endpoint" "primary" {
  name                = "nginx-primary"
  profile_id          = azurerm_traffic_manager_profile.nginxaas_failover_monitor.id
  priority            = 10 # Lower number results in higher priority
  target              = azurerm_nginx_deployment.primary_nginxaas_deployment.ip_address
}

resource "azurerm_traffic_manager_external_endpoint" "secondary" {
  name                = "nginx-secondary"
  profile_id          = azurerm_traffic_manager_profile.nginxaas_failover_monitor.id
  priority            = 20
  target              = azurerm_nginx_deployment.secondary_nginxaas_deployment.ip_address
}
```

----------------------------------------

TITLE: Configure NGINX Location Blocks for Proxying and Redirect
DESCRIPTION: This NGINX configuration snippet sets up two location blocks within a server block. The first proxies requests for '/tomcat-app/' to the 'tomcat' upstream group. The second redirects root requests ('/') to '/tomcat-app/', ensuring all traffic is funneled through the proxy.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_15

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
location /tomcat-app/ {
    proxy_pass http://tomcat;
}

location = / {
    return 302 /tomcat-app/;
}
```

----------------------------------------

TITLE: NGINX HTTPRoute Configuration for Initial Canary Traffic Split
DESCRIPTION: This YAML configuration for an HTTPRoute demonstrates how to implement an initial traffic split for a canary release. It directs 95% of incoming traffic to the 'my-app-old' backend and 5% to the 'my-app-new' backend, allowing for controlled testing of the new application version.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/how-to/upgrade-apps-without-downtime.md#_snippet_1

LANGUAGE: yaml
CODE:
```
- matches:
    - path:
        type: PathPrefix
        value: /
  backendRefs:
    - name: my-app-old
      port: 80
      weight: 95
    - name: my-app-new
      port: 80
      weight: 5
```

----------------------------------------

TITLE: Test NGINX Configuration Syntax
DESCRIPTION: This command tests the NGINX configuration file for syntactic validity before applying changes. It checks for errors and ensures the configuration is well-formed, preventing service disruptions from malformed configurations.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_22

LANGUAGE: none
CODE:
```
root# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

----------------------------------------

TITLE: Check NGINX Configuration Syntax
DESCRIPTION: This shell command is used to perform a syntax check on the NGINX configuration file. It helps identify any errors or misconfigurations before reloading the server, ensuring stability.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/installing-nginx/installing-nginx-plus.md#_snippet_27

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: Reloads the NGINX Plus configuration to apply changes without stopping the server, ensuring the new reverse proxy settings take effect.
SOURCE: https://github.com/nginx/documentation/blob/main/content/modsec-waf/admin-guide/nginx-plus-modsecurity-waf-installation-logging.md#_snippet_7

LANGUAGE: bash
CODE:
```
sudo nginx -s reload
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: Commands to gracefully reload NGINX, applying new configuration changes without stopping the service, ensuring continuous operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_11

LANGUAGE: none
CODE:
```
root# nginx -s reload
```

LANGUAGE: none
CODE:
```
root# service nginx reload
```

----------------------------------------

TITLE: Inspect NGINX Pod Status and Events
DESCRIPTION: Use `kubectl describe` to get detailed information about an NGINX Pod's current status, container details (image, ID, state, ports, mounts), and recent events, which is crucial for diagnosing why a Pod is not running or ready.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/troubleshooting.md#_snippet_16

LANGUAGE: shell
CODE:
```
kubectl describe pod <nginx-pod-name> -n <nginx-pod-namespace>
```

LANGUAGE: text
CODE:
```
Containers:
  nginx:
    Container ID:    containerd://0dd33fd358ba3b369de315be15b197e369342aba7aa8d3ea12e4455823fa90ce
    Image:           nginx-gateway-fabric/nginx:latest
    Image ID:        sha256:e5cb19bab49cbde6222df607a0946e1e00c1af767263b79ae36e4c69f8547f20
    Ports:           80/TCP, 9113/TCP
    Host Ports:      0/TCP, 0/TCP
    SeccompProfile:  RuntimeDefault
    State:           Running
      Started:       Thu, 24 Apr 2025 10:57:36 -0700
    Ready:           True
    Restart Count:   0
    Environment:     <none>
    Mounts:
      /etc/nginx-agent from nginx-agent (rw)
      /etc/nginx/conf.d from nginx-conf (rw)
      /etc/nginx/includes from nginx-includes (rw)
      /etc/nginx/main-includes from nginx-main-includes (rw)
      /etc/nginx/secrets from nginx-secrets (rw)
      /etc/nginx/stream-conf.d from nginx-stream-conf (rw)
      /var/cache/nginx from nginx-cache (rw)
      /var/lib/nginx-agent from nginx-agent-lib (rw)
      /var/log/nginx-agent from nginx-agent-log (rw)
      /var/run/nginx from nginx-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f9kph (ro)
      /var/run/secrets/ngf from nginx-agent-tls (rw)
      /var/run/secrets/ngf/serviceaccount from token (rw)
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  2m57s  default-scheduler  Successfully assigned default/gateway-nginx-85f7f6d7d-fx7q2 to kind-control-plane
  Normal  Pulled     2m54s  kubelet            Container image "nginx-gateway-fabric:latest" already present on machine
  Normal  Created    2m54s  kubelet            Created container: init
  Normal  Started    2m54s  kubelet            Started container init
  Normal  Pulled     2m53s  kubelet            Container image "nginx-gateway-fabric/nginx:latest" already present on machine
  Normal  Created    2m53s  kubelet            Created container: nginx
  Normal  Started    2m53s  kubelet            Started container nginx
```

----------------------------------------

TITLE: Backup and Restore NGINX Controller Configuration and Encryption Keys
DESCRIPTION: After installing NGINX Controller, back up the cluster config and encryption keys. These are needed for restoring the NGINX config database on a new installation. Use `cluster-config save` to back up and `cluster-config load` to restore.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/admin-guides/install/using-helper-script.md#_snippet_2

LANGUAGE: bash
CODE:
```
/opt/nginx-controller/helper.sh cluster-config save
```

LANGUAGE: bash
CODE:
```
/opt/nginx-controller/helper.sh cluster-config load <filename>
```

----------------------------------------

TITLE: Create HTTPRoutes for Coffee and Tea Applications
DESCRIPTION: This YAML manifest defines two Kubernetes HTTPRoute resources, 'coffee' and 'tea', associated with the 'gateway'. Each route specifies a hostname (`cafe.example.com`) and a path (`/coffee` or `/tea`) to direct traffic to the respective backend service on port 80.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/upstream-settings.md#_snippet_6

LANGUAGE: yaml
CODE:
```
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: coffee
spec:
  parentRefs:
    - name: gateway
      sectionName: http
  hostnames:
    - "cafe.example.com"
  rules:
    - matches:
        - path:
            type: Exact
            value: /coffee
      backendRefs:
        - name: coffee
          port: 80
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: tea
spec:
  parentRefs:
    - name: gateway
      sectionName: http
  hostnames:
    - "cafe.example.com"
  rules:
    - matches:
        - path:
            type: Exact
            value: /tea
      backendRefs:
        - name: tea
          port: 80
```

----------------------------------------

TITLE: Defining Basic NGINX Directives
DESCRIPTION: This snippet demonstrates basic, single-line NGINX directives. `user` sets the user and group credentials for worker processes, `error_log` configures the error log file path and logging level, and `worker_processes` specifies the number of worker processes NGINX will use.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/basic-functionality/managing-configuration-files.md#_snippet_0

LANGUAGE: nginx
CODE:
```
user             nobody;
error_log        logs/error.log notice;
worker_processes 1;
```

----------------------------------------

TITLE: Define NGINX Proxy Cache Path and Zone (HTTP Context)
DESCRIPTION: This NGINX configuration snippet, placed within the `http` block, defines the `proxy_cache_path` directive. It specifies the file system location for cached content, establishes a shared memory zone (`cache_oracle`) for storing cache keys, and sets the maximum size limits for both the key zone and the overall cache, crucial for efficient resource management.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_29

LANGUAGE: nginx
CODE:
```
# In the 'http' block
proxy_cache_path /var/oracle-cache/ keys_zone=cache_oracle:50m max_size=500m;
```

----------------------------------------

TITLE: Enable njs Module and Import Script in NGINX Configuration
DESCRIPTION: This NGINX configuration snippet demonstrates how to enable the `ngx_http_js_module` and import an njs script file named `http.js`. It then uses `js_content` to execute the `http.hello` function for requests to the root location. This setup allows NGINX functionality to be extended using JavaScript.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/njs-support.md#_snippet_0

LANGUAGE: nginx
CODE:
```
load_module modules/ngx_http_js_module.so;

http {
    js_import http.js;

    server {
        location / {
            js_content http.hello;
        }
    }
}
```

----------------------------------------

TITLE: NGINX location Directive Reference
DESCRIPTION: Documentation for the NGINX `location` directive, which defines configuration based on the request URI. It allows applying specific settings, such as `proxy_pass` and `health_check`, to requests matching a defined path.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_29

LANGUAGE: APIDOC
CODE:
```
location [modifier] uri {
  ...directives...
}
```

----------------------------------------

TITLE: Executing Terraform Configuration (Bash)
DESCRIPTION: These commands are used to initialize, plan, and apply the Terraform configuration. `terraform init` prepares the working directory, `terraform plan` shows the changes that will be applied, and `terraform apply --auto-approve` executes the planned changes without requiring manual confirmation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/disaster-recovery.md#_snippet_1

LANGUAGE: bash
CODE:
```
terraform init
terraform plan
terraform apply --auto-approve
```

----------------------------------------

TITLE: NGINX Configuration for SSL/TLS Termination
DESCRIPTION: This NGINX configuration demonstrates how to set up SSL/TLS termination. NGINXaaS decrypts incoming encrypted traffic on port 443 using the specified SSL certificate and key, then forwards the unencrypted traffic to the backend server.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/security-controls/certificates.md#_snippet_0

LANGUAGE: nginx
CODE:
```
http {
    upstream backend {
        server backend1.example.com:8000; # replace with your backend server address and port
    }

    server {
        listen 443 ssl;

        ssl_certificate /etc/nginx/ssl/example.crt;     # must match the Certificate path
        ssl_certificate_key /etc/nginx/ssl/example.key; # must match the Key path

        location / {
            proxy_pass http://backend;
        }
    }
}
```

----------------------------------------

TITLE: NGINX Full Configuration for Enhanced Tomcat Load Balancing
DESCRIPTION: This comprehensive NGINX configuration provides enhanced load balancing for Tomcat applications, including features like proxy caching, WebSocket handling, session persistence (sticky sessions), active health checks, and secure access to the NGINX Plus API. It sets up HTTP to HTTPS redirection and defines specific locations for application traffic, WebSocket tunnels, and API access.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_42

LANGUAGE: nginx
CODE:
```
proxy_cache_path /tmp/NGINX_cache/ keys_zone=backcache:10m;

# WebSocket configuration
map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

# Extract the data after the final period (.) in the
# JSESSIONID cookie and store it in the $route_cookie variable.
map $cookie_jsessionid $route_cookie {
    ~.+\.(?P<route>\w+)$ $route;
}

# Search the URL for a trailing jsessionid parameter, extract the
# data after the final period (.), and store it in
# the $route_uri variable.
map $request_uri $route_uri {
    jsessionid=.+\.(?P<route>\w+)$ $route;
}

# Application health checks
match tomcat_check {
    status 200;
    header Content-Type = text/html;
    body ~ "Apache Tomcat/8";
}

upstream tomcat {
    # Shared memory zone for application health checks, live activity
    # monitoring, and dynamic reconfiguration
    zone tomcat 64k;

    # List of Tomcat application servers
    server 10.100.100.11:8080 slow_start=30s;
    server 10.100.100.12:8080 slow_start=30s;

    # Session persistence based on the jvmRoute value in
    # the JSESSION ID cookie
    sticky route $route_cookie $route_uri;

    # Uncomment the following directive (and comment the preceding
    # 'sticky route' and JSESSIONID 'map' directives) for session
    # persistence based on the JSESSIONID
    #sticky learn create=$upstream_cookie_JSESSIONID
    #             lookup=$cookie_JSESSIONID
    #             zone=client_sessions:1m;
}

server {
    listen 80;
    server_name example.com;
    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
     }
}

server {
    listen 443 ssl;
    http2  on;

    server_name example.com;

    # Required for live activity monitoring of HTTPS traffic
    status_zone tomcat;

    ssl_certificate     /etc/nginx/ssl/example.com.crt;
    ssl_certificate_key /etc/nginx/ssl/example.com.key;
    ssl_session_cache         shared:SSL:1m;
    ssl_prefer_server_ciphers on;

    # Load balance requests for '/tomcat-app/' across Tomcat application
    # servers
    location /tomcat-app/ {
        proxy_pass http://tomcat;
        proxy_cache backcache;

        # Active health checks
        health_check interval=2s fails=1 passes=5 uri=/ match=tomcat_check;
    }

    # Return a 302 redirect to '/tomcat-app/' when user requests '/'
    location = / {
        return 302 /tomcat-app/;
    }

    # WebSocket configuration
    location /wstunnel/ {
        proxy_pass http://tomcat;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Secured access to the NGINX Plus API
    location /api {
        api write=on;
        allow 127.0.0.1; # Permit access from localhost
        deny all;        # Deny access from everywhere else
    }
}
```

----------------------------------------

TITLE: Test NGINX API with valid bearer token
DESCRIPTION: Sends a POST request to the test API including a valid JWT bearer token in the Authorization header. This demonstrates the policy allowing the request to proceed to the backend after successful introspection.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/tutorials/introspection-keycloak.md#_snippet_19

LANGUAGE: bash
CODE:
```
POST https://192.0.2.4/my/test/api
HEADERS:
  Authorization: 'Bearer <JWT_token>'
```

----------------------------------------

TITLE: Configure NGINX for HTTPS Session Optimization
DESCRIPTION: This NGINX configuration snippet demonstrates how to optimize HTTPS server performance by enabling SSL session caching and setting a session timeout. It also includes keepalive_timeout for persistent connections and basic SSL certificate directives.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/terminating-ssl-http.md#_snippet_6

LANGUAGE: nginx
CODE:
```
worker_processes auto;

http {
    ssl_session_cache   shared:SSL:10m;
    ssl_session_timeout 10m;

    server {
        listen              443 ssl;
        server_name         www.example.com;
        keepalive_timeout   70;

        ssl_certificate     www.example.com.crt;
        ssl_certificate_key www.example.com.key;
        ssl_protocols       TLSv1.2 TLSv1.3;
        ssl_ciphers         HIGH:!aNULL:!MD5;
        #...
    }
}
```

----------------------------------------

TITLE: NGINX Proxy Configuration for WebSocket Traffic
DESCRIPTION: This NGINX configuration demonstrates how to correctly proxy WebSocket traffic. It includes a `map` directive to dynamically set the `Connection` header based on the presence of the `Upgrade` header, and a `location` block that configures the proxy to use HTTP/1.1 and forward the necessary `Upgrade` and `Connection` headers. This setup is crucial for establishing and maintaining WebSocket connections through NGINX.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_16

LANGUAGE: nginx
CODE:
```
# In the 'http' block
map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

# In the 'server' block for HTTPS traffic
location /wstunnel/ {
    proxy_pass http://jboss;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;
}
```

----------------------------------------

TITLE: Returning 404 for Missing Files with `try_files` in NGINX
DESCRIPTION: This NGINX configuration demonstrates using `try_files` to attempt to serve the original URI, the URI with a trailing slash, or the URI with a `.html` extension. If none of these paths resolve to an existing file or directory, the directive returns a `404` Not Found status code directly.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/serving-static-content.md#_snippet_5

LANGUAGE: nginx
CODE:
```
location / {
    try_files $uri $uri/ $uri.html =404;
}
```

----------------------------------------

TITLE: Start NGINX Service (RHEL/CentOS)
DESCRIPTION: Starts the NGINX service using `systemctl`. This command activates the NGINX web server after installation and configuration.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/admin-guides/install/install-for-controller.md#_snippet_21

LANGUAGE: shell
CODE:
```
sudo systemctl start nginx
```

----------------------------------------

TITLE: NGINX: Dynamic DNS Resolution for HTTP Upstream Load Balancing
DESCRIPTION: This NGINX configuration snippet illustrates how to enable dynamic DNS resolution for upstream servers in an HTTP load balancing setup. It defines a DNS `resolver` and uses the `resolve` parameter with `server` directives to allow NGINX Plus to periodically re-resolve domain names, automatically updating the list of backend IP addresses without requiring a server reload or restart. The example also includes `zone` definition for shared memory and `least_conn` load balancing method.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-load-balancer.md#_snippet_17

LANGUAGE: nginx
CODE:
```
http {
    resolver 10.0.0.1 valid=300s ipv6=off;
    resolver_timeout 10s;
    server {
        location / {
            proxy_pass http://backend;
        }
    }
    upstream backend {
        zone backend 32k;
        least_conn;
        # ...
        server backend1.example.com resolve;
        server backend2.example.com resolve;
    }
}
```

----------------------------------------

TITLE: Install NGINX Instance Manager Helm Chart
DESCRIPTION: Deploys NGINX Instance Manager using Helm. This command sets the administrator password hash, specifies the chart repository, creates the namespace, and uses a custom values file. Remember to replace placeholders for password and values file path.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/deploy/kubernetes/deploy-using-helm.md#_snippet_7

LANGUAGE: shell
CODE:
```
helm install -n nms \
--set adminPasswordHash=$(openssl passwd -6 'YourPassword123#') \
nms nginx-stable/nms-hybrid \
--create-namespace \
-f <path-to-your-values.yaml> \
[--version <chart-version>] \
--wait
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: This shell command reloads the NGINX configuration to apply changes without stopping the service. It's necessary after modifying NGINX configuration files.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/use-cases/monitoring/enable-nginx-plus-api.md#_snippet_1

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Generate Certificate Signing Request (CSR) for NGINX using OpenSSL
DESCRIPTION: This section outlines the steps to create a private key and a Certificate Signing Request (CSR) file using OpenSSL, which can then be provided to a Certificate Authority (CA) for obtaining a signed certificate. It emphasizes the importance of not sharing private keys. Ensure openssl is installed and you are logged in as root.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_1

LANGUAGE: shell
CODE:
```
root# openssl genrsa -out ~/example.com.key 2048
```

LANGUAGE: shell
CODE:
```
root# cp ~/example.com.key secure-dir/example.com.key.backup
```

LANGUAGE: shell
CODE:
```
root# openssl req -new -sha256 -key ~/example.com.key -out ~/example.com.csr
```

----------------------------------------

TITLE: Test NGINX Plus Configuration Syntax
DESCRIPTION: Command to test the syntax of the NGINX Plus configuration file before reloading, ensuring no errors are present.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/http-substitutions-filter.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Shell: Reload NGINX Configuration
DESCRIPTION: This command reloads the NGINX configuration, applying any changes made to the configuration files without requiring a full server restart. This is essential for deploying new settings in a production environment.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/auth0.md#_snippet_10

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Example NGINX Gzip Compression Configuration
DESCRIPTION: An example of a complete gzip compression configuration block within a server context, including enabling gzip, specifying types, handling proxied requests, and setting minimum length.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/compression.md#_snippet_4

LANGUAGE: nginx
CODE:
```
server {
    gzip on;
    gzip_types      text/plain application/xml;
    gzip_proxied    no-cache no-store private expired auth;
    gzip_min_length 1000;
    ...
}
```

----------------------------------------

TITLE: NGINX Controller JWT Authentication Policy
DESCRIPTION: Explains the JWT authentication policy in F5 NGINX Controller, covering JWK sets, how clients present JWTs (HTTP header, query string, Bearer token, Cookie), the structure of a JWK set (Header, Payload, Signature), and supported JWT signature algorithms.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/services/available-policies.md#_snippet_1

LANGUAGE: APIDOC
CODE:
```
JWT Authentication Policy:
  Description: Validates clients using JSON Web Tokens (JWTs).
  Setup:
    - Requires a JSON Web Key (JWK) set to validate JWT signatures.
  JWK Set Structure:
    - Header: JSON object describing cryptographic operations (token type, signing algorithm).
    - Payload: Arbitrary sequence of messages.
    - Signature: Digital signature over Header and Payload.
  Credential Presentation Methods:
    - HTTP request header
    - Query string parameter
    - Bearer token (default NGINX Plus use case for JWT)
    - Cookie
  Authentication Process:
    - User/application logs in, authorization server returns JWT.
    - Application uses JWT to access protected API.
  Encoding:
    - Must use Base64URL encoding (handles padding and non-HTTP compliant characters).
  Supported JWT Signatures:
    - HS256, HS384, HS512
    - RS256, RS384, RS512
    - ES256, ES384, ES512
    - EdDSA (Ed25519 and Ed448 signatures) (1.15.7)
  Comparison with API Keys:
    - API keys: Convenient for testing, small-scale deployments.
    - JWTs: More appropriate for production use with external Identity Providers.
```

----------------------------------------

TITLE: NGINX Web Server and Reverse Proxy Feature Comparison
DESCRIPTION: Compares web server and reverse proxy functionalities across NGINX Open Source, NGINX Plus, and F5 NGINXaaS for Azure, including origin server, various proxy types, HTTP/2, gRPC, HTTP/2 server push, and HTTP/3 over QUIC.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/overview/feature-comparison.md#_snippet_2

LANGUAGE: APIDOC
CODE:
```
Web Server and Reverse Proxy Features:
  Origin server for static content:
    NGINX Open Source: Yes
    NGINX Plus: Yes
    F5 NGINXaaS for Azure: Yes
  Reverse proxy (HTTP, FastCGI, memcached, SCGI, uwsgi):
    NGINX Open Source: Yes
    NGINX Plus: Yes
    F5 NGINXaaS for Azure: Yes
  HTTP/2 gateway:
    NGINX Open Source: Yes
    NGINX Plus: Yes
    F5 NGINXaaS for Azure: Yes
  gRPC proxy:
    NGINX Open Source: Yes
    NGINX Plus: Yes
    F5 NGINXaaS for Azure: Yes
  HTTP/2 server push:
    NGINX Open Source: Yes
    NGINX Plus: Yes
    F5 NGINXaaS for Azure: Yes
  HTTP/3 over QUIC:
    NGINX Open Source: Yes
    NGINX Plus: Yes
    F5 NGINXaaS for Azure: Yes
```

----------------------------------------

TITLE: NGINX TLSRoute Hostname and Backend Configuration
DESCRIPTION: This YAML snippet defines the hostnames and backend references for a TLSRoute resource. It specifies that incoming TLS traffic for 'app.example.com' should be routed to the 'secure-app' service on port 8443. This configuration is a core component of the Kubernetes Gateway API for managing secure application traffic.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/tls-passthrough.md#_snippet_7

LANGUAGE: yaml
CODE:
```
hostnames:
- "app.example.com"
rules:
- backendRefs:
  - name: secure-app
    port: 8443
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: Reloads the NGINX Plus configuration to apply the changes made to the OpenID Connect setup without restarting the server.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/oidc-njs/auth0.md#_snippet_5

LANGUAGE: bash
CODE:
```
sudo nginx -s reload
```

----------------------------------------

TITLE: Implementing 301 Permanent Redirect in NGINX
DESCRIPTION: This example shows how to use the `return` directive to issue a 301 (Moved Permanently) HTTP redirect. When a request matches `/permanently/moved/url`, NGINX will redirect the client to the specified new URL, informing browsers and search engines of the permanent move.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/web-server.md#_snippet_9

LANGUAGE: nginx
CODE:
```
location /permanently/moved/url {
    return 301 http://www.example.com/moved/here;
}
```

----------------------------------------

TITLE: Complete NGINX Plus Keycloak OIDC Integration Example
DESCRIPTION: This comprehensive NGINX configuration example demonstrates a full setup for integrating NGINX Plus with Keycloak for OIDC authentication. It includes DNS resolver configuration, OIDC provider definition, SSL setup, location protection with claim forwarding, and a simple test backend application.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/keycloak.md#_snippet_11

LANGUAGE: nginx
CODE:
```
http {
    # Use a public DNS resolver for Issuer discovery, etc.
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider keycloak {
        # The 'issuer' typically matches your Keycloak realm's base URL:
        # For example: https://<keycloak-server>/realms/<realm_name>
        issuer https://<keycloak-server>/realms/master;

        # Replace with your actual Keycloak client_id and secret
        client_id <client_id>;
        client_secret <client_secret>;

        # If the .well-known endpoint can’t be derived automatically,
        # specify config_url:
        # config_url https://<keycloak-server>/realms/master/.well-known/openid-configuration;
    }

    server {
        listen 443 ssl;
        server_name demo.example.com;

        ssl_certificate /etc/ssl/certs/fullchain.pem;
        ssl_certificate_key /etc/ssl/private/key.pem;

        location / {
            # Protect this location with Keycloak OIDC
            auth_oidc keycloak;

            # Forward OIDC claims as headers if desired
            proxy_set_header sub $oidc_claim_sub;
            proxy_set_header email $oidc_claim_email;
            proxy_set_header name $oidc_claim_name;

            proxy_pass http://127.0.0.1:8080;
        }
    }

    server {
        # Simple test backend
        listen 8080;

        location / {
            return 200 "Hello, $http_name!\nEmail: $http_email\nSub: $http_sub\n";
            default_type text/plain;
        }
    }
}
```

----------------------------------------

TITLE: Deploy Secure Nginx Application on Kubernetes
DESCRIPTION: This Kubernetes manifest defines all necessary resources to deploy a secure Nginx application. It creates a Deployment for the Nginx pod, a Service to expose it, a ConfigMap for the Nginx server configuration (including SSL setup), and a Secret to store the TLS certificate and key. The application listens on port 8443 with SSL enabled.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/tls-passthrough.md#_snippet_0

LANGUAGE: yaml
CODE:
```
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
    spec:
      containers:
        - name: secure-app
          image: nginxdemos/nginx-hello:plain-text
          ports:
            - containerPort: 8443
          volumeMounts:
            - name: secret
              mountPath: /etc/nginx/ssl
              readOnly: true
            - name: config-volume
              mountPath: /etc/nginx/conf.d
      volumes:
        - name: secret
          secret:
            secretName: app-tls-secret
        - name: config-volume
          configMap:
            name: secure-config
---
apiVersion: v1
kind: Service
metadata:
  name: secure-app
spec:
  ports:
    - port: 8443
      targetPort: 8443
      protocol: TCP
      name: https
  selector:
    app: secure-app
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: secure-config
data:
  app.conf: |-
    server {
      listen 8443 ssl;
      listen [::]:8443 ssl;

      server_name app.example.com;

      ssl_certificate /etc/nginx/ssl/tls.crt;
      ssl_certificate_key /etc/nginx/ssl/tls.key;

      default_type text/plain;

      location / {
        return 200 "hello from pod \$hostname\n";
      }
    }
---
apiVersion: v1
kind: Secret
metadata:
  name: app-tls-secret
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURGRENDQWZ3Q0NRQ3EzQWxhdnJiaWpqQU5CZ2txaGtpRzl3MEJBUXNGQURCTU1Rc3dDUVlEVlFRR0V3SlYKVXpFTE1Ba0dBMVVFQ0F3Q1EwRXhGakFVQmdOVkJBY01EVk5oYmlCR2NtRnVZMmx6WTI4eEdEQVdCZ05WQkFNTQpEMkZ3Y0M1bGVHRnRjR3hsTG1OdmJUQWVGdzB5TURBek1qTXlNekl3TkROYUZ3MHlNekF6TWpNeU16SXdORE5hCk1Fd3hDekFKQmdOVkJBWVRBbFZUTVFzd0NRWURWUVFJREFKRFFURVdNQlFHQTFVRUJ3d05VMkZ1SUVaeVlXNWoKYVhOamJ6RVlNQllHQTFVRUF3d1BZWEJ3TG1WNFlXMXdiR1V1WTI5dE1JSUJJakFOQmdrcWhraUc5dzBCQVFFRgpBQU9DQVE4QU1JSUJDZ0tDQVFFQTJCRXhZR1JPRkhoN2VPMVlxeCtWRGMsM0czK1RIckxGVC83RFBRREJZM2t6Qy8KaGZaayt3OW1NNkQ1RU9uK2lpVlNhUWlQMm1aNFA3N29pR0dmd3JrNjJ0eEQ5cHphODM5NC9aSjF5Q0dXZ1QKK2NWUEVZbkxjQktzSTRMcktJZ21oWVIwUjNzWWRjR1JkSXJWUFZlNUVUQlk1Z1U0RGhhMDZOUEIraitmK0krWgphWGIvMlRBekJhNHozMWpIQzg2amVQeTFMdklGazFiY3I2cSsxRGR5eklxcWxkRDYvU3Q4Q2t3cDlOaDFCUGFhCktZZ1ZVd010UVBib2s1cFFmbVMrdDg4NHdSM0dTTEU4VkxRbzgyYnJhNUR3emhIamlzOTlJRGhzbUt0U3lWOXMKaWNJbXp5dHBnSXlhTS9zWEhRQU9KbVFJblFteWgyekd1WFhTQ0lkRGtRSURBUUFCTUEwR0NTcUdTSWIzRFFFQgpDd1VBQTRJQkFRQ0tsVkhOZ1k5VHZLaW9Xb0tvdllCdnNRMmYrcmFOOEJwdWNDcnRvRm15NUczcGIzU2lPTndaCkF2cnhtSm4vR3lsa3JKTHBpQVA1eUNBNGI2Y2lYMnRGa3pQRmhJVFZKRTVBeDlpaEF2WWZwTUFSdWVqM29HN2UKd0xwQk1iUnlGbHJYV29NWUVBMGxsV0JueHRQQXZYS2Y4SVZGYTRSSDhzV1JJSDB4M2hFdjVtQ3VUZjJTRTg0QwpiNnNjS3Z3MW9CQU5VWGxXRVZVYTFmei9rWWZBa1lrdHZyV2JUcTZTWGxodXRJYWY4WEYzSUMrL2x1b3gzZThMCjBBcEFQVE5sZ0JwOTkvcXMrOG9PMWthSmQ1TmV6TnlJeXhSdUtJMzlDWkxuQm9OYmkzdlFYY1NzRCtYU2lYT0cKcEVnTjNtci8xRms4OVZMSENhTnkyKzBqMjZ0eWpiclcKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
```

----------------------------------------

TITLE: Configure NGINX Basic Authentication for entire server with public exception
DESCRIPTION: This NGINX configuration applies HTTP Basic authentication to the entire server, using `conf/htpasswd` for user credentials. It then uses `auth_basic off` within the `/public/` location block to disable authentication for that specific path, allowing public access to `/public/` while the rest of the server remains protected.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-http-basic-authentication.md#_snippet_4

LANGUAGE: nginx
CODE:
```
server {
    ...
    auth_basic           "Administrator’s Area";
    auth_basic_user_file conf/htpasswd;

    location /public/ {
        auth_basic off;
    }
}
```

----------------------------------------

TITLE: Rust code for WASI HTTP proxy handler
DESCRIPTION: Provides the Rust source code for `src/lib.rs` that implements the `wasi::exports::http::incoming_handler::Guest` trait. This code handles incoming HTTP requests, constructs an outgoing response with custom headers, and writes a 'Hello' message to the response body.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/news/2024/wasm-component-model-part-2.md#_snippet_7

LANGUAGE: rust
CODE:
```
use wasi::http::types::{
   Fields, IncomingRequest, OutgoingBody, OutgoingResponse, ResponseOutparam,
};

wasi::http::proxy::export!(Component);

struct Component;

impl wasi::exports::http::incoming_handler::Guest for Component {
   fn handle(_request: IncomingRequest, response_out: ResponseOutparam) {

      let hdrs = Fields::new();
      let mesg = String::from("Hello, This is a Wasm Component using wasi/http:proxy!");
      let _try = hdrs.set(&"Content-Type".to_string(), &[b"plain/text".to_vec()]);
      let _try = hdrs.set(&"Content-Length".to_string(), &[mesg.len().to_string().as_bytes().to_vec()]);

      let resp = OutgoingResponse::new(hdrs);

      // Add the HTTP Response Status Code
      resp.set_status_code(200).unwrap();

      let body = resp.body().unwrap();
      ResponseOutparam::set(response_out, Ok(resp));

      let out = body.write().unwrap();
      out.blocking_write_and_flush(mesg.as_bytes()).unwrap();
      drop(out);

      OutgoingBody::finish(body, None).unwrap();
   }
}
```

----------------------------------------

TITLE: Configure NGINX Virtual Server for HTTPS Traffic
DESCRIPTION: This NGINX server block listens on port 443 for HTTPS requests to 'example.com'. It specifies the SSL certificate and key paths, and includes recommended directives for SSL session caching and preferred server ciphers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_12

LANGUAGE: nginx
CODE:
```
# In the 'http' block
server {
    listen 443 ssl;
    server_name example.com;

    ssl_certificate     /etc/nginx/ssl/example.com.crt;
    ssl_certificate_key /etc/nginx/ssl/example.com.key;
    ssl_session_cache   shared:SSL:1m;
    ssl_prefer_server_ciphers on;
}
```

----------------------------------------

TITLE: NGINX Gateway HTTPS Listener Configuration
DESCRIPTION: This YAML snippet defines the HTTPS listener configuration for an NGINX Gateway, specifying port 443, HTTPS protocol, TLS termination mode, and referencing a Kubernetes Secret 'cafe-secret' for the certificate.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/https-termination.md#_snippet_6

LANGUAGE: yaml
CODE:
```
- name: https
  port: 443
  protocol: HTTPS
  tls:
    mode: Terminate
    certificateRefs:
    - kind: Secret
      name: cafe-secret
      namespace: certificate
```

----------------------------------------

TITLE: Configure NGINX to Pass Custom Request Headers
DESCRIPTION: This NGINX configuration snippet demonstrates how to use the `proxy_set_header` directive to modify or add request headers like 'Host' and 'X-Real-IP' when proxying requests. It ensures that the proxied server receives the correct host and client IP information.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/reverse-proxy.md#_snippet_2

LANGUAGE: nginx
CODE:
```
location /some/path/ {
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_pass http://localhost:8000;
}
```

----------------------------------------

TITLE: Configuring NGINX Agent with nginx-agent.conf
DESCRIPTION: This configuration file (`nginx-agent.conf`) is used to statically set NGINX Agent parameters. It defines server connection details like `host` and `grpcPort` for the control plane, TLS settings for secure communication, logging preferences, NGINX-specific behaviors, data plane status reporting intervals, and metrics collection parameters. The file also includes settings for backoff strategies, NGINX configuration directories, internal queue size, and enabled extensions like `nginx-app-protect`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/agent/configuration/configuration-overview.md#_snippet_0

LANGUAGE: NGINX Config
CODE:
```
#
# /etc/nginx-agent/nginx-agent.conf
#
# Configuration file for NGINX Agent.
#
# This file tracks agent configuration values that are meant to be statically set. There
# are additional NGINX Agent configuration values that are set via the API and agent install script
# which can be found in /etc/nginx-agent/agent-dynamic.conf.

# specify the server grpc port to connect to
server:
  # host of the control plane
  host: <FQDN>
  grpcPort: 443
  backoff: # note: default values are prepopulated 
    initial_interval: 100ms # Add the appropriate duration value here, for example, "100ms" for 100 milliseconds, "5s" for 5 seconds, "1m" for 1 minute, "1h" for 1 hour
    randomization_factor: 0.10 # Add the appropriate float value here, for example, 0.10
    multiplier: 1.5 # Add the appropriate float value here, for example, 1.5
    max_interval: 1m # Add the appropriate duration value here, for example, "100ms" for 100 milliseconds, "5s" for 5 seconds, "1m" for 1 minute, "1h" for 1 hour
    max_elapsed_time: 0 # Add the appropriate duration value here, for example, "0" for indefinite "100ms" for 100 milliseconds, "5s" for 5 seconds, "1m" for 1 minute, "1h" for 1 hour
# tls options
tls:
  # enable tls in the nginx-agent setup for grpcs
  # default to enable to connect with secure connection but without client cert for mtls
  enable: true
  # controls whether the server certificate chain and host name are verified.
  # for production use, see instructions for configuring TLS
  skip_verify: false
log:
  # set log level (panic, fatal, error, info, debug, trace; default "info")
  level: info
  # set log path. if empty, don't log to file.
  path: /var/log/nginx-agent/
nginx:
  # path of NGINX logs to exclude
  exclude_logs: ""
  # Set to true when NGINX configuration should contain no warnings when performing a configuration apply (nginx -t is used to carry out this check)
  treat_warnings_as_errors: false # Default is false
# data plane status message / 'heartbeat'
dataplane:
  status:
    # poll interval for dataplane status - the frequency the NGINX Agent will query the dataplane for changes
    poll_interval: 30s
    # report interval for dataplane status - the maximum duration to wait before syncing dataplane information if no updates have been observed
    report_interval: 24h
metrics:
  # specify the size of a buffer to build before sending metrics
  bulk_size: 20
  # specify metrics poll interval
  report_interval: 1m
  collection_interval: 15s
  mode: aggregated
    backoff: # note: default values are prepopulated 
      initial_interval: 100ms # Add the appropriate duration value here, for example, "100ms" for 100 milliseconds, "5s" for 5 seconds, "1m" for 1 minute, "1h" for 1 hour
      randomization_factor: 0.10 # Add the appropriate float value here, for example, 0.10
      multiplier: 1.5 # Add the appropriate float value here, for example, 1.5
      max_interval: 1m # Add the appropriate duration value here, for example, "100ms" for 100 milliseconds, "5s" for 5 seconds, "1m" for 1 minute, "1h" for 1 hour
      max_elapsed_time: 0 # Add the appropriate duration value here, for example, "0" for indefinite "100ms" for 100 milliseconds, "5s" for 5 seconds, "1m" for 1 minute, "1h" for 1 hour

# OSS NGINX default config path
# path to aux file dirs can also be added
config_dirs: "/etc/nginx:/usr/local/etc/nginx"

# Internal queue size
queue_size: 100

extensions:
  - nginx-app-protect
```

----------------------------------------

TITLE: Configure NGINX Plus Sticky Learn Session Persistence
DESCRIPTION: This sophisticated method inspects requests and responses to find session identifiers, then 'learns' which upstream server corresponds to which session. Session information is kept server-side in a shared memory zone. Mandatory parameters include 'create' (how new sessions are created), 'lookup' (how existing sessions are found), and 'zone' (shared memory zone details).
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-load-balancer.md#_snippet_14

LANGUAGE: nginx
CODE:
```
upstream backend {
   server backend1.example.com;
   server backend2.example.com;
   sticky learn
       create=$upstream_cookie_examplecookie
       lookup=$cookie_examplecookie
       zone=client_sessions:1m
       timeout=1h;
}
```

----------------------------------------

TITLE: Configure NGINX Global Settings
DESCRIPTION: This NGINX configuration block defines essential global settings. It sets the user, worker processes, error log path, and PID file location, and configures event module parameters like worker connections, which are fundamental for NGINX operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_16

LANGUAGE: nginx
CODE:
```
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log info;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

# If using the standard configuration scheme, the 'http' block is usually placed here
```

----------------------------------------

TITLE: Handling Missing Files with `try_files` in NGINX
DESCRIPTION: This NGINX configuration uses the `try_files` directive to check for the existence of a file corresponding to the request URI. If the file is not found, it internally redirects the request to a default image file (`/images/default.gif`). The `root` directive defines the base path for file resolution.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/serving-static-content.md#_snippet_4

LANGUAGE: nginx
CODE:
```
server {
    root /www/data;

    location /images/ {
        try_files $uri /images/default.gif;
    }
}
```

----------------------------------------

TITLE: Get Detailed NGINX Gateway Fabric Pod Status
DESCRIPTION: Use the `kubectl describe` command to retrieve comprehensive information about a specific NGINX Gateway Fabric Pod. This command provides insights into the Pod's current state, including its image, status, and associated events, which are crucial for diagnosing startup or readiness problems.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/troubleshooting.md#_snippet_14

LANGUAGE: shell
CODE:
```
kubectl describe pod <ngf-pod-name> -n nginx-gateway
```

----------------------------------------

TITLE: Configuring NGINX Server with Multiple Locations for Static Files and Proxying
DESCRIPTION: This NGINX `server` block defines two `location` contexts. The first `location /images/` serves static files from the `/data` directory for URIs starting with `/images/`. The second `location /` acts as a fallback, proxying all other requests to `http://www.example.com`. This demonstrates how NGINX can handle different request types within a single virtual server.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/web-server.md#_snippet_7

LANGUAGE: nginx
CODE:
```
server {
    location /images/ {
        root /data;
    }

    location / {
        proxy_pass http://www.example.com;
    }
}
```

----------------------------------------

TITLE: Reloading NGINX Configuration (Bash)
DESCRIPTION: This command gracefully reloads the NGINX configuration without interrupting active connections. It sends a HUP signal to the NGINX master process, prompting it to re-read its configuration files and apply changes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/amplify/nginx-amplify-agent/configuring-metric-collection.md#_snippet_1

LANGUAGE: bash
CODE:
```
kill -HUP `cat /var/run/nginx.pid`
```

----------------------------------------

TITLE: Restore NGINX Controller Cluster Configuration
DESCRIPTION: Command to restore the NGINX Controller cluster configuration and encryption keys from a specified backup file. This is essential for recovering the NGINX config database on a new NGINX Controller installation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/admin-guides/install/install-nginx-controller.md#_snippet_8

LANGUAGE: bash
CODE:
```
/opt/nginx-controller/helper.sh cluster-config load <filename>
```

----------------------------------------

TITLE: Configure NGINX Plus Location Block for Reverse Proxying to Upstream Group
DESCRIPTION: This snippet adds a 'location' block within the 'server' block for HTTPS traffic. It configures NGINX Plus to proxy all incoming requests to the 'oracle' upstream group, ensuring the original 'Host' header is preserved for proper routing.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_22

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
location / {
     proxy_pass http://oracle;
     proxy_set_header Host $host;
}
```

----------------------------------------

TITLE: Configuring Keepalived VRRP Instance for NGINX Instance Manager (Shell)
DESCRIPTION: This snippet configures the `keepalived` service for high availability, defining a VRRP instance (`VI_28`) with a health check script, virtual IP address, and authentication. It specifies `MASTER` state for the primary server and requires placeholders like `<NETWORK_INTERFACE>`, `<AUTH_PASSWORD>`, and `<VIRTUAL_IP_ADDRESS>` to be replaced with actual network details.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/system-configuration/configure-high-availability.md#_snippet_3

LANGUAGE: sh
CODE:
```
vrrp_script nms_check_keepalived {
    script "/etc/nms/scripts/nms-check-keepalived.sh"
    interval 10
    weight 10
}

vrrp_instance VI_28 {
    state MASTER   # Set to BACKUP on the secondary server
    interface <NETWORK_INTERFACE>   # Replace with the correct network interface
    priority 100
    virtual_router_id 251
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass <AUTH_PASSWORD>   # Replace with a secure password
    }
    virtual_ipaddress {
        <VIRTUAL_IP_ADDRESS>   # Replace with your reserved VIP
    }
    track_script {
        nms_check_keepalived
    }
    notify /etc/nms/scripts/nms-notify-keepalived.sh
}
```

----------------------------------------

TITLE: Create secure-app Kubernetes Deployment, Service, ConfigMap, and Secret
DESCRIPTION: This YAML configuration creates a Kubernetes Deployment for a secure NGINX application, a Service to expose it, a ConfigMap for NGINX server configuration, and a Secret for TLS certificates. It sets up an NGINX server listening on port 8443 with SSL, serving a simple 'hello' message. The application uses an unprivileged NGINX image and mounts the TLS secret and configuration as volumes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-security/secure-backend.md#_snippet_0

LANGUAGE: yaml
CODE:
```
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
    spec:
      containers:
        - name: secure-app
          image: nginxinc/nginx-unprivileged:latest
          ports:
            - containerPort: 8443
          volumeMounts:
            - name: secret
              mountPath: /etc/nginx/ssl
              readOnly: true
            - name: config-volume
              mountPath: /etc/nginx/conf.d
      volumes:
        - name: secret
          secret:
            secretName: app-tls-secret
        - name: config-volume
          configMap:
            name: secure-config
---
apiVersion: v1
kind: Service
metadata:
  name: secure-app
spec:
  ports:
    - port: 8443
      targetPort: 8443
      protocol: TCP
      name: https
  selector:
    app: secure-app
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: secure-config
data:
  app.conf: |-
    server {
      listen 8443 ssl;
      listen [::]:8443 ssl;

      server_name secure-app.example.com;

      ssl_certificate /etc/nginx/ssl/tls.crt;
      ssl_certificate_key /etc/nginx/ssl/tls.key;

      default_type text/plain;

      location / {
        return 200 "hello from pod secure-app\n";
      }
    }
---
apiVersion: v1
kind: Secret
metadata:
  name: app-tls-secret
type: Opaque
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQwRENDQXJpZ0F3SUJBZ0lVVDQwYTFYd3doUHVBdDJNMkdZZUovYXluZlFBd0RRWUpLb1pJaHZjTkFRRUwKQlFBd1JqRWZNQjBHQTFVRUF3d1djMlZqZFhKbExXRndjQzVsZUdGdGNHeGxMbU52YlRFTE1Ba0dBMVVFQmhNQwpWVk14RmpBVUJnTlZCQWNNRFZOaGJpQkdjbUZ1YzJselkyOHdIaGNOTWpRd01URTRNVGd3TVRBeFdoY05NalV3Ck1URTNNVGd3TVRBeFdqQi9NUXN3Q1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0F3S1EyRnNhV1p2Y201cFlURVcKTUJRR0ExVUVCd3dOVTJGdUlFWnlZVzV6YVhOamJ6RU9NQXdHQTFVRUNnd0ZUa2RKVGxneEVqQVFCZ05WQkFzTQpDVTVIU1U1WUlFUmxkakVmTUIwR0ExVUVBd3dXYzJWamRYSmxMV0Z3Y0M1bGVHRnRjR3hsTG1OdmJUQ0NBU0l3CkRRWUpLb1pJaHZjTkFRRUJCUUFEZ2dFUEFEQ0NBUW9DZ2dFQkFMeUx0eURNbTZ4M0ZEUFJsOGZ0azNweCtrRWQKYTVpTGZOQ3lDbUVjYktBQVBDNEhZckl5b1B5QXpSTlJCMWErekE0UTlrbzJZRG5vR0dkeFJaMEdydldKZUV2Mgo3MWlHNGxhbHRVTS9WOWNvSktQY0UyTEI0R3R6cFA3ckdIWXNvRDlOUXFpV3YwZ0lOdE42MjdrWGg4UW41V1hYCk92Y2FkS2h0bjJER3RvU0VzT3dpNzR5NEt3SmFkWnlwLzJaM0hPakRTNjVIVmxydmUxUXpBMVRzTEp6S3cva3gKbHBSR0lWK0lhUjZXbXZsaVFVdDJxWFg0L3hGeVVEM2Vic05TeXpHUk5mQ0NOTWxlWlV3MTR3ZUdhOEVnc2tDcQprOGdYSmpFZXQxMlR4OGxkY3BpVWlxYVpkOStYZjJmUS8yL2Y5c1IzM3Q4K0VVUWpoZ2ZIbHlsLzV1RUNBd0VBCkFhTjlNSHN3SHdZRFZSMGpCQmd3Rm9BVTRUT096c1d0Q3ZWdGJlWXFSU0FqN2tXajFkb3dDUVlEVlIwVEJBSXcKQURBTEJnTlZIUThFQkFNQ0JQQXdJUVlEVlIwUkJCb3dHSUlXYzJWamRYSmxMV0Z3Y0M1bGVHRnRjR3hsTG1OdgpiVEFkQmdOVkhRNEVGZ1FVZmtWREFFWmIwcjRTZ2swck10a0FvQ2c2RjRnd0RRWUpLb1pJaHZjTkFRRUxCUUFECmdnRUJBQWFiQit6RzVSODl6WitBT2RsRy9wWE9nYjF6VkJsQ0dMSkhyYTl1cTMvcXRPR1VacDlnd2dZSWJ4VnkKUkVLbWVRa05pV0haSDNCSlNTZ3czbE9abGNxcW5xbUJ2OFAxTUxDZ3JqbDJSN1d2NVhkb2RlQkJxc0lvZkNxVgp3ZG51THJUU3RTbmd2MGhDcldBNlBmTnlQeXMzSGJva1k3RExNREhuNmhBQWcwMUNDT0pWWGpNZjFqLzNIMFNCClBQSWxtek5aRUpEd0JMR2hyb1V3aUY3NkNUV1Fudi8yc1pvWHMwUlFiRTY3TmNraXc2Z0svaWRwVTVzMmlkOEQKVExjVjNxenVFaE1ZeUlua0ZWNEJLZlFkTWxDQnE1QWdyU1Jqb2FoaCszbFRwYVpUalJGUGFVd3VZYXVsQXRzNgpra1ROaGltWWQ3Ym1aVk5MK2I0MzhmN1RMaGc9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0=
EOF
```

----------------------------------------

TITLE: NGINX Directive: location
DESCRIPTION: The `location` directive defines configuration based on a URI match. It's used to apply specific proxy settings, such as for WebSocket traffic, to a particular URL path.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_20

LANGUAGE: APIDOC
CODE:
```
Directive: location
Context: server, location
Purpose: Defines configuration for specific URI paths.
Usage: location [ = | ~ | ~* | ^~ ] uri { ... }
```

----------------------------------------

TITLE: Restrict NGINX API Access by IP Address
DESCRIPTION: This configuration snippet demonstrates how to restrict access to the NGINX API location (`/api`) to specific IP ranges (e.g., `192.168.1.0/24`) using the `allow` and `deny` directives, enhancing security.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/monitoring/live-activity-monitoring.md#_snippet_9

LANGUAGE: Nginx
CODE:
```
http {
    # ...
    server {
        listen 192.168.1.23;
        # ...
        location /api {
            api write=on;
            allow 192.168.1.0/24;
            deny  all;
        }
    }
}
```

----------------------------------------

TITLE: NGINX Plus Proxy Configuration with Live Monitoring API
DESCRIPTION: This NGINX Plus configuration demonstrates best practices for proxying HTTP and HTTPS traffic to upstream servers, including setting `Host` and `Connection` headers, using HTTP/1.1, and enabling health checks. It defines two upstream pools with sticky sessions and keepalive connections. A dedicated server block exposes the NGINX Plus API for live activity monitoring, allowing statistics to be consumed by APM tools.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/migrate-hardware-adc/f5-big-ip-configuration.md#_snippet_13

LANGUAGE: nginx
CODE:
```
upstream test_pool {
    zone test_pool_zone 64k;
    server 10.10.10.10:80;
    server 10.10.10.20:80;
    sticky cookie mysession expires=1h;
    keepalive 32;
}

upstream ssl_test_pool {
    zone ssl_test_pool_zone 64k;
    server 10.10.10.10:443;
    server 10.10.10.20:443;
    sticky cookie mysession expires=1h;
    keepalive 32;
}

server {
    listen 192.168.10.10:80 default_server;
    proxy_set_header Host $host;

    location / {
         proxy_pass http://test_pool;
         health_check;
         proxy_http_version 1.1;
    }

    location ~ /favicon.ico {
        root /usr/share/nginx/images;
    }
}

server {
    listen 192.168.10.10:443 ssl default_server;
    ssl_certificate     test.crt;
    ssl_certificate_key test.key;
    proxy_set_header    Host $host;

    location / {
        proxy_pass https://ssl_test_pool;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        health_check;
    }

    location ~ /favicon.ico {
        root /usr/share/nginx/images;
    }
}

server {
    listen 8080;
    status_zone status-page;
    root /usr/share/nginx/html;

    location /api {
        api write=on;
        # directives controlling access, such as 'allow' and 'deny'
    }

    location = /dashboard.html {
        root /usr/share/nginx/html;
    }

    # Redirect requests made to the old (pre-R14) dashboard
    location = /status.html {
        return 301 /dashboard.html;
    }

    location ~ /favicon.ico {
        root /usr/share/nginx/images;
    }
}
```

----------------------------------------

TITLE: NGINX Configuration for WebLogic Load Balancing and Health Checks
DESCRIPTION: This NGINX configuration sets up a reverse proxy with load balancing for WebLogic application servers. It includes active health checks, session persistence using JSESSIONID, HTTP to HTTPS redirection, SSL/TLS termination, HTTP/2 support, cache purging, WebSocket proxying, and secured access to the NGINX Plus API. It defines an upstream group for WebLogic servers and two server blocks for handling HTTP and HTTPS traffic.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_51

LANGUAGE: Nginx
CODE:
```
match health_check {
    status 200;
    header Content-Type = text/html;
    body ~ "Welcome To Dizzyworld";
}

upstream weblogic {
    # Shared memory zone for application health checks, live activity
    # monitoring, and dynamic reconfiguration
    zone weblogic 64k;

    # List of WebLogic Server application servers
    server 192.168.25.33:7001 slow_start=30s;
    server 192.168.25.69:7001 slow_start=30s;

    # Session persistence based on JSESSIONID
    sticky learn create=$upstream_cookie_JSESSIONID
                 lookup=$cookie_JSESSIONID
                 zone=client_sessions:1m;
}

server {
    listen 80;
    server_name example.com;

    # Required for live activity monitoring of HTTP traffic
    status_zone weblogic;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
     }
}

server {
    listen 443 ssl;
    http2  on;

    server_name example.com;

    # Required for live activity monitoring of HTTPS traffic
    status_zone weblogic-ssl;
    ssl_certificate     /etc/nginx/ssl/certificate-name;
    ssl_certificate_key /etc/nginx/ssl/private-key;
    ssl_session_cache shared:SSL:1m;
    ssl_prefer_server_ciphers on;

    # Load balance requests for '/weblogic-app/' across WebLogic Server
    # application servers
    location /weblogic-app/ {
        proxy_pass http://weblogic;
        proxy_cache backcache;

        # Enable purging of the content cache
        proxy_cache_purge $purge_method;

        # Active health checks
        health_check uri=/benefits match=health_check;
    }

    # Return a 302 redirect to '/weblogic-app/' when user requests '/'
    location = / {
        return 302 /weblogic-app/;
    }

    # WebSocket configuration
    location /wstunnel/ {
        proxy_pass http://weblogic;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Secured access to the NGINX Plus API
    location /api {
        api write=on;
        allow 127.0.0.1; # Permit access from localhost
        deny all;        # Deny access from everywhere else;
    }
}
```

----------------------------------------

TITLE: Reload NGINX Proxy Configuration
DESCRIPTION: This command reloads the NGINX proxy configuration, applying any changes made to the NGINX configuration files without stopping the server. It ensures new settings take effect immediately.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/system-configuration/secure-traffic.md#_snippet_12

LANGUAGE: bash
CODE:
```
sudo nginx -s reload
```

----------------------------------------

TITLE: Configure NGINX HTTP to HTTPS Redirect
DESCRIPTION: Sets up a server block to listen on port 80 for HTTP requests and permanently redirects them (301) to the corresponding HTTPS URL. This ensures all traffic is served over HTTPS without compromising security on backend servers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_19

LANGUAGE: nginx
CODE:
```
server {
     listen 80;
     status_zone oracle-http-redirect;
     return 301 https://$http_host$request_uri;
}
```

----------------------------------------

TITLE: Configure AWS Credentials in Terraform Provider
DESCRIPTION: Specify your AWS region, access key, and secret key in the `provider` block within `terraform/provider.tf` to enable Terraform to authenticate and manage resources in your AWS account.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/amazon-web-services/high-availability-network-load-balancer.md#_snippet_3

LANGUAGE: none
CODE:
```
provider "aws" {
  region = "us-west-1"
  access_key = ""
  secret_key = ""
}
```

----------------------------------------

TITLE: Redirect NGINX HTTP Traffic to HTTPS
DESCRIPTION: This NGINX server block listens on port 80 for HTTP requests and implements a permanent (301) redirect to the corresponding HTTPS URL. This ensures all unencrypted traffic is automatically upgraded to secure HTTPS connections.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_10

LANGUAGE: nginx
CODE:
```
# In the 'http' block
server {
    listen 80;
    server_name example.com;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}
```

----------------------------------------

TITLE: NGINX: Reload Configuration
DESCRIPTION: This command reloads the NGINX configuration file, applying any changes without stopping the NGINX service. It's a standard practice after modifying NGINX settings to ensure the new configuration takes effect efficiently.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/cognito.md#_snippet_8

LANGUAGE: nginx
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Create SSL/TLS Certificate Bundle .pem File
DESCRIPTION: This console command concatenates a leaf certificate, an optional CA certificate, and a private key into a single .pem file. This bundle is essential for configuring SSL/TLS listeners in NGINX Unit.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/certificates.md#_snippet_0

LANGUAGE: console
CODE:
```
cat cert.pem ca.pem key.pem > bundle.pem  # Leaf certificate file | CA certificate file | Private key file | Arbitrary certificate bundle's filename
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: This command reloads the NGINX configuration file, applying any changes without stopping the NGINX service. It's essential after modifying NGINX configuration files to ensure new settings take effect.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/ping-identity.md#_snippet_9

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Complete NGINX Plus Entra ID OIDC Integration Example
DESCRIPTION: This comprehensive NGINX configuration example summarizes all steps for integrating NGINX Plus with Entra ID OIDC. It includes essential settings such as DNS resolver, OIDC provider definition, SSL configuration, and proxying requests to an internal server with OIDC protection and claim forwarding.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/entra-id.md#_snippet_12

LANGUAGE: nginx
CODE:
```
http {
    # Use a public DNS resolver for Issuer discovery, etc.
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider entra {
        # The issuer is typically something like:
        # https://login.microsoftonline.com/<tenant_id>/v2.0
        issuer https://login.microsoftonline.com/<tenant_id>/v2.0;

        # Replace with your actual Entra client_id and client_secret
        client_id <client_id>;
        client_secret <client_secret>;
    }

    server {
        listen 443 ssl;
        server_name demo.example.com;

        ssl_certificate /etc/ssl/certs/fullchain.pem;
        ssl_certificate_key /etc/ssl/private/key.pem;

        location / {
            # Protect this location with Entra OIDC
            auth_oidc entra;

            # Forward OIDC claims as headers if desired
            proxy_set_header sub $oidc_claim_sub;
            proxy_set_header email $oidc_claim_email;
            proxy_set_header name $oidc_claim_name;

            proxy_pass http://127.0.0.1:8080;
        }
    }

    server {
        listen 8080;

        location / {
            return 200 "Hello, $http_username!\n Your email is $http_email\n Your unique id is $http_sub\n";
            default_type text/plain;
        }
    }
}
```

----------------------------------------

TITLE: Starting NGINX Service (Shell)
DESCRIPTION: This command immediately starts the NGINX service, activating NGINX Plus and any configured modules like App Protect DoS after installation or configuration changes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/deployment-guide/learn-about-deployment.md#_snippet_16

LANGUAGE: shell
CODE:
```
sudo systemctl start nginx
```

----------------------------------------

TITLE: Running NGINX Container with Defined Volumes (Shell)
DESCRIPTION: This shell command creates and runs a Docker container named mynginx4 in detached mode (-d) from the mynginx_image2 image. It maps port 80 of the host to port 80 of the container, making the NGINX server accessible, and ensures the volumes defined in the image are active.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/installing-nginx/installing-nginx-docker.md#_snippet_28

LANGUAGE: shell
CODE:
```
docker run --name mynginx4 -p 80:80 -d mynginx_image2
```

----------------------------------------

TITLE: Configure ACL Consumer Restriction Policy via API
DESCRIPTION: This JSON snippet illustrates how to set up an ACL policy to restrict access based on consumer client IDs or token claims. The 'lookupVariable' specifies the source for the restriction (e.g., 'client.id' for APIKey/Basic Auth or 'token.{claimKey}' for JWT/OAuth2). It defines both allowed and denied lists for consumer identifiers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/how-to/policies/api-access-control-lists.md#_snippet_1

LANGUAGE: json
CODE:
```
"policies": {
            "acl-consumer": [
                {
                    "action": {
                        "lookupVariable": "client.id",
                        "allow": ["allowed-user"],
                        "deny": ["denied-user"]
                    }
                }
            ]
        }
```

----------------------------------------

TITLE: Reload NGINX Configuration to Apply Changes
DESCRIPTION: Command to gracefully reload the NGINX Plus configuration. This applies new settings, such as enabling a dynamic module, without stopping the NGINX service, ensuring continuous operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/encrypted-session.md#_snippet_3

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Enable NGINX Access and Error Logging
DESCRIPTION: This NGINX configuration snippet demonstrates how to enable access and error logging within the 'http' block of the main NGINX configuration file. These logs are essential for capturing detailed information about request processing and errors, which is vital for troubleshooting communication issues.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/system-configuration/secure-traffic.md#_snippet_16

LANGUAGE: nginx
CODE:
```
# nginx.conf
http {
    ...
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;
    ...
}
```

----------------------------------------

TITLE: Build NGINX with App Protect WAF Docker Image
DESCRIPTION: This Dockerfile defines the steps to create a container image with NGINX Open Source and the NGINX App Protect WAF v5 module. It uses Oracle Linux 8 as the base, configures NGINX and App Protect YUM repositories using secrets for authentication, installs the modules, and sets up logging, port exposure, and the default NGINX command.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/v5/build-nginx-image-oss/build-oracle.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Base image
FROM oraclelinux:8

# Install NGINX OSS and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    dnf -y install wget ca-certificates yum-utils \
    && echo "[nginx-mainline]" > /etc/yum.repos.d/nginx.repo \
    && echo "name=nginx mainline repo" >> /etc/yum.repos.d/nginx.repo \
    && echo "baseurl=http://nginx.org/packages/mainline/centos/\$releasever/\$basearch/" >> /etc/yum.repos.d/nginx.repo \
    && echo "gpgcheck=1" >> /etc/yum.repos.d/nginx.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/nginx.repo \
    && echo "gpgkey=https://nginx.org/keys/nginx_signing.key" >> /etc/yum.repos.d/nginx.repo \
    && echo "module_hotfixes=true" >> /etc/yum.repos.d/nginx.repo \
    && echo "[app-protect-x-oss]" > /etc/yum.repos.d/app-protect-8-x-oss.repo \
    && echo "name=nginx-app-protect repo" >> /etc/yum.repos.d/app-protect-8-x-oss.repo \
    && echo "baseurl=https://pkgs.nginx.com/app-protect-x-oss/centos/8/\$basearch/" >> /etc/yum.repos.d/app-protect-8-x-oss.repo \
    && echo "sslclientcert=/etc/ssl/nginx/nginx-repo.crt" >> /etc/yum.repos.d/app-protect-8-x-oss.repo \
    && echo "sslclientkey=/etc/ssl/nginx/nginx-repo.key" >> /etc/yum.repos.d/app-protect-8-x-oss.repo \
    && echo "gpgcheck=0" >> /etc/yum.repos.d/app-protect-8-x-oss.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/app-protect-8-x-oss.repo \
    && dnf clean all \
    && dnf -y install app-protect-module-oss \
    && dnf clean all \
    && rm -rf /var/cache/dnf \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: Configure Nginx Location Blocks for Proxying and Redirects
DESCRIPTION: This Nginx configuration snippet, placed within a 'server' block for HTTPS traffic, defines two location blocks. The first block, `/weblogic-app/`, proxies requests to the 'weblogic' upstream group, enabling load balancing for a specific application path. The second block, `=`, redirects root requests to `/weblogic-app/` with a 302 temporary redirect, funneling all traffic to the load-balanced application.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_11

LANGUAGE: Nginx
CODE:
```
# In the 'server' block for HTTPS traffic
location /weblogic-app/ {
    proxy_pass http://weblogic;
}

location = / {
    return 302 /weblogic-app/;
}
```

----------------------------------------

TITLE: Configure NGINX HTTPS Virtual Server
DESCRIPTION: This NGINX configuration snippet defines a virtual server block that listens for HTTPS requests on port 443 for 'example.com'. It includes essential directives for specifying SSL certificate and key paths, along with recommended settings for SSL session caching and cipher preferences to secure client traffic.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_12

LANGUAGE: Nginx
CODE:
```
# In the 'http' block
server {
    listen 443 ssl;
    server_name example.com;

    ssl_certificate           /etc/nginx/ssl/<certificate-name>;
    ssl_certificate_key       /etc/nginx/ssl/<private-key>;
    ssl_session_cache         shared:SSL:1m;
    ssl_prefer_server_ciphers on;
 }
```

----------------------------------------

TITLE: Deploy Coffee Application in Kubernetes
DESCRIPTION: This YAML defines a Kubernetes Deployment for a 'coffee' application with two replicas and a corresponding Service to expose it internally. It uses the 'nginxdemos/nginx-hello:plain-text' image and sets up a service to route traffic to the pods.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/basic-routing.md#_snippet_0

LANGUAGE: yaml
CODE:
```
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coffee
spec:
  replicas: 2
  selector:
    matchLabels:
      app: coffee
  template:
    metadata:
      labels:
        app: coffee
    spec:
      containers:
      - name: coffee
        image: nginxdemos/nginx-hello:plain-text
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: coffee
spec:
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  selector:
    app: coffee
EOF
```

----------------------------------------

TITLE: Configure NGINX Stub Status Module for Basic Metrics
DESCRIPTION: This NGINX configuration block enables the stub status API on a specific location, allowing basic server activity metrics to be collected. It restricts access to localhost (127.0.0.1) for security, denying all other requests.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/use-cases/monitoring/enable-nginx-oss-stub-status.md#_snippet_0

LANGUAGE: nginx
CODE:
```
server {
    listen 127.0.0.1:8080;
    location /api {
        stub_status;
        allow 127.0.0.1;
        deny all;
    }
}
```

----------------------------------------

TITLE: Configure Health Checks for NGINX Plus
DESCRIPTION: This snippet demonstrates how to configure server health checks in NGINX Plus to verify backend server functionality. NGINX Plus places the health check in a `location` block. The BIG-IP LTM configuration for this feature was incomplete in the provided text.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/migrate-hardware-adc/f5-big-ip-configuration.md#_snippet_10

LANGUAGE: nginx
CODE:
```
upstream test_pool {
    server 10.10.10.10:80;
    server 10.10.10.20:80;
    keepalive 32;
}
```

----------------------------------------

TITLE: Configure NGINX HTTP Reverse Proxy with URI Replacement
DESCRIPTION: This NGINX configuration snippet demonstrates how to proxy requests for a specific path (`/some/path/`) to an HTTP server. The `proxy_pass` directive includes a URI (`/link/`), which replaces the part of the original request URI that matches the location parameter when forwarding the request to `http://www.example.com/link/`. For example, a request to `/some/path/page.html` will be proxied to `http://www.example.com/link/page.html`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/reverse-proxy.md#_snippet_0

LANGUAGE: nginx
CODE:
```
location /some/path/ {
    proxy_pass http://www.example.com/link/;
}
```

----------------------------------------

TITLE: Test NGINX Plus Configuration Syntax
DESCRIPTION: Execute this command in a terminal to verify the syntax and validity of the NGINX Plus configuration file (`nginx.conf`). A successful output confirms the configuration is correct.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/lua.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Complete gRPC Streaming IDL File Example
DESCRIPTION: Provides a full Protocol Buffer (proto3) IDL file demonstrating various gRPC streaming types: unary, client-streaming, server-streaming, and bidirectional streaming service definitions. It also includes the basic message structures for requests and replies used in these services.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/how-to/bidirectional-configuration.md#_snippet_3

LANGUAGE: proto
CODE:
```
syntax = "proto3";
package streaming;
service Greeter {
  rpc BothUnary (HelloRequest) returns (HelloReply) {}
  rpc ClientStreaming (stream HelloRequest) returns (HelloReply) {}
  rpc ServerStreaming (HelloRequest) returns (stream HelloReply) {}
  rpc BidirectionalStreaming (stream HelloRequest) returns (stream HelloReply) {}
}
message HelloRequest {
  string message = 1;
}
message HelloReply {
  string message = 1;
}
```

----------------------------------------

TITLE: Defining Pet and ApiResponse Schemas in OpenAPI
DESCRIPTION: This JSON snippet defines the data models for 'Pet' and 'ApiResponse' within an OpenAPI specification. It details the properties, their types (e.g., string, integer), formats (e.g., int32), descriptions, and enumeration values for the 'Pet' status. It also includes XML mapping information for both schemas.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/tutorials/oas-security-schemes.md#_snippet_25

LANGUAGE: json
CODE:
```
                "items": {
                  "$ref": "#/components/schemas/Tag"
                }
              },
              "status": {
                "type": "string",
                "description": "pet status in the store",
                "enum": [
                  "available",
                  "pending",
                  "sold"
                ]
              }
            },
            "xml": {
              "name": "pet"
            }
          },
          "ApiResponse": {
            "type": "object",
            "properties": {
              "code": {
                "type": "integer",
                "format": "int32"
              },
              "type": {
                "type": "string"
              },
              "message": {
                "type": "string"
              }
            },
            "xml": {
              "name": "##default"
            }
          }
        },
        "requestBodies": {
          "Pet": {
            "description": "Pet object that needs to be added to the store",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Pet"
                }
              },
              "application/xml": {
                "schema": {
                  "$ref": "#/components/schemas/Pet"
                }
              }
            }
          }
        }
```

----------------------------------------

TITLE: NGINX Full Configuration for Enhanced Node.js Load Balancing
DESCRIPTION: This comprehensive NGINX configuration sets up enhanced load balancing for Node.js application servers. It includes directives for proxy caching, WebSocket handling, active health checks, session persistence using sticky cookies, HTTP to HTTPS redirection, and secure access to the NGINX Plus API. The configuration also defines an upstream group for Node.js servers with slow start and uses HTTP/2 for secure connections.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_38

LANGUAGE: nginx
CODE:
```
proxy_cache_path /tmp/NGINX_cache/ keys_zone=backcache:10m;

map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

match nodejs_check {
    status 200;
    header Content-Type ~ "text/html";
    body ~ "Hello world";
}

upstream nodejs {
    # Health-monitored upstream groups must have a zone defined
    zone nodejs 64k;

    # List of Node.js application servers
    server 192.168.33.11:8080 slow_start=30s;
    server 192.168.33.12:8080 slow_start=30s;

    # Session persistence using sticky cookie
    sticky cookie srv_id expires=1h domain=.example.com path=/;
}

server {
    listen 80;
    server_name example.com;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}

server {
    listen 443 ssl;
    http2  on;

    server_name example.com;

    # Required for NGINX Plus to provide extended status information
    status_zone nodejs;

    ssl_certificate            /etc/nginx/ssl/certificate-name;
    ssl_certificate_key        /etc/nginx/ssl/private-key;
    ssl_session_cache          shared:SSL:1m;
    ssl_prefer_server_ciphers  on;

    # Return a 302 redirect to '/webapp/' when user requests '/'
    location = / {
        return 302 /webapp/;
    }

    # Load balance requests for '/webapp/' across Node.js app servers
    location /webapp/ {
        proxy_pass http://nodejs;
        proxy_cache backcache;
        # Set up active health checks
        health_check match=nodejs_check;
    }

    # WebSocket configuration
    location /wstunnel/ {
        proxy_pass https://nodejs;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Secured access to the NGINX Plus API
    location /api {
        api write=on;
        allow 127.0.0.1; # Permit access from localhost
        deny all;        # Deny access from everywhere else
    }
}
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: Commands to instruct NGINX to reload its configuration, applying recent changes without restarting the server. This ensures continuous service availability while updates are deployed.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_7

LANGUAGE: none
CODE:
```
root# nginx -s reload
```

LANGUAGE: none
CODE:
```
root# service nginx reload
```

----------------------------------------

TITLE: Building NGINX Image with Custom Content and Configuration (Dockerfile)
DESCRIPTION: This Dockerfile defines a custom NGINX image. It starts from the official NGINX base image, removes the default NGINX configuration file to prevent conflicts, and then copies custom content to /usr/share/nginx/html and custom configuration files to /etc/nginx from the build context.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/installing-nginx/installing-nginx-docker.md#_snippet_23

LANGUAGE: dockerfile
CODE:
```
FROM nginx
RUN rm /etc/nginx/conf.d/default.conf
COPY content /usr/share/nginx/html
COPY conf /etc/nginx
```

----------------------------------------

TITLE: Launching NGINX Open Source Container - Shell
DESCRIPTION: This command launches an NGINX Open Source instance in a Docker container. It names the container `mynginx1`, maps port 80 from the host to port 80 in the container, and runs the container in detached mode, allowing it to run in the background.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/installing-nginx/installing-nginx-docker.md#_snippet_15

LANGUAGE: sh
CODE:
```
docker run --name mynginx1 -p 80:80 -d nginx
```

----------------------------------------

TITLE: Create Simple NGINX Backend Test Application
DESCRIPTION: This NGINX server block defines a simple backend application listening on port 8080. It demonstrates how to retrieve and display OIDC claims passed as HTTP headers ("$http_name", "$http_email", "$http_sub") from the upstream proxy, confirming successful authentication and claim forwarding.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/ping-identity.md#_snippet_8

LANGUAGE: nginx
CODE:
```
# ...
server {
    listen 8080;

    location / {
        return 200 "Hello, $http_name!\nEmail: $http_email\nSub: $http_sub\n";
        default_type text/plain;
    }
}
```

----------------------------------------

TITLE: Pass OIDC Claims as Headers in NGINX
DESCRIPTION: This NGINX configuration shows how to extract OIDC claims (subject, email, name) from the ID token returned by Ping Identity and pass them as custom headers to the backend application using "proxy_set_header". This allows the application to access authenticated user information.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/ping-identity.md#_snippet_7

LANGUAGE: nginx
CODE:
```
# ...
location / {
     auth_oidc ping;

     proxy_set_header sub   $oidc_claim_sub;
     proxy_set_header email $oidc_claim_email;
     proxy_set_header name  $oidc_claim_name;

     proxy_pass http://127.0.0.1:8080;
}
# ...
```

----------------------------------------

TITLE: Update NGINX Temporary Path Directives for Kubernetes
DESCRIPTION: This snippet shows the essential NGINX configuration directives that need to be updated to specify writable temporary directories. These paths are crucial for NGINX operations when deployed in a Kubernetes environment with a read-only filesystem, ensuring NGINX can write necessary temporary files.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/nap-k8s-readonly-paths.md#_snippet_0

LANGUAGE: nginx
CODE:
```
pid        /tmp/nginx.pid;
...
http {
...
    # Temporary directories for kubernetes "readonlyfilesystem"
    client_body_temp_path /tmp/nginx-client-body;
    proxy_temp_path       /tmp/nginx-proxy;    
    fastcgi_temp_path     /tmp/nginx-fastcgi;    
    uwsgi_temp_path       /tmp/nginx-uwsgi;    
    scgi_temp_path        /tmp/nginx-scgi;
...
}
```

----------------------------------------

TITLE: NGINX Directive: map
DESCRIPTION: The `map` directive creates variables whose values depend on the values of other variables. In the context of WebSocket proxying, it's used to dynamically set the `Connection` header based on the presence of the `Upgrade` header.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_19

LANGUAGE: APIDOC
CODE:
```
Directive: map
Context: http
Purpose: Creates new variables based on values of other variables.
Usage: map <source_variable> <target_variable> {
  <value> <result>;
  ...
}
Example: map $http_upgrade $connection_upgrade {
  default upgrade;
  ''      close;
}
```

----------------------------------------

TITLE: Configure Keepalived for NGINX Plus HA
DESCRIPTION: Create the keepalived.conf file in /etc/keepalived to define VRRP instances, health checks for NGINX, and authentication between peers. This configuration ensures high availability by managing a virtual IP address (Elastic IP) that can fail over between instances.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/amazon-web-services/high-availability-keepalived.md#_snippet_3

LANGUAGE: conf
CODE:
```
vrrp_script chk_nginx_service {
    script "<path-to-health-check-script>"
    interval 3
    weight 50
}
vrrp_instance VI_1 {
    interface eth0
    priority <priority>
    virtual_router_id 51
    advert_int 1
    unicast_src_ip <internal-ip-address-of-instance>
    unicast_peer {
        <internal-ip-address-of-other-instance>
    }
    authentication {
        auth_type PASS
        auth_pass <password>
    }
    track_script {
        chk_nginx_service
    }
    notify "<path-to-notify-script>"
}
```

----------------------------------------

TITLE: Configure Delayed Pod Termination for Zero Downtime Upgrades in NGINX Gateway Fabric
DESCRIPTION: Steps to configure delayed pod termination for NGINX Gateway Fabric pods, enabling graceful connection closure and zero-downtime upgrades. This involves adding 'lifecycle: preStop' hooks with a 'sleep' command to both 'nginx' and 'nginx-gateway' container definitions within the 'values.yaml' file, and setting an appropriate termination grace period.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/install/upgrade-version.md#_snippet_12

LANGUAGE: yaml
CODE:
```
nginxGateway:
<...>
lifecycle:
    preStop:
    exec:
        command:
        - /usr/bin/gateway
        - sleep
        - --duration=40s # This flag is optional, the default is 30s

nginx:
<...>
lifecycle:
    preStop:
    exec:
        command:
        - /bin/sleep
        - "40"
```

----------------------------------------

TITLE: Enable HTTP/2 in NGINX Server Block
DESCRIPTION: This snippet shows how to enable HTTP/2 support within an NGINX server block for HTTPS traffic. It requires adding the `http2 on;` directive alongside the `listen` directive.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_38

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
listen 443 ssl;
http2  on;
```

----------------------------------------

TITLE: Configure NGINX Passive Health Checks with fail_timeout and max_fails
DESCRIPTION: This NGINX configuration snippet demonstrates how to set up passive health checks for upstream servers. It uses the `max_fails` and `fail_timeout` parameters within the `server` directive to define the conditions under which a server is marked unavailable and for how long, ensuring that failed servers are temporarily removed from the load-balanced group.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-health-check.md#_snippet_0

LANGUAGE: nginx
CODE:
```
upstream backend {
    server backend1.example.com;
    server backend2.example.com max_fails=3 fail_timeout=30s;
}
```

----------------------------------------

TITLE: NGINX Server Block for Basic JWT Authentication
DESCRIPTION: This NGINX configuration snippet sets up a server block to enable basic JWT authentication for a specific location. It defines the authentication realm, specifies a local JSON Web Key (JWK) file for signature verification, and configures a subrequest to fetch additional keys from a remote JWKS URI. A separate internal location handles the proxying of the JWKS endpoint.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/security-controls/jwt.md#_snippet_0

LANGUAGE: nginx
CODE:
```
server {
   listen 80;

   location / {
      auth_jwt "API";
      auth_jwt_key_file /srv/key.jwk;
      auth_jwt_key_request /_jwks_uri;
   }

   location = /_jwks_uri {
      proxy_pass https://login.microsoftonline.com/common/discovery/keys;
      subrequest_output_buffer_size 12k;
   }
}
```

----------------------------------------

TITLE: NGINX Basic Load Balancing Configuration
DESCRIPTION: This NGINX configuration block, intended for the `http` context, sets up basic load balancing for Node.js application servers. It includes a proxy cache path, maps HTTP upgrade headers for WebSockets, defines an upstream group with IP hash for session persistence, and configures two server blocks: one for HTTP to HTTPS redirection and another for HTTPS traffic handling, including load balancing for '/webapp/', WebSocket proxying for '/wstunnel/', and a temporary redirect for the root path.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_22

LANGUAGE: nginx
CODE:
```
proxy_cache_path /tmp/NGINX_cache/ keys_zone=backcache:10m;

map $http_upgrade $connection_upgrade {
    default upgrade;
    ' '     close;
}

upstream nodejs {
    # Use IP Hash for session persistence
    ip_hash;

    # List of Node.js application servers
    server 192.168.33.11:8080;
    server 192.168.33.12:8080;
}

server {
    listen 80;
    server_name example.com;

    # Redirect all HTTP requests to HTTPS
    location / {
        return 301 https://$server_name$request_uri;
    }
}

server {
    listen 443 ssl;
    http2  on;

    server_name example.com;

    ssl_certificate           /etc/nginx/ssl/certificate-name;
    ssl_certificate_key       /etc/nginx/ssl/private-key;
    ssl_session_cache         shared:SSL:1m;
    ssl_prefer_server_ciphers on;

    # Return a temporary redirect to '/webapp/' when user requests '/'
    location = / {
         return 302 /webapp/;
    }

    # Load balance requests for '/webapp/' across Node.js app servers
    location /webapp/ {
        proxy_pass http://nodejs;
        proxy_cache backcache;
    }

    # WebSocket configuration
    location /wstunnel/ {
        proxy_pass https://nodejs;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }
}
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: Reload the NGINX Plus configuration to apply changes and enable the newly configured module without restarting the server.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/passenger-open-source.md#_snippet_4

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: Command to apply new NGINX Plus configuration changes without stopping the server, enabling the newly installed module.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/set-misc.md#_snippet_4

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Configure NGINX Upstream Block for Application Servers
DESCRIPTION: This NGINX configuration snippet defines an `upstream` block named `upstream_app_pool` for load balancing. It lists the internal IP addresses of four application servers and includes a `sticky cookie` directive for session persistence. This block should be edited in `gce-all-active-lb.conf` on the load balancer instances.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/google-cloud-platform/high-availability-all-active.md#_snippet_26

LANGUAGE: nginx
CODE:
```
upstream upstream_app_pool {
    zone upstream-apps 64k;

    server 10.10.10.1;
    server 10.10.10.2;
    server 10.10.10.3;
    server 10.10.10.4;

    sticky cookie GCPPersist expires=300;
}
```

----------------------------------------

TITLE: Reload NGINX configuration
DESCRIPTION: Applies the new NGINX Plus configuration without stopping the server.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/nginscript.md#_snippet_8

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Separate Static and Dynamic Content Routes with Fallback
DESCRIPTION: Configures NGINX Unit routes to separate static and dynamic content. Requests for ".php" files are matched and passed to a "php-app", while all other requests attempt to serve from a "share" path for static assets, falling back to a "proxy" if the file is not found.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/configuration.md#_snippet_101

LANGUAGE: json
CODE:
```
{
      "routes": [
         {
            "match": {
                  "uri": "*.php"
            },

            "action": {
                  "pass": "applications/php-app"
            }
         },
         {
            "action": {
                  "share": "/www/php-app/assets/files$uri",
                  "fallback": {
                     "proxy": "http://127.0.0.1:9000"
                  }
            }
         }

      ],

      "applications": {
         "php-app": {
            "type": "php",
            "root": "/www/php-app/scripts/"
         }
      }
}
```

----------------------------------------

TITLE: Configure NGINX Plus for SSL/TLS Proxying
DESCRIPTION: This NGINX Plus configuration shows how to proxy SSL/TLS connections, where NGINX acts as a passthrough proxy for encrypted traffic to backend HTTPS servers. It includes client certificate authentication, protocol, and cipher suite enforcement for enhanced security.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/migrate-hardware-adc/f5-big-ip-configuration.md#_snippet_5

LANGUAGE: nginx
CODE:
```
upstream ssl_test_pool {
     server 10.10.10.10:443;
}

server {
     listen 192.168.10.10:443 ssl;
     ssl_certificate     /etc/nginx/ssl/test.crt;
     ssl_certificate_key /etc/nginx/ssl/test.key;

     location / {
         proxy_pass https://ssl_test_pool;
         proxy_ssl_certificate /etc/nginx/ssl/client.pem;
         proxy_ssl_certificate_key /etc/nginx/ssl/client.key;
         proxy_ssl_protocols TLSv1.2 TLSv1.3;
         proxy_ssl_ciphers HIGH:!aNULL:!MD5;
         proxy_ssl_trusted_certificate /etc/nginx/ssl/trusted_ca_cert.crt;
         proxy_ssl_verify on;
         proxy_ssl_verify_depth 2;
     }
}
```

----------------------------------------

TITLE: Create Certificate Signing Request (CSR) with openssl
DESCRIPTION: This command generates a SHA256-hashed Certificate Signing Request (CSR) file (`company.com.csr`) using the previously created private key. The CSR is then submitted to a Certificate Authority (CA) to obtain the actual SSL/TLS certificate.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_15

LANGUAGE: shell
CODE:
```
root# openssl req -new -sha256 -key ~/company.com.key -out ~/company.com.csr
```

----------------------------------------

TITLE: Configuring Secondary NGINXaaS Deployment and NGINX Configuration (Terraform)
DESCRIPTION: This Terraform snippet defines a secondary NGINXaaS deployment in Azure, including its network interface. It also configures the NGINX instance with a custom `nginx.conf` file, setting up worker processes, error logging, and an HTTP block with upstream backend servers and a `/health` endpoint for monitoring. This configuration is crucial for the secondary region's NGINXaaS instance to function correctly and be monitored by Azure Traffic Manager.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/disaster-recovery.md#_snippet_7

LANGUAGE: HCL
CODE:
```
resource "azurerm_nginx_deployment" "secondary_nginxaas_deployment" {
  name                = var.secondary_deployment_name
  resource_group_name = var.secondary_resource_group
  location            = "centralus"
  # ...
  network_interface {
    subnet_id = azurerm_subnet.secondary_subnet_1.id
  }
}

resource "azurerm_nginx_configuration" "secondary_nginxaas_config" {
  nginx_deployment_id = azurerm_nginx_deployment.secondary_nginxaas_deployment.id
  root_file           = "/etc/nginx/nginx.conf"

  config_file {
    content = base64encode(<<-EOT
user nginx;
worker_processes auto;
worker_rlimit_nofile 8192;
pid /run/nginx/nginx.pid;

events {
    worker_connections 4000;
}

error_log /var/log/nginx/error.log error;

http {
    upstream backend_servers {
        server <Upstream-1-private-ip>:80;
        server <Upstream-2-private-ip>:80;
        keepalive 16;
    }
    server {
        listen 80 default_server;
        # /health will be used for Azure Traffic Manager Profile
        location /health {
            return 200 'nginx proxy alive';
        }
        location / {
            proxy_pass http://backend_servers;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_next_upstream error timeout http_500;
            proxy_http_version 1.1;
            proxy_set_header   "Connection" "";
        }
    }
}
EOT
    )
    virtual_path = "/etc/nginx/nginx.conf"
  }
}
```

----------------------------------------

TITLE: NGINX App Protect DoS Docker Deployment (Ubuntu)
DESCRIPTION: This Dockerfile provides a comprehensive example for deploying NGINX Plus with NGINX App Protect DoS on Ubuntu (18.04, 20.04, 22.04, 24.04). It covers setting up the base image, copying license files, installing prerequisites, adding NGINX signing keys, configuring NGINX Plus and App Protect DoS repositories, installing packages, and setting up NGINX configuration and entrypoint.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/deployment-guide/learn-about-deployment.md#_snippet_161

LANGUAGE: Dockerfile
CODE:
```

ARG OS_CODENAME
# Where OS_CODENAME can be: bionic/focal/jammy/noble

FROM ubuntu:${OS_CODENAME}

# Download certificate, key, and JWT license from the customer portal (https://my.f5.com)
# and copy to the build context:
RUN mkdir -p /etc/ssl/nginx/
RUN mkdir -p /etc/nginx/
COPY nginx-repo.crt nginx-repo.key /etc/ssl/nginx/
COPY nginx-repo.crt license.jwt /etc/nginx/

# Install prerequisite packages:
RUN apt-get update && apt-get install -y apt-transport-https lsb-release ca-certificates wget gnupg2 ubuntu-keyring

# Download and add the NGINX signing key:
RUN wget -qO - https://cs.nginx.com/static/keys/nginx_signing.key | gpg --dearmor | tee /usr/share/keyrings/nginx-archive-keyring.gpg >/dev/null

# Add NGINX Plus and NGINX App Protect DoS repository:
RUN printf "deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] https://pkgs.nginx.com/plus/ubuntu `lsb_release -cs` nginx-plus\n" | tee /etc/apt/sources.list.d/nginx-plus.list
RUN printf "deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] https://pkgs.nginx.com/app-protect-dos/ubuntu `lsb_release -cs` nginx-plus\n" | tee /etc/apt/sources.list.d/nginx-app-protect-dos.list

# Download the apt configuration to `/etc/apt/apt.conf.d`:
RUN wget -P /etc/apt/apt.conf.d https://cs.nginx.com/static/files/90pkgs-nginx

# Update the repository and install the most recent version of the NGINX App Protect DoS package (which includes NGINX Plus):
RUN apt-get update && apt-get install -y app-protect-dos

# Remove nginx repository key/cert from docker
RUN rm -rf /etc/ssl/nginx

# Copy configuration files:
COPY nginx.conf /etc/nginx/
COPY entrypoint.sh /root/

CMD /root/entrypoint.sh && tail -f /dev/null
```

----------------------------------------

TITLE: Applying NginxGateway Configuration with kubectl
DESCRIPTION: This command attempts to apply an NginxGateway configuration from a YAML file. It is used to demonstrate the first step of validation, where the Kubernetes API server checks the resource against its OpenAPI schema.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/overview/resource-validation.md#_snippet_4

LANGUAGE: shell
CODE:
```
kubectl apply -f nginx-gateway-config.yaml
```

----------------------------------------

TITLE: Configure NGINX App Protect WAF Security Log Destination
DESCRIPTION: This NGINX configuration snippet demonstrates how to enable and configure security logging for NGINX App Protect WAF. It sets the `log_blocked` profile and directs logs to a syslog server, illustrating how to integrate WAF security logging within an NGINX `location` block.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v5/logging-overview/logs-overview.md#_snippet_0

LANGUAGE: nginx
CODE:
```
    ...
    location / {

        # NGINX App Protect WAF
        app_protect_enable on;
        app_protect_security_log_enable on;
        app_protect_security_log log_blocked syslog:server=log-server:514;

        proxy_pass http://127.0.0.1:8080/;
    }
```

----------------------------------------

TITLE: Reference Backend Configuration Policy API Request Body
DESCRIPTION: This comprehensive JSON snippet provides a full reference for the backend configuration policy API request body. It outlines various settings for connection management (e.g., `keepCacheConnectionAlive`, `connectTimeout`, `readTimeout`, `sendTimeout`), client body size (`clientMaxBodySize`), NTLM authentication (`enableNTLMAuthn`), load balancing algorithms (`loadBalancing`), request queuing (`queue`), buffering (`buffer`), and session cookie configurations (`sessionCookie`). This body is used in `POST` requests to configure API proxies.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/how-to/policies/http-backend-configuration.md#_snippet_14

LANGUAGE: JSON
CODE:
```
{
   "policies": {
      "backend-config": [
         {
            "action": {
               "targetBackendPolicyLabel" : "default",
               "keepCacheConnectionAlive": 32,
               "keepAliveRequests": 1000,
               "keepAliveTime": "1h",
               "keepAliveTimeout": "60s",
               "connectTimeout": "30s",
               "readTimeout": "30s",
               "sendTimeout": "30s",
               "clientMaxBodySize": "2m",
               "enableNTLMAuthn": false,
               "loadBalancing": {
                  "algorithm": "LEAST_CONN",
                  "leastTimeMeasurement": "HEADER",
                  "hashKey": "$request_uri",
                  "consistentHashing": true,
                  "randomTwo": true,
                  "randomMethod": "LEAST_CONN"
               },
               "queue": {
                  "maxNumberOfRequests": 10,
                  "timeOut": "60s"
               },
               "buffer": {
                  "number": 8,
                  "size": "8k"
               },
               "sessionCookie": {
                  "name": "auth_cookie",
                  "path": "/",
                  "expiresIn": "1h",
                  "domainName": ".example.com",
                  "httpOnly": true,
                  "secure": true,
                  "sameSite": "strict"
               }
            }
         }
      ]
   }
}
```

----------------------------------------

TITLE: Configure NGINX Plus Load Balancing for Backend Servers
DESCRIPTION: This NGINX Plus configuration defines an `upstream` block to list backend servers for load balancing. The `server` block then uses `proxy_pass` to distribute incoming requests to these backend servers, enabling basic load balancing.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/amazon-web-services/route-53-global-server-load-balancing.md#_snippet_14

LANGUAGE: nginx
CODE:
```
upstream backend-servers {
    server <public DNS name of Backend 1>; # Backend 1
    server <public DNS name of Backend 2>; # Backend 2
}
server {
    location / {
        proxy_pass http://backend-servers;
    }
}
```

----------------------------------------

TITLE: Creating Dedicated System User and Group for an Application
DESCRIPTION: This series of commands demonstrates how to create a dedicated system user and group for an application, deny interactive login for security, and add the user to their primary group. This practice enhances security by isolating app permissions.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/howto/security.md#_snippet_11

LANGUAGE: bash
CODE:
```
# useradd -M app_user  # Add user account without home directory
```

LANGUAGE: bash
CODE:
```
# groupadd app_group
```

LANGUAGE: bash
CODE:
```
# usermod -L app_user  # Deny interactive login
```

LANGUAGE: bash
CODE:
```
# usermod -a -G app_group app_user  # Add user to the group
```

----------------------------------------

TITLE: Configure NGINX Error Log File and Severity
DESCRIPTION: This snippet demonstrates how to change the default NGINX error log file path and set the minimum severity level for logged messages. By default, NGINX logs errors to /var/log/nginx/error.log with 'error' severity or higher.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nginxaas-azure/logging-config-error-logs.md#_snippet_0

LANGUAGE: nginx
CODE:
```
error_log /var/log/nginx/nginx-error.log emerg;
```

----------------------------------------

TITLE: Configure NGINX Plus for JSESSIONID-based Session Persistence
DESCRIPTION: This NGINX Plus configuration demonstrates how to set up JSESSIONID-based session persistence using the 'sticky learn' directive within an 'upstream' block. It ensures that client requests with a specific JSESSIONID cookie are consistently routed to the same backend server, improving user experience for stateful applications.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/migrate-hardware-adc/citrix-adc-configuration.md#_snippet_6

LANGUAGE: nginx
CODE:
```
upstream myapp {
    server 10.0.0.100:80;
    server 10.0.0.101:80;
    server 10.0.0.102:80;
    sticky learn create=$upstream_cookie_jsessionid
                 lookup=$cookie_jsessionid
                 zone=client_sessions:1m;
}
```

----------------------------------------

TITLE: Build NGINX Plus with App Protect WAF on UBI
DESCRIPTION: This Dockerfile defines a build process to create a container image for NGINX Plus, integrated with the NGINX App Protect WAF v5 module. It uses Red Hat Universal Base Image (UBI) and supports versions 7, 8, and 9, dynamically adjusting the package manager (yum/dnf) and repository names based on the UBI version. It requires NGINX repository certificates and keys as Docker build secrets for installation. The image exposes port 80 and sets NGINX to run in the foreground.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/v5/build-nginx-image-plus/build-rhel.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Supported UBI_VERSION's are 7/8/9
ARG UBI_VERSION=9

# Base Image
FROM registry.access.redhat.com/ubi${UBI_VERSION}/ubi

# Define the ARG again after FROM to use it in this stage
ARG UBI_VERSION

# Install NGINX Plus and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    PKG_MANAGER=dnf; \
    if [ "${UBI_VERSION}" = "7" ]; then \
        PKG_MANAGER=yum; \
        NGINX_PLUS_REPO="nginx-plus-7.4.repo"; \
    elif [ "${UBI_VERSION}" = "9" ]; then \
        NGINX_PLUS_REPO="plus-${UBI_VERSION}.repo"; \
    else \
        NGINX_PLUS_REPO="nginx-plus-${UBI_VERSION}.repo"; \
    fi \
    && $PKG_MANAGER -y install wget ca-certificates \
    && wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/dependencies.repo \
    && wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/${NGINX_PLUS_REPO} \
    && echo "[app-protect-x-plus]" > /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-plus.repo \
    && echo "name=nginx-app-protect repo" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-plus.repo \
    && echo "baseurl=https://pkgs.nginx.com/app-protect-x-plus/centos/${UBI_VERSION}/\$basearch/" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-plus.repo \
    && echo "sslclientcert=/etc/ssl/nginx/nginx-repo.crt" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-plus.repo \
    && echo "sslclientkey=/etc/ssl/nginx/nginx-repo.key" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-plus.repo \
    && echo "gpgcheck=0" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-plus.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-plus.repo \
    && $PKG_MANAGER clean all \
    && $PKG_MANAGER install -y app-protect-module-plus \
    && $PKG_MANAGER clean all \
    && rm -rf /var/cache/$PKG_MANAGER \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: Nginx GraphQL Policy with Custom Profiles and URL Mappings
DESCRIPTION: This JSON configuration defines a comprehensive Nginx policy named 'graphql_policy'. It includes two GraphQL profiles: a 'Default' profile and a 'My Custom Profile' with specific defense attributes. The configuration then associates these profiles with different URLs: the 'Default' profile is applied to '/graphql', and 'My Custom Profile' is applied to '/mygraphql', demonstrating how to enforce distinct GraphQL security policies based on the URL.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/common/associating-graphql-profiles.md#_snippet_0

LANGUAGE: json
CODE:
```
{
    "name": "graphql_policy",
    "template": {
        "name": "POLICY_TEMPLATE_NGINX_BASE"
    },
    "applicationLanguage": "utf-8",
    "caseInsensitive": false,
    "enforcementMode": "blocking",

    "graphql-profiles": [
        {
            "attackSignaturesCheck": true,
            "defenseAttributes": {
                "allowIntrospectionQueries": true,
                "maximumBatchedQueries": "any",
                "maximumQueryCost": "any",
                "maximumStructureDepth": "any",
                "maximumTotalLength": "any",
                "maximumValueLength": "any",
                "tolerateParsingWarnings": true
            },
            "description": "Default GraphQL Profile",
            "metacharElementCheck": true,
            "name": "Default",
            "responseEnforcement": {
                "blockDisallowedPatterns": false
            }
        },
        {
            "attackSignaturesCheck": true,
            "defenseAttributes": {
                "allowIntrospectionQueries": true,
                "maximumBatchedQueries": "any",
                "maximumQueryCost": "any",
                "maximumStructureDepth": "any",
                "maximumTotalLength": "400",
                "maximumValueLength": "any",
                "tolerateParsingWarnings": false
            },
            "description": "my custom Profile",
            "metacharElementCheck": true,
            "name": "My Custom Profile",
            "responseEnforcement": {
                "blockDisallowedPatterns": true,
                "disallowedPatterns": ["pattern1", "pattern2"]
            }
        }
    ],
    "urls": [
        {
            "$action": "delete",
            "method": "*",
            "name": "*",
            "protocol": "http",
            "type": "wildcard"
        },
        {
            "isAllowed": true,
            "name": "/graphql",
            "protocol": "http",
            "type": "explicit",
            "performStaging": false,
            "urlContentProfiles": [
                {
                    "contentProfile": {
                        "name": "Default"
                    },
                    "headerValue": "*",
                    "headerName": "*",
                    "headerOrder": "default",
                    "type": "graphql"
                }
            ]
        },
        {
            "isAllowed": true,
            "name": "/mygraphql",
            "protocol": "http",
            "type": "explicit",
            "performStaging": false,
            "urlContentProfiles": [
                {
                    "contentProfile": {
                        "name": "My Custom Profile"
                    },
                    "headerValue": "*",
                    "headerName": "*",
                    "headerOrder": "default",
                    "type": "graphql"
                }
            ]
        }
    ]
}
```

----------------------------------------

TITLE: Build NGINX Open Source Docker Image for Amazon Linux 2023
DESCRIPTION: This Dockerfile defines the steps to create a Docker image based on Amazon Linux 2023, installing NGINX Open Source and the NGINX App Protect WAF v5 module. It configures NGINX and App Protect repositories, handles certificate-based authentication for package downloads, exposes port 80, and sets the default NGINX command.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v5/admin-guide/deploy-on-docker.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Base image
FROM amazonlinux:2023

# Install NGINX OSS and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    yum -y install wget ca-certificates shadow-utils yum-utils \
    && echo "[nginx-mainline]" > /etc/yum.repos.d/nginx.repo \
    && echo "name=nginx mainline repo" >> /etc/yum.repos.d/nginx.repo \
    && echo "baseurl=http://nginx.org/packages/mainline/amzn/2023/\$basearch/" >> /etc/yum.repos.d/nginx.repo \
    && echo "gpgcheck=1" >> /etc/yum.repos.d/nginx.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/nginx.repo \
    && echo "gpgkey=https://nginx.org/keys/nginx_signing.key" >> /etc/yum.repos.d/nginx.repo \
    && echo "module_hotfixes=true" >> /etc/yum.repos.d/nginx.repo \
    && echo "priority=9" >> /etc/yum.repos.d/nginx.repo \
    && echo "[app-protect-x-oss]" > /etc/yum.repos.d/app-protect-oss.repo \
    && echo "name=nginx-app-protect repo" >> /etc/yum.repos.d/app-protect-oss.repo \
    && echo "baseurl=https://pkgs.nginx.com/app-protect-x-oss/amzn/2023/\$basearch/" >> /etc/yum.repos.d/app-protect-oss.repo \
    && echo "sslclientcert=/etc/ssl/nginx/nginx-repo.crt" >> /etc/yum.repos.d/app-protect-oss.repo \
    && echo "sslclientkey=/etc/ssl/nginx/nginx-repo.key" >> /etc/yum.repos.d/app-protect-oss.repo \
    && echo "gpgcheck=0" >> /etc/yum.repos.d/app-protect-oss.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/app-protect-oss.repo \
    && yum -y install app-protect-module-oss \
    && yum clean all \
    && rm -rf /var/cache/yum \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: Enable HTTP/2 Support in NGINX
DESCRIPTION: This snippet demonstrates how to enable HTTP/2 support for HTTPS traffic in NGINX. It adds the `http2 on;` directive within the `server` block, alongside the `listen` directive for SSL, to activate the HTTP/2 protocol.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_26

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
listen 443 ssl;
http2  on;
```

----------------------------------------

TITLE: Configure NGINX Plus Health Check in Location Block
DESCRIPTION: This snippet demonstrates how to add the `health_check` directive within a `location` block to enable out-of-band HTTP requests for monitoring server health. It configures NGINX Plus to send requests every 2 seconds to the specified URI, marking a server down after 1 failure and up after 5 passes, using a custom match definition.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_28

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
location /tomcat-app/ {
    proxy_pass http://tomcat;
    proxy_cache backcache;
    health_check interval=2s fails=1 passes=5 uri=/ match=tomcat_check;
}
```

----------------------------------------

TITLE: Configure NGINX Plus Sticky Cookie Session Persistence
DESCRIPTION: This method adds a session cookie to the first response, identifying the server. Subsequent requests with this cookie are routed to the same server. The example demonstrates setting the cookie name, expiration, domain, and path.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-load-balancer.md#_snippet_12

LANGUAGE: nginx
CODE:
```
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    sticky cookie srv_id expires=1h domain=.example.com path=/;
}
```

----------------------------------------

TITLE: Generated NGINX Configuration for Pattern-Based Cache Splitting
DESCRIPTION: This NGINX configuration file is generated from the provided JSON `desiredState` and implements the pattern-based cache splitting. It includes `map` directives to associate request URIs with specific cache zones, `proxy_cache_path` directives to define the physical cache locations and their properties, and a `location` block that dynamically selects the appropriate cache based on the `$request_uri`. It also sets up upstream servers and various proxy and header configurations.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/app-delivery/about-caching.md#_snippet_9

LANGUAGE: Nginx
CODE:
```
map $request_uri $cache_8de5273e13f731e283acbc999760c3e3 {
    ~.html$ app_centric_env|app|split_string|/tmp/hdd1;
    ~.mp4$ app_centric_env|app|split_string|/tmp/hdd2;
    default app_centric_env|app|split_string|/tmp/default;
}
proxy_cache_path /tmp/hdd1/app_centric_env|app|split_string| max_size=2G min_free=1m keys_zone=app_centric_env|app|split_string|/tmp/hdd1:10m purger=off inactive=1m;
proxy_cache_path /tmp/hdd2/app_centric_env|app|split_string| max_size=1g min_free=10k keys_zone=app_centric_env|app|split_string|/tmp/hdd2:50m purger=off inactive=1m;
proxy_cache_path /tmp/default/app_centric_env|app|split_string| max_size=2g min_free=10k keys_zone=app_centric_env|app|split_string|/tmp/default:30m purger=off inactive=1m;
upstream wg_http_0ace772a-0c68-4d01-a443-6e377d4f6133 {
    zone wg_http_0ace772a-0c68-4d01-a443-6e377d4f6133 160k;
    server 10.146.187.154:80;
    keepalive 64;
    keepalive_requests 100;
    keepalive_timeout 60s;
}
map $host $f5_published_api {
    default -;
}
server {
    server_name test.example.com;
    listen 80 reuseport;
    status_zone server_4d1ee345-cf08-354e-93dc-1c3a844a04e3;
    set $f5_gateway gw;
    f5_metrics_marker gateway $f5_gateway;
    set $f5_environment env;
    f5_metrics_marker environment $f5_environment;
    location / {
        error_log /dev/null;
        access_log off;
        proxy_cache $cache_8de5273e13f731e283acbc999760c3e3;
        set $f5_app app;
        f5_metrics_marker app $f5_app;
        set $f5_component split_string;
        f5_metrics_marker component $f5_component;
        proxy_set_header X-Forwarded-For $remote_addr;
        proxy_set_header Host $host;
        proxy_set_header Connection '';
        proxy_http_version 1.1;
        add_header Cache $upstream_cache_status;
        proxy_cache_valid any 1m;
        proxy_pass <http://wg_http_0ace772a-0c68-4d01-a443-6e377d4f6133;>
    }
}
```

----------------------------------------

TITLE: Verify Kubernetes Pods Deployment
DESCRIPTION: Check the status of deployed pods in the specified Kubernetes namespace to ensure they are running correctly.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v5/admin-guide/deploy-with-helm.md#_snippet_6

LANGUAGE: shell
CODE:
```
kubectl get pods -n <namespace>
```

----------------------------------------

TITLE: Extract Certificate from PFX using OpenSSL
DESCRIPTION: This command extracts only the certificate file from a PKCS#12 (.pfx) file. It does not extract the private key, resulting in a .crt file (e.g., company.com.crt).
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_18

LANGUAGE: shell
CODE:
```
root# openssl pkcs12 -in exported-cert.pfx -clcerts -nokeys -out company.com.crt
```

----------------------------------------

TITLE: Configure OIDC Provider Details in NGINX Plus
DESCRIPTION: Specify the `issuer` URL, `client_id`, and `client_secret` (if not using PKCE) within the `oidc_provider {}` context for Keycloak. This configures NGINX Plus to interact with the Identity Provider for authentication.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/keycloak.md#_snippet_5

LANGUAGE: nginx
CODE:
```
http {
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider keycloak {
        issuer        https://<keycloak-server>/realms/<realm_name>;
        client_id     <client_id>;
        client_secret <client_secret>;
    }

    # ...
}
```

----------------------------------------

TITLE: NGINX: Configure Upstream Server for Client Certificate Authentication
DESCRIPTION: This NGINX server block configuration snippet demonstrates how to configure an upstream server to require or optionally request client certificates for authentication. It uses `ssl_client_certificate` to specify the trusted CA certificate for client verification and `ssl_verify_client` to set the verification mode.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/securing-http-traffic-upstream.md#_snippet_6

LANGUAGE: nginx
CODE:
```
server {
    #...
    ssl_client_certificate /etc/ssl/certs/ca.crt;
    ssl_verify_client      optional;
    #...
}
```

----------------------------------------

TITLE: AWS IAM Policy for NGINX Controller on EC2
DESCRIPTION: This JSON policy defines the permissions required for an IAM role to allow NGINX Controller to manage AWS resources. It grants access to EC2, EBS, and Elastic Load Balancing (ELB) services, enabling operations like volume creation, security group management, and automatic ELB provisioning for the NGINX Controller cluster.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/admin-guides/install/resilient-cluster-aws.md#_snippet_0

LANGUAGE: json
CODE:
```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "autoscaling:DescribeAutoScalingGroups",
        "autoscaling:DescribeLaunchConfigurations",
        "autoscaling:DescribeTags",
        "ec2:DescribeInstances",
        "ec2:DescribeRegions",
        "ec2:DescribeRouteTables",
        "ec2:DescribeSecurityGroups",
        "ec2:DescribeSubnets",
        "ec2:DescribeVolumes",
        "ec2:CreateSecurityGroup",
        "ec2:CreateTags",
        "ec2:CreateVolume",
        "ec2:ModifyInstanceAttribute",
        "ec2:ModifyVolume",
        "ec2:AttachVolume",
        "ec2:AuthorizeSecurityGroupIngress",
        "ec2:CreateRoute",
        "ec2:DeleteRoute",
        "ec2:DeleteSecurityGroup",
        "ec2:DeleteVolume",
        "ec2:DetachVolume",
        "ec2:RevokeSecurityGroupIngress",
        "ec2:DescribeVpcs",
        "elasticloadbalancing:AddTags",
        "elasticloadbalancing:AttachLoadBalancerToSubnets",
        "elasticloadbalancing:ApplySecurityGroupsToLoadBalancer",
        "elasticloadbalancing:CreateLoadBalancer",
        "elasticloadbalancing:CreateLoadBalancerPolicy",
        "elasticloadbalancing:CreateLoadBalancerListeners",
        "elasticloadbalancing:ConfigureHealthCheck",
        "elasticloadbalancing:DeleteLoadBalancer",
        "elasticloadbalancing:DeleteLoadBalancerListeners",
        "elasticloadbalancing:DescribeLoadBalancers",
        "elasticloadbalancing:DescribeLoadBalancerAttributes",
        "elasticloadbalancing:DetachLoadBalancerFromSubnets",
        "elasticloadbalancing:DeregisterInstancesFromLoadBalancer",
        "elasticloadbalancing:ModifyLoadBalancerAttributes",
        "elasticloadbalancing:RegisterInstancesWithLoadBalancer",
        "elasticloadbalancing:SetLoadBalancerPoliciesForBackendServer",
        "elasticloadbalancing:AddTags",
        "elasticloadbalancing:CreateListener",
        "elasticloadbalancing:CreateTargetGroup",
        "elasticloadbalancing:DeleteListener",
        "elasticloadbalancing:DeleteTargetGroup",
        "elasticloadbalancing:DescribeListeners",
        "elasticloadbalancing:DescribeLoadBalancerPolicies",
        "elasticloadbalancing:DescribeTargetGroups",
        "elasticloadbalancing:DescribeTargetHealth",
        "elasticloadbalancing:ModifyListener",
        "elasticloadbalancing:ModifyTargetGroup",
        "elasticloadbalancing:RegisterTargets",
        "elasticloadbalancing:DeregisterTargets",
        "elasticloadbalancing:SetLoadBalancerPoliciesOfListener",
        "iam:CreateServiceLinkedRole",
        "kms:DescribeKey"
      ],
      "Resource": [
        "*"
      ]
    }
  ]
}
```

----------------------------------------

TITLE: Kubernetes HTTPRoute for Coffee Application
DESCRIPTION: This Kubernetes HTTPRoute resource defines how external traffic is routed to the 'coffee' application. It specifies a hostname 'cafe.example.com' and a path prefix match '/coffee', directing requests to the 'coffee' service on port 80.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/troubleshooting.md#_snippet_9

LANGUAGE: yaml
CODE:
```
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: coffee
spec:
  parentRefs:
    - name: gateway
      sectionName: http
  hostnames:
    - "cafe.example.com"
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /coffee
      backendRefs:
        - name: coffee
          port: 80
```

----------------------------------------

TITLE: Docker Compose Configuration for NGINX App Protect WAF v5
DESCRIPTION: Provides a comprehensive `docker-compose.yml` file to orchestrate the deployment of NGINX, WAF Enforcer, and WAF Config Manager services. This configuration includes image names, volume mounts for shared configurations, network definitions, and port mappings, facilitating a multi-service setup for NGINX App Protect WAF v5. Remember to replace `5.4.0` with the actual release version.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v5/admin-guide/deploy-on-docker.md#_snippet_20

LANGUAGE: yaml
CODE:
```
services:
  nginx:
    container_name: nginx
    image: nginx-app-protect-5
    volumes:
      - app_protect_bd_config:/opt/app_protect/bd_config
      - app_protect_config:/opt/app_protect/config
      - app_protect_etc_config:/etc/app_protect/conf
      - /conf/nginx.conf:/etc/nginx/nginx.conf # based on the provided example
      - /conf/default.conf:/etc/nginx/conf.d/default.conf # based on the provided example
    networks:
      - waf_network
    ports:
      - "80:80"

  waf-enforcer:
    container_name: waf-enforcer
    image: "private-registry.nginx.com/nap/waf-enforcer:5.4.0"
    environment:
      - ENFORCER_PORT=50000
    volumes:
      - app_protect_bd_config:/opt/app_protect/bd_config
    networks:
      - waf_network
    restart: always

  waf-config-mgr:
    container_name: waf-config-mgr
    image: "private-registry.nginx.com/nap/waf-config-mgr:5.4.0"
    volumes:
      - app_protect_bd_config:/opt/app_protect/bd_config
      - app_protect_config:/opt/app_protect/config
      - app_protect_etc_config:/etc/app_protect/conf
    restart: always
    network_mode: none
    depends_on:
      waf-enforcer:
        condition: service_started

networks:
  waf_network:
    driver: bridge

volumes:
  app_protect_bd_config:
  app_protect_config:
  app_protect_etc_config:
```

----------------------------------------

TITLE: Mount Writable Volumes for NGINX Logs and Temporary Files in Kubernetes
DESCRIPTION: This YAML configuration shows how to define and mount writable `emptyDir` volumes for `/tmp` and `/var/log/nginx`, and a `persistentVolumeClaim` for `/etc/app_protect/bundles`, allowing NGINX and App Protect to write necessary data while maintaining a read-only root filesystem.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/nap-k8s-readonly-context.md#_snippet_1

LANGUAGE: yaml
CODE:
```
containers:
    - name: nginx
      ...
      volumeMounts:
           - name: app-protect-bd-config
             mountPath: /opt/app_protect/bd_config
           - name: app-protect-config
             mountPath: /opt/app_protect/config
           - name: tmp-volume
             mountPath: /tmp
           - name: nginx-log
             mountPath: /var/log/nginx
           - name: app-protect-bundles
             mountPath: /etc/app_protect/bundles
...

volumes:
        - name: app-protect-bd-config
          emptyDir: {}
        - name: app-protect-config
          emptyDir: {}
        - name: nginx-log
          emptyDir: {}
        - name: tmp-volume
          emptyDir: {}
        - name: app-protect-bundles
          persistentVolumeClaim:
            claimName: nap5-bundles-pvc
```

----------------------------------------

TITLE: Configure SSL Certificates for NGINX Plus mTLS Reporting
DESCRIPTION: Shows how to specify SSL protocols, ciphers, client certificate, and private key within the `mgmt` block for secure mutual TLS (mTLS) communication with NGINX Instance Manager.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nginx-plus/usage-tracking/agentless-reporting.md#_snippet_1

LANGUAGE: nginx
CODE:
```
mgmt {
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers   DEFAULT;

    ssl_certificate     client_cert.pem;
    ssl_certificate_key client_cert.key;
    #...
}
```

----------------------------------------

TITLE: NGINX Correlation ID Headers Configuration
DESCRIPTION: Provides guidance on configuring a custom correlation ID header in NGINX. This header, often named 'x-correlation-id', typically uses the `$request_id` value but can be overridden by a specific value present in the incoming request header, aiding in request tracing across services.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/how-to/policies/proxy-response-headers.md#_snippet_6

LANGUAGE: NGINX
CODE:
```
Header: <correlation-id-header-name>
  Example: x-correlation-id: 26fd65ab0bbe36e546e3da14f4aea89f
  Directive: add_header <correlation-id-header-name> <correlation-id> [always]
  Description: There must also be a request-correlation-id policy that will tell you the header name that gets used. The correlation id value is usually the $request_id but there is logic that that can be overridden by a specific value in the request header itself.
```

----------------------------------------

TITLE: Configure NGINX Plus Mandatory and Persistent Health Checks with Slow Start
DESCRIPTION: This NGINX configuration demonstrates how to set up an upstream group with a server using `slow_start` and a location block that applies `mandatory` and `persistent` health checks. New servers added to `my_upstream` will be marked unhealthy until they pass checks, then gradually receive traffic over 30 seconds. The `persistent` flag ensures their health state is remembered across configuration reloads, preventing re-checks if the server was healthy before a reload.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-health-check.md#_snippet_12

LANGUAGE: nginx
CODE:
```
upstream my_upstream {
    zone   my_upstream 64k;
    server backend1.example.com slow_start=30s;
}

server {
    location / {
        proxy_pass   http://my_upstream;
        health_check mandatory persistent;
    }
}
```

----------------------------------------

TITLE: Create Azure Private Link Service
DESCRIPTION: Creates an Azure Private Link service, associating it with a Standard Load Balancer's frontend IP configuration, enabling private access to the application hosted behind the load balancer.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/security-controls/private-link-to-upstreams.md#_snippet_6

LANGUAGE: bash
CODE:
```
$ az network private-link-service create \
    --resource-group $APP_RESOURCE_GROUP \
    --name private-link-service \
    --vnet-name $APP_VNET_NAME \
    --subnet $APP_SUBNET_NAME \
    --lb-name load-balancer \
    --lb-frontend-ip-configs frontend \
    --location $APP_LOCATION
```

----------------------------------------

TITLE: Configure NGINX Unit for URI-Based Application Selection
DESCRIPTION: This NGINX Unit JSON configuration illustrates how to dynamically select applications based on the request URI. By setting the `pass` directive to `applications$uri`, Unit routes incoming requests to applications whose names match the URI, enabling a flexible way to serve different applications from a single listener.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/configuration.md#_snippet_62

LANGUAGE: json
CODE:
```
{
      "listeners": {
         "*:80": {
            "pass": "applications$uri"
         }
      },

      "applications": {
         "blog": {
            "root": "/path/to/blog_app/",
            "script": "index.php"
         },

         "sandbox": {

```

----------------------------------------

TITLE: Dockerfile for NGINX App Protect WAF on Ubuntu
DESCRIPTION: This Dockerfile provides instructions for building a Docker image with NGINX App Protect WAF on Ubuntu (20.04, 22.04, or 24.04). It covers installing prerequisite packages, downloading and adding NGINX signing keys, and adding the NGINX Plus repository.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v4/admin-guide/install.md#_snippet_102

LANGUAGE: dockerfile
CODE:
```
ARG OS_CODENAME
# Where OS_CODENAME can be: focal/jammy/noble
# syntax=docker/dockerfile:1
# For Ubuntu 20.04 / 22.04 / 24.04:
FROM ubuntu:${OS_CODENAME}

# Install prerequisite packages:
RUN apt-get update && apt-get install -y apt-transport-https lsb-release ca-certificates wget gnupg2

# Download and add the NGINX signing keys:
RUN wget -qO - https://cs.nginx.com/static/keys/nginx_signing.key | \
    gpg --dearmor | tee /usr/share/keyrings/nginx-archive-keyring.gpg >/dev/null
RUN wget -qO - https://cs.nginx.com/static/keys/app-protect-security-updates.key | \
    gpg --dearmor | tee /usr/share/keyrings/app-protect-security-updates.gpg >/dev/null

# Add NGINX Plus repository:
RUN printf "deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \
    https://pkgs.nginx.com/plus/ubuntu `lsb_release -cs` nginx-plus\n" | \
    tee /etc/apt/sources.list.d/nginx-plus.list
```

----------------------------------------

TITLE: Nginx Unit Configuration for App Internals and Security
DESCRIPTION: This JSON configuration snippet demonstrates how to secure web application internals within Nginx Unit. It defines routing rules to prevent direct access to sensitive files (e.g., .ini, hidden files, temporary files) and directories, while correctly serving static content and routing PHP requests to the application. This configuration should be combined with proper file system permissions for comprehensive security.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/howto/security.md#_snippet_25

LANGUAGE: json
CODE:
```
{
         "routes": {
            "app": [
               {
                     "match": {
                        "uri": [
                           "*.php",
                           "*.php/*"
                        ]
                        /* Handles requests that target PHP scripts to avoid having them served as static files */
                     },

                     "action": {
                        "pass": "applications/app/direct"
                     }
               },
               {
                     "match": {
                        "uri": [
                           "!/sensitive/*",  /* Restricts access to a directory with sensitive data */
                           "!/data/*",  /* Restricts access to a directory with sensitive data */
                           "!/app_config_values.ini",  /* Restricts access to a specific file */
                           "!*/.*",  /* Restricts access to hidden files and directories */
                           "!*~"  /* Restricts access to temporary files */
                        ]
                        /* Protects files and directories best kept hidden */
                     },

                     "action": {
                        "share": "/path/to/app/static$uri",
                        /* Serves valid requests with static content | Path to the application's static file directory; use a real path in your configuration */

                        "types": [
                           "image/*",
                           "text/*",
                           "application/javascript"
                        ]
                        /* Limits file types served from the share */

                        "fallback": {
                           "pass": "applications/app/index"
                        }
                        /* Relays all requests not yet served to a catch-all app target */
                     }
               }
            ]
         }
   }
```

----------------------------------------

TITLE: Rewriting URIs with Regular Expressions and `break` Flag in NGINX
DESCRIPTION: This configuration snippet illustrates how to rewrite a request URI using a regular expression and the `rewrite` directive. It captures part of the original URI (`(.*)`) and uses it to construct a new URI (`/show?user=$1`), with the `break` flag stopping further `rewrite` processing within the current `location` context.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/web-server.md#_snippet_10

LANGUAGE: nginx
CODE:
```
location /users/ {
    rewrite ^/users/(.*)$ /show?user=$1 break;
}
```

----------------------------------------

TITLE: Build NGINX App Protect Docker Image
DESCRIPTION: Commands to build the Docker image for NGINX App Protect WAF, using '--secret' for secure handling of repository credentials. Includes examples for various Linux distributions (Oracle Linux/Debian/Ubuntu/Alpine/Amazon Linux) using 'docker build' and RHEL using 'podman build'. The '--no-cache' option ensures the installation of the latest version of NGINX Plus and NGINX App Protect WAF 4.x.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v4/admin-guide/install.md#_snippet_94

LANGUAGE: shell
CODE:
```
DOCKER_BUILDKIT=1 docker build --no-cache --platform linux/amd64 --secret id=nginx-crt,src=nginx-repo.crt --secret id=nginx-key,src=nginx-repo.key -t app-protect .
```

LANGUAGE: shell
CODE:
```
podman build --no-cache --secret id=nginx-crt,src=nginx-repo.crt --secret id=nginx-key,src=nginx-repo.key -t app-protect .
```

----------------------------------------

TITLE: Include Custom NGINX Configuration Directory
DESCRIPTION: Add the `include conf.d/*.conf;` directive to the main context of `/etc/nginx/nginx.conf`. This ensures that all custom configuration files created in the `conf.d` directory, such as `app.conf`, are loaded and applied by NGINX.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/setting-up-nginx-demo-environment.md#_snippet_3

LANGUAGE: nginx
CODE:
```
include conf.d/*.conf;
```

----------------------------------------

TITLE: NGINX App Protect Policy with Embedded JSON Schema Validation
DESCRIPTION: Illustrates an NGINX App Protect policy that embeds a JSON schema directly within its configuration. This policy associates the schema with a JSON profile (`reg_form_prof`) and applies it to POST requests on the `/register` URL, enforcing the schema's validation rules and triggering a `VIOL_JSON_SCHEMA` violation if non-compliant.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/common/handling-xml-and-json-content.md#_snippet_3

LANGUAGE: json
CODE:
```
{
    "policy": {
        "name": "json_form_policy_inline_schema",
        "template": {
            "name": "POLICY_TEMPLATE_NGINX_BASE"
        },
        "json-validation-files": [
            {
                "fileName": "person_schema.json",
                "contents": "{\r\n \"$schema\": \"http://json-schema.org/draft-07/schema#\",\r\n \"title\": \"Person\",\r\n \"type\": \"object\",\r\n \"properties\": {\r\n \"firstName\": {\r\n \"type\": \"string\",\r\n \"description\": \"The person's first name.\"\r\n },\r\n \"lastName\": {\r\n \"type\": \"string\",\r\n \"description\": \"The person's last name.\"\r\n },\r\n \"age\": {\r\n \"description\": \"Age in years which must be equal to or greater than zero.\",\r\n \"type\": \"integer\",\r\n \"minimum\": 0\r\n }\r\n }\r\n}"
            }
        ],
        "json-profiles": [
            {
                "name": "reg_form_prof",
                "defenseAttributes": {
                    "maximumArrayLength": "any",
                    "maximumStructureDepth": "any",
                    "maximumTotalLengthOfJSONData": 1000,
                    "maximumValueLength": "any",
                    "tolerateJSONParsingWarnings": false
                },
                "validationFiles": [
                    {
                        "isPrimary": true,
                        "jsonValidationFile": {
                            "fileName": "person_schema.json"
                        }
                    }
                ]
            }
        ],
        "urls": [
            {
                "name": "/register",
                "type": "explicit",
                "method": "POST",
                "attackSignaturesCheck": true,
                "clickjackingProtection": false,
                "disallowFileUploadOfExecutables": false,
                "isAllowed": true,
                "mandatoryBody": false,
                "methodsOverrideOnUrlCheck": false,
                "urlContentProfiles": [
                    {
                        "contentProfile": {
                            "name": "reg_form_prof"
                        },
                        "headerName": "*",
                        "headerOrder": "default",
                        "headerValue": "*",
                        "type": "json"
                    }
                ]
            }
        ]
    }
}
```

----------------------------------------

TITLE: NGINX Apply Defined Cache to Location Block
DESCRIPTION: Applies a previously defined NGINX cache zone ('backcache') to a specific location block (/weblogic-app/), enabling caching for requests matching that path. This configuration ensures that responses from the http://weblogic backend are cached according to the 'backcache' settings. This snippet is placed within the 'server' block for HTTPS traffic.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_17

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
location /weblogic-app/ {
    proxy_pass http://weblogic;
    proxy_cache backcache;
}
```

----------------------------------------

TITLE: Reverse Scheme for Static Content with Unconditional Application Pass
DESCRIPTION: Shows an NGINX Unit configuration where specific static file types (e.g., ".css", ".jpg") are served from a "share" with a "fallback" to a "proxy". All other requests, not matching these static types, are unconditionally passed to a "php-app", useful for apps avoiding filenames in dynamic URIs.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/configuration.md#_snippet_102

LANGUAGE: json
CODE:
```
{
      "routes": [
         {
            "match": {
                  "uri": [
                     "*.css",
                     "*.ico",
                     "*.jpg",
                     "*.js",
                     "*.png",
                     "*.xml"
                  ]
            },

            "action": {
                  "share": "/www/php-app/assets/files$uri",
                  "fallback": {
                     "proxy": "http://127.0.0.1:9000"
                  }
            }
         },
         {
            "action": {
                  "pass": "applications/php-app"
            }
         }

      ],

      "applications": {
         "php-app": {
            "type": "php",
            "root": "/www/php-app/scripts/"
         }
      }
}
```

----------------------------------------

TITLE: Set NGINX Error Log Level to Warn
DESCRIPTION: This NGINX configuration sets the `error.log` level to `warn`. This reduces log verbosity by ensuring that only warning, error, critical, alert, and emergency messages are logged, while still capturing important operational issues.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/admin-guides/config-agent/configure-metrics-collection.md#_snippet_2

LANGUAGE: nginx
CODE:
```
error_log /var/log/nginx/error.log warn;
```

----------------------------------------

TITLE: Create and Get Kubernetes Deployment YAML
DESCRIPTION: These `kubectl` commands demonstrate how to create a new Kubernetes deployment from a Docker image and then retrieve its current YAML configuration for inspection or modification.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/infrastructure/instances/manage-containerized-instances.md#_snippet_7

LANGUAGE: bash
CODE:
```
kubectl create deployment hello-node --image=yourusername/yourimagename
kubectl get deploy hello-node -o yaml
```

----------------------------------------

TITLE: Apply Nginx Rate Limit to a Specific Location
DESCRIPTION: This Nginx configuration shows how to apply a previously defined rate limiting zone (`zone=one`) to a specific `location` block, such as `/search/`. When applied, NGINX will delay requests exceeding the configured rate (1 request/second in this example) and return a `503 Service Unavailable` error if the 'bucket' becomes full. This ensures traffic to the specified path adheres to the rate limit.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/controlling-access-proxied-http.md#_snippet_4

LANGUAGE: nginx
CODE:
```
http {
    #...

    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;

    server {
        #...

        location /search/ {
            limit_req zone=one;
        }
    }
}
```

----------------------------------------

TITLE: Configure OIDC Provider Details in NGINX
DESCRIPTION: Specify the IdP's `issuer` URL, `client_id`, `client_secret`, and `ssl_trusted_certificate` within the `oidc_provider {}` context. The `ssl_trusted_certificate` is crucial for NGINX Plus to validate IdP TLS certificates.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-oidc.md#_snippet_5

LANGUAGE: nginx
CODE:
```
http {
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider my_idp {
        issuer        https://your-idp-domain/idp;
        client_id     <client_id>;
        client_secret <client_secret>;

        ssl_trusted_certificate /etc/ssl/certs/ca-certificates.crt;
    }

    # ...
}
```

----------------------------------------

TITLE: Install NGINX Gateway Fabric Helm Chart
DESCRIPTION: Installs NGINX Gateway Fabric using its Helm chart, configuring the NGINX Service to use NodePort with specific port mappings for external access, and displays the deployment status.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/get-started.md#_snippet_4

LANGUAGE: shell
CODE:
```
helm install ngf oci://ghcr.io/nginx/charts/nginx-gateway-fabric --create-namespace -n nginx-gateway --set nginx.service.type=NodePort --set-json 'nginx.service.nodePorts=[{"port":31437,"listenerPort":80}]'
```

LANGUAGE: text
CODE:
```
NAME: ngf
LAST DEPLOYED: Tue Apr 29 14:45:14 2025
NAMESPACE: nginx-gateway
STATUS: deployed
REVISION: 1
TEST SUITE: None
```

----------------------------------------

TITLE: Create Filter-Based NGINX WAF Signature Set
DESCRIPTION: This example demonstrates how to create a new signature set in NGINX App Protect WAF by filtering existing signatures. The filter criteria can include properties like attack type, signature type (request/response), risk level, and accuracy level. Supported filter operators are `eq` (equal to), `le` (less than or equal), `ge` (greater than or equal), and `all` (no filter). The provided JSON configures a set named 'my-low-accuracy-signatures' that blocks and alarms for signatures with 'Other Application Attacks' attack type, 'request' signature type, 'high' risk, and accuracy less than or equal to 'high'.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/common/user-defined-signature-sets.md#_snippet_0

LANGUAGE: json
CODE:
```
{
    "name": "filtered_signature_sets",
    "template": {
        "name": "POLICY_TEMPLATE_NGINX_BASE"
    },
    "applicationLanguage": "utf-8",
    "enforcementMode": "blocking",
    "signature-sets": [
        {
            "name": "my-low-accuracy-signatures",
            "block": true,
            "alarm": true,
            "signatureSet": {
                "type": "filter-based",
                "filter": {
                    "attackType": {
                        "name": "Other Application Attacks"
                    },
                    "signatureType": "request",
                    "riskFilter": "eq",
                    "riskValue": "high",
                    "accuracyFilter": "le",
                    "accuracyValue": "high"
                }
            }
        }
    ]
}
```

----------------------------------------

TITLE: Define NGINX Upstream Group with Shared Memory Zone
DESCRIPTION: This NGINX configuration defines an upstream server group named 'backend' and allocates a 64KB shared memory zone for it. The shared zone allows all NGINX worker processes to share configuration and health check counters, ensuring consistent load balancing and health monitoring across the group.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-health-check.md#_snippet_4

LANGUAGE: nginx
CODE:
```
http {
    upstream backend {
        zone backend 64k;
        server backend1.example.com;
        server backend2.example.com;
        server backend3.example.com;
        server backend4.example.com;
    }
}
```

----------------------------------------

TITLE: Configure NGINX Proxy for WebSocket Traffic
DESCRIPTION: This NGINX configuration snippet shows the necessary directives to correctly proxy WebSocket connections. WebSocket requires HTTP/1.1 for upstream connections. The `map` directive is used to set the `Connection` header based on the `Upgrade` header, ensuring proper handshake and two-way communication between clients and backend servers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_14

LANGUAGE: nginx
CODE:
```
# In the 'http' block
map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}
```

----------------------------------------

TITLE: Configure API Backends using OAS x-acm-backends Extension
DESCRIPTION: This JSON snippet demonstrates how to define multiple upstream backends for an API within an OpenAPI Specification using the `x-acm-backends` extension. It specifies service details like name, version, label, context root, and multiple upstream URLs with connection parameters such as `maxFails`, `maxConnections`, `failTimeout`, and `slowStart`. This allows API Connectivity Manager to automatically create and manage backend configurations.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/getting-started/publish-api-proxy.md#_snippet_5

LANGUAGE: json
CODE:
```
"servers": [
  {
    "url": "https://{server}.example.com/api/{version}",
    "variables": {
      "version": {
        "default": "v1"
      },
      "server": {
        "default": "staging"
      }
    },
    "x-acm-append-rule": "NONE",
    "x-acm-strip-basepath": false,
    "x-acm-backends": [
      {
        "serviceName": "pets-backend",
        "serviceVersion": "pets-backend-v1",
        "serviceLabel": "default",
        "contextRoot": "/dev",
        "upstreams": [
          {
            "url": "https://gecho1.null.ie",
            "maxFails": 10,
            "maxConnections": 5,
            "failTimeout": "5s",
            "slowStart": "10s"
          },
          {
            "url": "https://gecho2.null.ie",
            "maxFails": 5,
            "maxConnections": 8,
            "failTimeout": "15s",
            "slowStart": "3s"
          },
          {
            "url": "https://gecho3.null.ie",
            "maxFails": 7,
            "maxConnections": 33,
            "failTimeout": "35s",
            "slowStart": "1s"
          }
        ]
      }
    ]
  }
],
```

----------------------------------------

TITLE: Test NGINX Plus Configuration Syntax
DESCRIPTION: Command to verify the syntax of the NGINX Plus configuration file. This step helps identify any errors before reloading the server. The expected output confirms a successful configuration.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/rtmp.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: NGINX Instance Manager Configuration for Vault Secrets
DESCRIPTION: This `/etc/nms/nms.conf` snippet sets the `secrets` driver to 'vault', specifies the Vault address, and defines an `isolation` namespace and prefix for organizing secrets within Vault.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/system-configuration/configure-vault.md#_snippet_4

LANGUAGE: text
CODE:
```
secrets:
  # change driver to "local" if you want to stop using vault
  driver: vault
  config:
    # local file path for stored secrets when using the local driver
    path: /var/lib/nms/secrets
    # key_file is required for local driver
    key_file: /var/lib/nms/secrets/key
    # vault address for when using the vault driver
    address: http://127.0.0.1:8200/v1
    # isolation is used to store secrets in a specific namespace and prefix to better restrict access rights
    # on the local file system or shared vault server.
    isolation:
      namespace: secret
      prefix: secureString
```

----------------------------------------

TITLE: Build NGINX with App Protect WAF on Alpine Linux
DESCRIPTION: This Dockerfile constructs an NGINX image based on Alpine Linux, integrating the NGINX App Protect WAF v5 module. It uses build arguments for OS version, mounts secrets for certificate management during package installation, configures NGINX repositories, and sets up standard logging to stdout/stderr. The image exposes port 80 and defines the default command to run NGINX in the foreground.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/v5/build-nginx-image-oss/build-alpine.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Supported OS_VER's are 3.16/3.17/3.19
ARG OS_VER="3.19"

# Base image
FROM alpine:${OS_VER}

# Install NGINX OSS and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/apk/cert.pem,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/apk/cert.key,mode=0644 \
    apk add openssl curl ca-certificates \
    && printf "%s%s%s%s\n" \
        "http://nginx.org/packages/mainline/alpine/v" \
        `egrep -o '^[0-9]+\.[0-9]+' /etc/alpine-release` \
        "/main" \
        | tee -a /etc/apk/repositories \
    && wget -O /etc/apk/keys/nginx_signing.rsa.pub https://cs.nginx.com/static/keys/nginx_signing.rsa.pub \
    && printf "https://pkgs.nginx.com/app-protect-x-oss/alpine/v`egrep -o '^[0-9]+\.[0-9]+' /etc/alpine-release`/main\n" | \
        tee -a /etc/apk/repositories \
    && apk update \
    && apk add app-protect-module-oss \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log \
    && rm -rf /var/cache/apk/*

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: Enhanced SSL Client Verify Variable
DESCRIPTION: The `$ssl_client_verify` variable now includes the reason for failure, providing more detailed error information for SSL client verification issues.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/releases.md#_snippet_62

LANGUAGE: APIDOC
CODE:
```
$ssl_client_verify variable: Now includes the reason for failure.
```

----------------------------------------

TITLE: Resolve ForbiddenByPolicy Error by Assigning Key Vault Access Policy - Azure CLI
DESCRIPTION: This snippet provides Azure CLI commands to resolve the `ForbiddenByPolicy` error by assigning the necessary 'Get secrets' permissions to the NGINXaaS deployment's managed identity in Azure Key Vault. It covers obtaining the principal ID for both user-assigned and system-assigned managed identities, and then applying the policy.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/getting-started/ssl-tls-certificates/overview.md#_snippet_8

LANGUAGE: bash
CODE:
```
mi_principal_id=$(az identity show --name $MI_NAME \
   --resource-group $MI_RESOURCE_GROUP \
   --query principalId --output tsv)
```

LANGUAGE: bash
CODE:
```
mi_principal_id=$(az nginx deployment show --name $DEP_NAME \
   --resource-group $DEP_RESOURCE_GROUP \
   --query identity.principalId --output tsv)
```

LANGUAGE: bash
CODE:
```
az keyvault set-policy --name $KV_NAME \
   --resource-group $KV_RESOURCE_GROUP \
   --object-id $mi_principal_id \
   --secret-permissions get
```

----------------------------------------

TITLE: NGINX Mesh Production Deployment with Disk Upstream CA
DESCRIPTION: This YAML configuration outlines a production deployment setup for NGINX Service Mesh utilizing a 'disk' upstream authority for Certificate Authority management. It specifies paths for the intermediate CA certificate, its key, and the root CA bundle, promoting enhanced security by using an intermediate CA.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/guides/secure-traffic-mtls.md#_snippet_6

LANGUAGE: yaml
CODE:
```
apiVersion: "v1"
upstreamAuthority: "disk"
config:
    cert_file_path: "/path/to/intermediateCA.crt"
    key_file_path: "/path/to/intermediateCA.key"
    bundle_file_path: "/path/to/rootCA.crt"
```

----------------------------------------

TITLE: Enable Nginx Rate Limit Dry Run Mode for Testing
DESCRIPTION: This Nginx configuration demonstrates how to enable the 'dry run' mode for rate limiting using the `limit_req_dry_run on;` directive within a `location` block. In this mode, NGINX will not actually limit requests but will still account for and log excessive requests, marking them with 'dry run'. This is useful for testing and observing the impact of rate limiting without affecting live traffic.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/controlling-access-proxied-http.md#_snippet_5

LANGUAGE: nginx
CODE:
```
http {
    #...

    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;

    server {
        #...

        location /search/ {
            limit_req zone=one;
            limit_req_dry_run on;
        }
    }
}
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: This command reloads the NGINX configuration without stopping the server, applying any changes made to the configuration file. It's essential after modifying NGINX settings to ensure they take effect.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/active-directory-federation-services.md#_snippet_9

LANGUAGE: bash
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Reload NGINX Configuration (nginx command)
DESCRIPTION: This command signals the NGINX master process to gracefully reload its configuration. It allows NGINX to start using the new configuration without stopping the service, ensuring continuous operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_14

LANGUAGE: none
CODE:
```
root# nginx -s reload
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: This command reloads the NGINX configuration file, applying any changes without stopping the NGINX service. It's essential after modifying NGINX configuration files.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/onelogin.md#_snippet_9

LANGUAGE: shell
CODE:
```
nginx -s reload
```

----------------------------------------

TITLE: Configure Keepalived for Three or More Active NGINX Plus Nodes
DESCRIPTION: This Keepalived configuration demonstrates an active-active-active setup for three or more NGINX Plus nodes. It defines multiple vrrp_instance blocks, each managing a specific Virtual IP (VIP) and assigning different priorities to nodes. This allows for a highly redundant HA configuration where each node can be active for one VIP, secondary for another, and tertiary for a third, ensuring continuous service availability.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/high-availability/ha-keepalived-nodes.md#_snippet_4

LANGUAGE: yaml
CODE:
```
vrrp_script chk_nginx_service {
    script   "/usr/lib/keepalived/nginx-ha-check"
    interval 3
    weight   50
}

vrrp_instance VI_1 {
    interface         eth0
    state             BACKUP
    priority          101
    virtual_router_id 51
    advert_int        1
    accept
    unicast_src_ip    192.168.10.10

    unicast_peer {
        192.168.10.11
        192.168.10.12
        192.168.10.13
    }

    virtual_ipaddress {
        192.168.10.100
    }

    track_script {
        chk_nginx_service
    }

    notify "/usr/lib/keepalived/nginx-ha-notify"
}

vrrp_instance VI_2 {
    interface         eth0
    state             BACKUP
    priority          100
    virtual_router_id 61
    advert_int        1
    accept
    unicast_src_ip    192.168.10.10

    unicast_peer {
        192.168.10.11
        192.168.10.12
        192.168.10.13
    }

    virtual_ipaddress {
        192.168.10.101
    }

    track_script {
        chk_nginx_service
    }

    notify "/usr/lib/keepalived/nginx-ha-notify"
}

vrrp_instance VI_3 {
    interface         eth0
    state             BACKUP
    priority          99
    virtual_router_id 71
    advert_int        1
    accept
    unicast_src_ip    192.168.10.10

    unicast_peer {
        192.168.10.11
        192.168.10.12
        192.168.10.13
    }

    virtual_ipaddress {
        192.168.10.102
    }

    track_script {
        chk_nginx_service
    }

    notify "/usr/lib/keepalived/nginx-ha-notify"
}
```

----------------------------------------

TITLE: NGINX Unit: Dynamic URI Rewrite with JavaScript Expression
DESCRIPTION: This example illustrates using a JavaScript expression within the `rewrite` rule to dynamically modify the URI. It converts the incoming URI to lowercase before serving static files from `/var/www`, showcasing programmatic URI manipulation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/news/2023/unit-1.30.0-released.md#_snippet_2

LANGUAGE: json
CODE:
```
{
    "routes": [
        {
            "action": {
                "rewrite": "`${uri.toLowerCase()}`",
                "share": "/var/www$uri"
            }
        }
    ]
}
```

----------------------------------------

TITLE: NGINX configuration for serving static content
DESCRIPTION: This NGINX configuration block defines a server listening on port 80. It sets the root directory for static files to '/srv' and specifies 'index.html' as the default index file for requests to the root location. This configuration is used to serve static websites.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/hosting-static-content.md#_snippet_0

LANGUAGE: nginx
CODE:
```
http {
	server {
		listen 80;
		location / {
			root /srv;
			index index.html;
		}
	}
}
```

----------------------------------------

TITLE: Build Docker Image for NGINX Plus with App Protect WAF
DESCRIPTION: This Dockerfile defines the steps to create a container image based on Oracle Linux 8, installing NGINX Plus and the NGINX App Protect WAF v5 module. It utilizes Docker build secrets for securely accessing the NGINX Plus repositories, configures yum repositories, sets up logging, exposes port 80, and defines the default command to run NGINX.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/v5/build-nginx-image-plus/build-oracle.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Base image
FROM oraclelinux:8

# Install NGINX Plus and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    dnf -y install wget ca-certificates yum-utils \
    && wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/nginx-plus-8.repo \
    && echo "[app-protect-x-plus]" > /etc/yum.repos.d/app-protect-8-x-plus.repo \
    && echo "name=nginx-app-protect repo" >> /etc/yum.repos.d/app-protect-8-x-plus.repo \
    && echo "baseurl=https://pkgs.nginx.com/app-protect-x-plus/centos/8/\$basearch/" >> /etc/yum.repos.d/app-protect-8-x-plus.repo \
    && echo "sslclientcert=/etc/ssl/nginx/nginx-repo.crt" >> /etc/yum.repos.d/app-protect-8-x-plus.repo \
    && echo "sslclientkey=/etc/ssl/nginx/nginx-repo.key" >> /etc/yum.repos.d/app-protect-8-x-plus.repo \
    && echo "gpgcheck=0" >> /etc/yum.repos.d/app-protect-8-x-plus.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/app-protect-8-x-plus.repo \
    && dnf clean all \
    && dnf -y install app-protect-module-plus \
    && dnf clean all \
    && rm -rf /var/cache/dnf \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: NGINX: Pass OIDC Claims as Headers to Upstream
DESCRIPTION: This NGINX configuration snippet demonstrates how to extract OIDC claims such as email, name, and subject from the ID token returned by Auth0 and pass them as custom headers (`sub`, `email`, `name`) to an upstream application using the `proxy_set_header` directive. It also enforces OIDC authentication for the location.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/auth0.md#_snippet_8

LANGUAGE: nginx
CODE:
```
# ...
location / {
     auth_oidc auth0;

     proxy_set_header sub   $oidc_claim_sub;
     proxy_set_header email $oidc_claim_email;
     proxy_set_header name  $oidc_claim_name;

     proxy_pass http://127.0.0.1:8080;
}
# ...
```

----------------------------------------

TITLE: Verify Kubernetes Services with kubectl get
DESCRIPTION: This command lists all services in the 'default' namespace, showing their type, cluster IP, external IP, ports, and age. It helps confirm that expected services like 'coffee', 'gateway-nginx', and 'tea' are running and accessible.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/get-started.md#_snippet_13

LANGUAGE: shell
CODE:
```
kubectl -n default get services
```

LANGUAGE: text
CODE:
```
NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
coffee          ClusterIP   10.96.206.93    <none>        80/TCP         2m2s
gateway-nginx   NodePort    10.96.157.168   <none>        80:31437/TCP   104s
kubernetes      ClusterIP   10.96.0.1       <none>        443/TCP        142m
tea             ClusterIP   10.96.43.183    <none>        80/TCP         2m2s
```

----------------------------------------

TITLE: Specify Okta OIDC Provider Credentials in NGINX
DESCRIPTION: Configure the `oidc_provider {}` context with your actual Okta **Client ID**, **Client Secret**, and **Issuer** URL. It is crucial that NGINX trusts the IdP's certificate; if not in the system CA bundle, explicitly specify a trusted certificate with `ssl_trusted_certificate`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/okta.md#_snippet_3

LANGUAGE: nginx
CODE:
```
http {
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider okta {
        issuer        https://dev-123456.okta.com/oauth2/default;
        client_id     <client_id>;
        client_secret <client_secret>;
    }

    # ...
}
```

----------------------------------------

TITLE: Introspect Keycloak User Access Token with NGINX Client
DESCRIPTION: Demonstrates how an NGINX client can introspect an incoming user access token using Keycloak's OpenID Connect token introspection endpoint. The process involves sending a POST request with the token in the request body and basic authentication credentials (CLIENT_ID:CLIENT_SECRET base64 encoded) in the Authorization header. The response is a JSON object with token claims.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/tutorials/introspection-keycloak.md#_snippet_9

LANGUAGE: shell
CODE:
```
curl -L -X POST 'http://{HOST/IP_ADDRESS}:{PORT}/realms/{REALM}/protocol/openid-connect/token/introspect' \
   -H "Authorization: Bearer <access token>" \
   -H "Accept: application/json" \
   -H "Content-Type: application/x-www-form-urlencoded" \
   --data-urlencode 'token=<ACCESS_TOKEN>' \
   | jq
```

LANGUAGE: shell
CODE:
```
curl -L -X POST 'http://192.0.2.5:8080/realms/nginx/protocol/openid-connect/token/introspect' \
   -H "Authorization: Bearer <access token>" \
   -H "Accept: application/json" \
   -H "Content-Type: application/x-www-form-urlencoded" \
   --data-urlencode 'token=<JWT_token>'\
   | jq
```

LANGUAGE: json
CODE:
```
{
   "active": true,
    "exp": 1665585794,
   "iat": 1665585494,
   "jti": "c8723771-2474-4c94-b155-f78a4583419f",
   "iss": "http://192.0.2.5:8080/realms/nginx",
   "aud": "account",
   "sub": "a95117bf-1a2e-4d46-9c44-5fdee8dddd11",
   "typ": "Bearer",
   "azp": "nginx-plus",
   "session_state": "b7ca9271-02ce-453f-b491-61ec4e648d5d",
   "given_name": "",
   "family_name": "",
   "preferred_username": "nginx-user",
   "email_verified": false,
   "acr": "1",
   "scope": "openid profile email",
   "sid": "b7ca9271-02ce-453f-b491-61ec4e648d5d",
   "client_id": "nginx-plus",
   "username": "nginx-user",
   "realm_access": {
      "roles": [
         "default-roles-nginx",
         "offline_access",
         "nginx-keycloak-role",
         "uma_authorization"
      ]
   },
   "resource_access": {
      "account": {
         "roles": [
            "manage-account",
            "manage-account-links",
            "view-profile"
         ]
      }
   }
}
```

----------------------------------------

TITLE: Dockerfile for NGINX with App Protect WAF Installation
DESCRIPTION: This Dockerfile defines a multi-stage build process to create an NGINX image. It installs NGINX Open Source and the NGINX App Protect WAF v5 module on Ubuntu. It includes steps for adding NGINX repositories, importing GPG keys, installing necessary packages, and configuring logging. It also exposes port 80 and sets the default command to run NGINX in the foreground.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/v5/build-nginx-image-oss/build-ubuntu.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Supported OS_CODENAME's are: focal/jammy
ARG OS_CODENAME=jammy

# Base image
FROM ubuntu:${OS_CODENAME}

# Install NGINX OSS and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    apt-get update \
    && apt-get install -y \
      apt-transport-https \
      lsb-release \
      ca-certificates \
      wget \
      gnupg2 \
      ubuntu-keyring \
    && wget -qO - https://nginx.org/keys/nginx_signing.key | gpg --dearmor | \
      tee /usr/share/keyrings/nginx-archive-keyring.gpg >/dev/null \
    && gpg --dry-run --quiet --no-keyring --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpg \
    && printf "deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \
      http://nginx.org/packages/mainline/ubuntu `lsb_release -cs` nginx\n" | \
      tee /etc/apt/sources.list.d/nginx.list \
    && wget -qO - https://cs.nginx.com/static/keys/nginx_signing.key | gpg --dearmor | \
      tee /usr/share/keyrings/nginx-static-archive-keyring.gpg >/dev/null \
    && gpg --dry-run --quiet --no-keyring --import --import-options import-show /usr/share/keyrings/nginx-static-archive-keyring.gpg \
    && printf "deb [signed-by=/usr/share/keyrings/nginx-static-archive-keyring.gpg] \
      https://pkgs.nginx.com/app-protect-x-oss/ubuntu `lsb_release -cs` nginx-plus\n" | \
      tee /etc/apt/sources.list.d/nginx-app-protect.list \
    && wget -P /etc/apt/apt.conf.d https://cs.nginx.com/static/files/90pkgs-nginx \
    && apt-get update \
    && DEBIAN_FRONTEND="noninteractive" apt-get install -y nginx=1.25.5-1~`lsb_release -cs` app-protect-module-oss \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: Build NGINX OSS with App Protect WAF Docker Image
DESCRIPTION: This Dockerfile defines the complete process for creating a Docker image that includes NGINX Open Source and the NGINX App Protect WAF v5 module. It specifies the base Debian OS, handles repository key management, installs required packages, sets up logging, exposes the default HTTP port, and defines the NGINX startup command.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/v5/build-nginx-image-oss/build-debian.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Supported OS_CODENAME's are: bullseye/bookworm
ARG OS_CODENAME=bookworm

# Base image
FROM debian:${OS_CODENAME}

# Install NGINX OSS and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    apt-get update \
    && apt-get install -y \
      apt-transport-https \
      lsb-release \
      ca-certificates \
      wget \
      gnupg2 \
      debian-archive-keyring \
    && wget -qO - https://nginx.org/keys/nginx_signing.key | gpg --dearmor | \
      tee /usr/share/keyrings/nginx-archive-keyring.gpg >/dev/null \
    && gpg --dry-run --quiet --no-keyring --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpg \
    && printf "deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \
      http://nginx.org/packages/mainline/debian `lsb_release -cs` nginx\n" | \
      tee /etc/apt/sources.list.d/nginx.list \
    && wget -qO - https://cs.nginx.com/static/keys/nginx_signing.key | gpg --dearmor | \
      tee /usr/share/keyrings/nginx-static-archive-keyring.gpg >/dev/null \
    && gpg --dry-run --quiet --no-keyring --import --import-options import-show /usr/share/keyrings/nginx-static-archive-keyring.gpg \
    && printf "deb [signed-by=/usr/share/keyrings/nginx-static-archive-keyring.gpg] \
      https://pkgs.nginx.com/app-protect-x-oss/debian `lsb_release -cs` nginx-plus\n" | \
      tee /etc/apt/sources.list.d/nginx-app-protect.list \
    && wget -P /etc/apt/apt.conf.d https://cs.nginx.com/static/files/90pkgs-nginx \
    && apt-get update \
    && DEBIAN_FRONTEND="noninteractive" apt-get install -y nginx=1.25.5-1~`lsb_release -cs` app-protect-module-oss \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: Example Valid NGINX Proxy Buffer Configuration
DESCRIPTION: This example illustrates a correct configuration for NGINX proxy buffers, demonstrating how proxy_busy_buffers_size must be less than the total proxy_buffers size minus one buffer. It shows the calculation and the resulting valid state.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/how-to/policies/http-backend-configuration.md#_snippet_8

LANGUAGE: text
CODE:
```
proxy busy buffers size : 16 KB
proxy buffer number     : 8
proxy buffer size       : 4 KB
total buffer size       : 32 KB

busy_buffers_size < total buffer size - buffer
16 KB < 32 KB - 4 KB
16 KB < 28 KB
True: Valid proxy buffer number & size configuration
```

----------------------------------------

TITLE: Test NGINX Redirect for /tea/type to /organic/type
DESCRIPTION: This example demonstrates a redirect from `http://cafe.example.com/tea/type` to `http://cafe.example.com/organic/type`. The curl command sends a request to the tea/type path, and the output shows a 302 redirect to the organic/type path.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/redirects-and-rewrites.md#_snippet_11

LANGUAGE: shell
CODE:
```
curl --resolve cafe.example.com:$GW_PORT:$GW_IP http://cafe.example.com:$GW_PORT/tea/type --include
```

LANGUAGE: text
CODE:
```
HTTP/1.1 302 Moved Temporarily
..
Location: http://cafe.example.com:8080/organic/type
```

----------------------------------------

TITLE: Configure Basic Rate Limiting in NGINX
DESCRIPTION: This NGINX configuration snippet demonstrates how to set up basic rate limiting for the `/login/` location. It defines a shared memory zone `mylimit` to track request rates based on the client's IP address, allowing 1 request per second. The `limit_req` directive then applies this limit to the specified location.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/rate-limiting.md#_snippet_0

LANGUAGE: nginx
CODE:
```
http {
    #...

    limit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s;

    server {
        #...

        location /login/ {
            limit_req zone=mylimit;

        }
}
```

----------------------------------------

TITLE: YAML Configuration for Kubernetes Pod Termination Grace Period
DESCRIPTION: Example YAML snippet demonstrating how to set the `terminationGracePeriodSeconds` for a Kubernetes pod. This value ensures that the pod has sufficient time to execute its `preStop` hook, preventing Kubernetes from forcefully terminating the pod before the hook completes its operations, such as a graceful shutdown or cleanup. The recommended value should be at least the duration of the `sleep` command within the `preStop` hook, which defaults to 30 seconds.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/ngf/installation/delay-pod-termination/termination-grace-period.md#_snippet_0

LANGUAGE: yaml
CODE:
```
terminationGracePeriodSeconds: 50
```

----------------------------------------

TITLE: Configuring NGINX for Certificate-Based Zone Sync Authentication
DESCRIPTION: This NGINX configuration snippet demonstrates how to set up certificate-based authentication for inter-instance communication using the `stream` block. It enables `ssl_verify_client` and `zone_sync` directives, specifying paths for SSL certificates, keys, and trusted CA certificates. This setup ensures that cluster instances authenticate each other securely before synchronizing runtime state.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/quickstart/runtime-state-sharing.md#_snippet_3

LANGUAGE: nginx
CODE:
```
stream {
  resolver 127.0.0.1:49153 valid=20s;

  server {
    listen 9000 ssl;

    ssl_certificate     /opt/ssl/zone_sync.crt;
    ssl_certificate_key /opt/ssl/zone_sync.key;
    ssl_verify_client       on;
    ssl_client_certificate /opt/ssl/zone_sync_ca.pem;

    zone_sync;
    zone_sync_server internal.nginxaas.nginx.com:9000 resolve;

    zone_sync_ssl                     on;
    zone_sync_ssl_verify              on;
    zone_sync_ssl_trusted_certificate /opt/ssl/zone_sync_ca.pem;

    zone_sync_ssl_certificate     /opt/ssl/zone_sync.crt;
    zone_sync_ssl_certificate_key /opt/ssl/zone_sync.key;
  }
}
```

----------------------------------------

TITLE: Create Cert-Manager ClusterIssuer for Let's Encrypt
DESCRIPTION: This YAML defines a Kubernetes ClusterIssuer resource for cert-manager, configured to use Let's Encrypt's ACME v2 server. It specifies an email for notifications, a secret to store the account's private key, and an HTTP01 solver using a NGINX Gateway Fabric Gateway resource. Remember to update the email address.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-security/integrate-cert-manager.md#_snippet_2

LANGUAGE: yaml
CODE:
```
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    # You must replace this email address with your own.
    # Let's Encrypt will use this to contact you about expiring
    # certificates, and issues related to your account.
    email: my-name@example.com
    server: https://acme-v02.api.letsencrypt.org/directory
    privateKeySecretRef:
      # Secret resource that will be used to store the account's private key.
      name: issuer-account-key
    # Add a single challenge solver, HTTP01 using NGINX Gateway Fabric
    solvers:
    - http01:
        gatewayHTTPRoute:
          parentRefs: # This is the name of the Gateway that will be created in the next step
          - name: gateway
            namespace: default
            kind: Gateway
```

----------------------------------------

TITLE: Configure NGINX Unit for WordPress
DESCRIPTION: This JSON configuration sets up NGINX Unit to serve WordPress. It defines listeners on port 80, routes for PHP files and static assets, and application targets for direct script execution and index file serving. It uses /path/to/app as the root for WordPress files.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/howto/apps/wordpress.md#_snippet_0

LANGUAGE: JSON
CODE:
```
{
   "listeners": {
      "*:80": {
            "pass": "routes"
      }
   },

   "routes": [
      {
            "match": {
               "uri": [
                  "*.php",
                  "*.php/*",
                  "/wp-admin/"
               ]
            },
            "action": {
               "pass": "applications/wordpress/direct"
            }
      },
      {
            "action": {
               "share": "/path/to/app$uri",
               "fallback": {
                  "pass": "applications/wordpress/index"
               }
            }
      }
   ],

   "applications": {
      "wordpress": {
            "type": "php",
            "targets": {
               "direct": {
                  "root": "/path/to/app/"
               },
               "index": {
                  "root": "/path/to/app/",
                  "script": "index.php"
               }
            }
      }
   }
}
```

----------------------------------------

TITLE: NGINX App Protect WAF Access Profile Configuration Example
DESCRIPTION: This example demonstrates a complete NGINX App Protect WAF policy configuration that includes an access profile named "access_profile_jwt". The profile is configured to expect the JWT in the "authorization" header, enforces a maximum length of 2000 characters, and requires digital signature verification. It also includes a JWKS file for key management and username extraction settings.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v5/configuration-guide/configuration.md#_snippet_27

LANGUAGE: shell
CODE:
```
{
    "policy": {
        "name": "jwt_policy",
        "template": { "name": "POLICY_TEMPLATE_NGINX_BASE"
        },
        "access-profiles": [
         {
            "description": "",
            "enforceMaximumLength": true,
            "enforceValidityPeriod": false,
            "keyFiles": [
               {
                  "contents": "{\r\n  \"keys\": [\r\n    {\r\n      \"alg\": \"RS256\",\r\n      \"e\": \"AQAB\",\r\n      \"kid\": \"1234\",\r\n      \"kty\": \"RSA\",\r\n      \"n\": \"tSbi8WYTScbuM4fe5qe4l60A2SG5oo3u5JDBtH_dPJTeQICRkrgLD6oyyHJc9BCe9abX4FEq_Qd1SYHBdl838g48FWblISBpn9--B4D9O5TPh90zAYP65VnViKun__XHGrfGT65S9HFykvo2KxhtxOFAFw0rE6s5nnKPwhYbV7omVS71KeT3B_u7wHsfyBXujr_cxzFYmyg165Yx9Z5vI1D-pg4EJLXIo5qZDxr82jlIB6EdLCL2s5vtmDhHzwQSdSOMWEp706UgjPl_NFMideiPXsEzdcx2y1cS97gyElhmWcODl4q3RgcGTlWIPFhrnobhoRtiCZzvlphu8Nqn6Q\",\r\n      \"use\": \"sig\",\r\n      \"x5c\": [\r\n        \"MIID1zCCAr+gAwIBAgIJAJ/bOlwBpErqMA0GCSqGSIb3DQEBCwUAMIGAMQswCQYDVQQGEwJpbDEPMA0GA1UECAwGaXNyYWVsMRAwDgYDVQQHDAd0ZWxhdml2MRMwEQYDVQQKDApmNW5ldHdvcmtzMQwwCgYDVQQLDANkZXYxDDAKBgNVBAMMA21heDEdMBsGCSqGSIb3DQEJARYOaG93ZHlAbWF0ZS5jb20wIBcNMjIxMTA3MTM0ODQzWhgPMjA1MDAzMjUxMzQ4NDNaMIGAMQswCQYDVQQGEwJpbDEPMA0GA1UECAwGaXNyYWVsMRAwDgYDVQQHDAd0ZWxhdml2MRMwEQYDVQQKDApmNW5ldHdvcmtzMQwwCgYDVQQLDANkZXYxDDAKBgNVBAMMA21heDEdMBsGCSqGSIb3DQEJARYOaG93ZHlAbWF0ZS5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC1JuLxZhNJxu4zh97mp7iXrQDZIbmije7kkMG0f908lN5AgJGSuAsPqjLIclz0EJ71ptfgUSr9B3VJgcF2XzfyDjwVZuUhIGmf374HgP07lM+H3TMBg/rlWdWIq6f/9ccat8ZPrlL0cXKS+jYrGG3E4UAXDSsTqzmeco/CFhtXuiZVLvUp5PcH+7vAex/IFe6Ov9zHMVibKDXrljH1nm8jUP6mDgQktcijmpkPGvzaOUgHoR0sIvazm+2YOEfPBBJ1I4xYSnvTpSCM+X80UyJ16I9ewTN1zHbLVxL3uDISWGZZw4OXirdGBwZOVYg8WGuehuGhG2IJnO+WmG7w2qfpAgMBAAGjUDBOMB0GA1UdDgQWBBSHykVOY3Q1bWmwFmJbzBkQdyGtkTAfBgNVHSMEGDAWgBSHykVOY3Q1bWmwFmJbzBkQdyGtkTAMBgNVHRMEBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCgcgp72Xw6qzbGLHyNMaCm9A6smtquKTdFCXLWVSOBix6WAJGPv1iKOvvMNF8ZV2RU44vS4Qa+o1ViBN8DXuddmRbShtvxcJzRKy1I73szZBMlZL6euRB1KN4m8tBtDj+rfKtPpheMtwIPbiukRjJrzRzSz3LXAAlxEIEgYSifKpL/okYZYRY6JF5PwSR0cvrfe/qa/G2iYF6Ps7knxy424RK6gpMbnhxb2gdhLPqDE50uxkr6dVHXbc85AuwAi983tOMhTyzDh3XTBEt2hr26F7jSeniC7TTIxmMgDdtYzRMwdb1XbubdtzUPnB/SW7jemK9I45kpKlUBDZD/QwER\"\r\n      ]\r\n    }\r\n  ]\r\n}",  # there can be more only one JWKs file (contents) in the policy JSON schema, however, the total amount of JWK in the JWKs is limited to 10.
                  "fileName": "JWKSFile.json"
               }
            ],
            "location": {
               "in": "header",  # the other option is: "query"
               "name": "authorization"  # the name of the header or parameter (according to "part")
            },
            "maximumLength": 2000,
            "name": "access_profile_jwt",
            "type": "jwt",
            "usernameExtraction": {
               "claimPropertyName": "sub",
               "enabled": true,
               "isMandatory": false
            },
            "verifyDigitalSignature": true
        }
      ],
      "urls": [
         {
            "name": "/jwt",
            "accessProfile": {
               "name": "access_profile_jwt"
            },
            "attackSignaturesCheck": true,
            "isAllowed": true,
            "mandatoryBody": false,
            "method": "*",
            "methodsOverrideOnUrlCheck": false

```

----------------------------------------

TITLE: Build NGINX with App Protect WAF on UBI
DESCRIPTION: This Dockerfile builds a Universal Base Image (UBI) based container for NGINX Open Source and NGINX App Protect WAF v5 module. It supports UBI versions 7, 8, and 9, dynamically selecting the package manager (yum/dnf) and configuring NGINX and App Protect repositories using build secrets for repository authentication.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/v5/build-nginx-image-oss/build-rhel.md#_snippet_0

LANGUAGE: Dockerfile
CODE:
```
# syntax=docker/dockerfile:1

# Supported UBI_VERSION's are 7/8/9
ARG UBI_VERSION=9

# Base Image
FROM registry.access.redhat.com/ubi${UBI_VERSION}/ubi

# Define the ARG again after FROM to use it in this stage
ARG UBI_VERSION

# Install NGINX OSS and NGINX App Protect WAF v5 module
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    PKG_MANAGER=dnf; \
    if [ "${UBI_VERSION}" = "7" ]; then \
        PKG_MANAGER=yum; \
    fi \
    && $PKG_MANAGER -y install wget ca-certificates yum-utils \
    && wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/dependencies.repo \
    && echo "[nginx-mainline]" > /etc/yum.repos.d/nginx.repo \
    && echo "name=nginx mainline repo" >> /etc/yum.repos.d/nginx.repo \
    && echo "baseurl=http://nginx.org/packages/mainline/centos/\$releasever/\$basearch/" >> /etc/yum.repos.d/nginx.repo \
    && echo "gpgcheck=1" >> /etc/yum.repos.d/nginx.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/nginx.repo \
    && echo "gpgkey=https://nginx.org/keys/nginx_signing.key" >> /etc/yum.repos.d/nginx.repo \
    && echo "module_hotfixes=true" >> /etc/yum.repos.d/nginx.repo \
    && echo "[app-protect-x-oss]" > /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-oss.repo \
    && echo "name=nginx-app-protect repo" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-oss.repo \
    && echo "baseurl=https://pkgs.nginx.com/app-protect-x-oss/centos/${UBI_VERSION}/\$basearch/" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-oss.repo \
    && echo "sslclientcert=/etc/ssl/nginx/nginx-repo.crt" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-oss.repo \
    && echo "sslclientkey=/etc/ssl/nginx/nginx-repo.key" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-oss.repo \
    && echo "gpgcheck=0" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-oss.repo \
    && echo "enabled=1" >> /etc/yum.repos.d/app-protect-${UBI_VERSION}-x-oss.repo \
    && $PKG_MANAGER clean all \
    && $PKG_MANAGER install -y app-protect-module-oss \
    && $PKG_MANAGER clean all \
    && rm -rf /var/cache/$PKG_MANAGER \
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Expose port
EXPOSE 80

# Define stop signal
STOPSIGNAL SIGQUIT

# Set default command
CMD ["nginx", "-g", "daemon off;"]
```

----------------------------------------

TITLE: NGINX: Configure Upstream Zone for Dynamic API Reconfiguration
DESCRIPTION: To enable dynamic reconfiguration of an NGINX upstream group via the NGINX Plus API, include the `zone` directive. This creates a shared memory zone for storing the group's configuration and runtime state, making it accessible to all worker processes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_34

LANGUAGE: nginx
CODE:
```
# In the 'http' block
upstream nodejs {
    zone nodejs 64k;
    server 192.168.33.11:8080;
    server 192.168.33.12:8080;
    # ...
}
```

----------------------------------------

TITLE: Configure Prometheus Annotations for NGINX Ingress Controller Pod
DESCRIPTION: Add these annotations to the NGINX Ingress Controller Pod spec to enable Prometheus scraping. The `prometheus.io/scrape` annotation enables scraping, and `prometheus.io/port` specifies the port where metrics are exposed, which is customizable via the `-prometheus-metrics-listen-port` argument.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/kic/deploy-with-kic.md#_snippet_10

LANGUAGE: yaml
CODE:
```
prometheus.io/scrape: "true"
prometheus.io/port: "<prometheus-metrics-listen-port>"
```

----------------------------------------

TITLE: Example of Exceeded Listen Queue Output
DESCRIPTION: This output demonstrates a scenario where the number of unaccepted connections (qlen) on port 80 (192) exceeds the maximum allowed (128). This indicates a bottleneck due to heavy traffic, requiring system and NGINX tuning.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/serving-static-content.md#_snippet_12

LANGUAGE: none
CODE:
```
Current listen queue sizes (qlen/incqlen/maxqlen)
Listen         Local Address
0/0/128        *.12345
192/0/128        *.80
0/0/128        *.8080
```

----------------------------------------

TITLE: Configure NGINX App Protect DoS Monitor Port
DESCRIPTION: This NGINX configuration example illustrates the correct setup for `app_protect_dos_monitor`. It emphasizes that the monitor port must match the server's listening port to prevent false attack declarations, ensuring accurate DoS protection.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/releases/about-2.4.md#_snippet_1

LANGUAGE: nginx-conf
CODE:
```
server {
    listen 8080;
    location / {  app_protect_dos_monitor "myservice.com:8080";  }
}
```

----------------------------------------

TITLE: Diagnose ClickHouse Pod Crash in NGINX Controller HA
DESCRIPTION: Use `kubectl` to check ClickHouse pod status and logs for 'Cannot lock file' errors, indicating a crash due to another instance running. This helps diagnose failover issues in multi-node NGINX Controller configurations.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/releases/adc/adc-release-notes-3.22.md#_snippet_2

LANGUAGE: yaml
CODE:
```
kubectl get po -o wide | grep clickhouse
clickhouse-0                 0/1     CrashLoopBackOff   5          3m53s

kubeclt logs clickhouse-0
2021.12.14 14:53:13.631963 [ 1 ] {} <Error> Application: DB::Exception: Cannot lock file /var/lib/clickhouse/status. Another server instance in same directory is already running.
```

----------------------------------------

TITLE: Configure NGINX Log Forwarding to Docker
DESCRIPTION: Creates symbolic links to forward NGINX access and error logs to `/dev/stdout` and `/dev/stderr` respectively. This configuration allows Docker's log collector to capture NGINX logs, making them accessible via `docker logs`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v4/admin-guide/install.md#_snippet_106

LANGUAGE: Dockerfile
CODE:
```
RUN ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log
```

----------------------------------------

TITLE: Configure NGINX Plus as API Gateway
DESCRIPTION: Sets up NGINX Plus as a gateway to upstream API servers, defining the upstream block with multiple backend servers and a basic location for proxying requests to the API server.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-jwt-authentication.md#_snippet_0

LANGUAGE: nginx
CODE:
```
upstream api_server {
    server 10.0.0.1;
    server 10.0.0.2;
}

server {
    listen 80;

    location /products/ {
        proxy_pass http://api_server;
        #...
    }
}
```

----------------------------------------

TITLE: Update NGINX Controller TLS Certificates
DESCRIPTION: This snippet provides the command to update or replace the TLS certificates used for secure connections to NGINX Controller. It requires paths to the new certificate and key files.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/admin-guides/install/using-helper-script.md#_snippet_8

LANGUAGE: bash
CODE:
```
/opt/nginx-controller/helper.sh configtls <cert_file> <key_file>
```

LANGUAGE: APIDOC
CODE:
```
Options for configtls command:
cert_file: Certificate file path.
key_file: Key file path.
```

----------------------------------------

TITLE: Basic Node.js 'Hello World' Application
DESCRIPTION: A simple Node.js application using `unit-http` to create an HTTP server that responds with 'Hello, Node.js on Unit!'. This demonstrates the minimal setup for a Node.js app with NGINX Unit.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/howto/samples.md#_snippet_9

LANGUAGE: javascript
CODE:
```
#!/usr/bin/env node

require("unit-http").createServer(function (req, res) {
    res.writeHead(200, {"Content-Type": "text/plain"});
    res.end("Hello, Node.js on Unit!")
}).listen()
```

----------------------------------------

TITLE: Renew Expired Kubernetes Kubelet Certificates (Initial Steps)
DESCRIPTION: This sequence of commands provides the initial steps to stop the kubelet, renew all Kubernetes certificates using `kubeadm`, and reconfigure the `kubectl` context. These actions are crucial to resolve issues caused by expired certificates.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/releases/adc/adc-release-notes-3.20.md#_snippet_4

LANGUAGE: bash
CODE:
```
sudo systemctl stop kubelet
sudo kubeadm alpha certs renew all
cd
mv .kube/config .kube/config.old
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
sudo chmod 777 $HOME/.kube/config
export KUBECONFIG=.kube/config
sudo shutdown now -r
```

----------------------------------------

TITLE: Test HTTP to HTTPS Redirect with Curl
DESCRIPTION: This curl command sends an HTTP request to the configured gateway, resolving 'cafe.example.com' to the NGINX Service IP. The '--include' option is used to display response headers, verifying the HTTP to HTTPS redirect.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/https-termination.md#_snippet_9

LANGUAGE: shell
CODE:
```
curl --resolve cafe.example.com:$GW_HTTP_PORT:$GW_IP http://cafe.example.com:$GW_HTTP_PORT/coffee --include
```

----------------------------------------

TITLE: Exposing Application with HTTPRoute Routing Rule
DESCRIPTION: Example of an HTTPRoute routing rule used to expose an application. It defines a path prefix match and references a backend service by name and port.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/how-to/upgrade-apps-without-downtime.md#_snippet_0

LANGUAGE: yaml
CODE:
```
- matches:
    - path:
        type: PathPrefix
        value: /
  backendRefs:
    - name: my-app
      port: 80
```

----------------------------------------

TITLE: NGINX Plus JWT Validation with Subrequest Key Fetching
DESCRIPTION: Configures NGINX Plus to validate JWTs by dynamically fetching JSON Web Keys (JWKs) from a remote identity provider. The `auth_jwt_key_request` directive specifies an internal subrequest URI to retrieve the keys, enabling flexible and secure JWT authentication.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-jwt-authentication.md#_snippet_10

LANGUAGE: nginx
CODE:
```
http {
    #...

    server {
        listen 80;
            #...

        location / {
            auth_jwt "closed site";
            auth_jwt_key_request /_jwks_uri; # Keys will be fetched by subrequest

            proxy_pass http://my_backend;
        }
    }
}
```

----------------------------------------

TITLE: Configure NGINX Server Blocks with App Protect WAF and Proxy Pass
DESCRIPTION: This NGINX configuration defines two server blocks. The first block listens on port 80 for 'domain.com', enables NGINX App Protect WAF, sets a large client body size, and proxies requests to a backend server. The second block listens on port 8080 for 'localhost', serves static HTML files from '/usr/share/nginx/html', and redirects server errors to a custom 50x.html page.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/default-conf-hostname.md#_snippet_0

LANGUAGE: nginx
CODE:
```
server {
    listen 80;
    server_name domain.com;

    proxy_http_version 1.1;

    location / {

        # NGINX App Protect WAF
        app_protect_enable on;

        client_max_body_size 0;
        default_type text/html;
        proxy_pass http://127.0.0.1:8080/;
    }
}

server {
    listen 8080;
    server_name localhost;


    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }

    # redirect server error pages to the static page /50x.html
    #
    error_page 500 502 503 504 /50x.html;
    location = /50x.html {
        root /usr/share/nginx/html;
    }
}
```

----------------------------------------

TITLE: Configure NGINX Stream Proxy SSL for Upstream Servers
DESCRIPTION: This NGINX stream block configuration demonstrates how to secure TCP traffic forwarded to upstream backend servers using SSL/TLS. It defines an upstream group and a server block that listens on a specific port, proxies connections to the backend, and applies various proxy_ssl directives to manage certificates, specify protocols and ciphers, enable session reuse, and verify upstream server certificates for enhanced security.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/securing-tcp-traffic-upstream.md#_snippet_5

LANGUAGE: nginx
CODE:
```
stream {

    upstream backend {
        server backend1.example.com:12345;
        server backend2.example.com:12345;
        server backend3.example.com:12345;
   }

    server {
        listen     12345;
        proxy_pass backend;
        proxy_ssl  on;

        proxy_ssl_certificate         /etc/ssl/certs/backend.crt;
        proxy_ssl_certificate_key     /etc/ssl/certs/backend.key;
        proxy_ssl_protocols           TLSv1.2 TLSv1.3;
        proxy_ssl_ciphers             HIGH:!aNULL:!MD5;
        proxy_ssl_trusted_certificate /etc/ssl/certs/trusted_ca_cert.crt;

        proxy_ssl_verify        on;
        proxy_ssl_verify_depth  2;
        proxy_ssl_session_reuse on;
    }
}
```

----------------------------------------

TITLE: NGINX App Protect WAF JWT Claims Attribute Access Examples
DESCRIPTION: This snippet provides examples of how specific JWT claims are accessed and interpreted within NGINX App Protect WAF's authorization rules. It demonstrates accessing top-level claims, array elements (as strings), nested object properties, and handling non-existent claims or entire JSON structures.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v4/configuration-guide/configuration.md#_snippet_7

LANGUAGE: APIDOC
CODE:
```
claims['scope'] = "top-level:read"
claims['roles'] = "["inventory-manager", "price-editor]" # the whole array is presented as a string
claims['address.country'] = "US"
claims['company'] = null # does not exist
claims['address'] = "{ \"address\": { .... } }" # JSON structs can be accessed using the dot "." notation
```

----------------------------------------

TITLE: Increase NGINX File Descriptors for 'Too many open files' Error
DESCRIPTION: To resolve the 'Too many open files' error in NGINX, increase the number of file descriptors by adding the `worker_rlimit_nofile` directive to the main context of the `nginx.conf` file. This allows NGINX to handle more concurrent file operations.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/troubleshooting-guide/how-to-troubleshoot.md#_snippet_0

LANGUAGE: NGINX Config
CODE:
```
worker_rlimit_nofile 65535;
```

----------------------------------------

TITLE: Handling Index Files with Internal Redirects and PHP Processing in NGINX
DESCRIPTION: This NGINX configuration demonstrates how index file resolution can lead to internal redirects and subsequent processing by different `location` blocks. If `index.html` is not found, NGINX attempts `index.php`, which triggers an internal redirect to the `.php` location, passing the request to a FastCGI server for processing.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/web-server/serving-static-content.md#_snippet_3

LANGUAGE: Nginx
CODE:
```
location / {
    root /data;
    index index.html index.php;
}

location ~ \.php {
    fastcgi_pass localhost:8000;
    #...
}
```

----------------------------------------

TITLE: Inspect and Extract Tarball Archives (Bash)
DESCRIPTION: These commands are used to safely inspect the contents of a `.tar.gz` archive without extracting it, and to extract its contents. This is useful for verifying archive contents before unpacking to prevent accidental overwrites.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx-one/staged-configs/import-export-staged-config.md#_snippet_1

LANGUAGE: bash
CODE:
```
tar -tvzf <archive-name>.tar.gz
```

LANGUAGE: bash
CODE:
```
tar -xvzf <archive-name>.tar.gz
```

----------------------------------------

TITLE: Backup NGINX Instance Manager OIDC Configuration Files
DESCRIPTION: Creates backup copies of the original `openid_configuration.conf` and `nms-http.conf` files before modification to ensure a rollback option.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/admin-guide/authentication/oidc/keycloak-setup.md#_snippet_2

LANGUAGE: bash
CODE:
```
sudo cp /etc/nms/nginx/oidc/openid_configuration.conf ~/openid_configuration.conf.orig
sudo cp /etc/nginx/conf.d/nms-http.conf ~/nms-http.conf.orig
```

----------------------------------------

TITLE: NGINX Plus Firewall Configuration Requirements
DESCRIPTION: This table outlines the necessary firewall rules for an NGINX Plus load balancer, detailing required ports, source, and destination for various purposes like administration, software updates, and application traffic.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_0

LANGUAGE: APIDOC
CODE:
```
FirewallConfiguration:
  - Purpose: Admin access, file transfer
    Port: 22
    Source: Administrative network
    Destination: NGINX Plus load balancer
  - Purpose: Installation and update of NGINX Plus software
    Port: 443
    Source: NGINX Plus load balancer
    Destination: Repository: pkgs.nginx.com
  - Purpose: HTTP to HTTPS redirects
    Port: 80
    Source: Any
    Destination: NGINX Plus
  - Purpose: Production HTTPS traffic
    Port: 443
    Source: Any
    Destination: NGINX Plus
  - Purpose: Access to backend application
    Port: 8000*
    Source: NGINX Plus
    Destination: Backend application servers
  - Purpose: Access to load-balanced application from application servers
    Port: 443
    Source: Backend application servers
    Destination: NGINX Plus load balancer
```

----------------------------------------

TITLE: Add HTTP Strict Transport Security Headers to Nginx Gateway (JSON)
DESCRIPTION: This JSON snippet demonstrates how to add an HTTP Strict Transport Security (HSTS) header to an Nginx gateway configuration. It sets the 'Strict-Transport-Security' header with a max-age of one year and includes subdomains, ensuring browsers enforce HTTPS for subsequent visits.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/app-delivery/about-snippets.md#_snippet_2

LANGUAGE: json
CODE:
```
{
    "metadata": {
        "name": "<gateway-name>"
    },
    "desiredState": {
        "configSnippets": {
            "uriSnippets": [
                {
                    "applicableUris": [
                        {
                            "uri": "http://172.16.0.238:81"
                        }
                    ],
                    "directives": [
                        {
                            "directive": "add_header",
                            "args": ["Strict-Transport-Security", "max-age=31536000; includeSubDomains", "always"]
                        }
                    ]
                }
            ]
        },
        "ingress": {
            "uris": {
                "http://example.com:8020": {}
            },
            "placement":  {
                "instanceRefs": [
                    {
                        "ref": "/infrastructure/locations/unspecified/instances/<instance-name>"
                    }
                ]
            }
        }
    }
}
```

----------------------------------------

TITLE: Configuring NGINX Listen Directives for PROXY Protocol
DESCRIPTION: This snippet demonstrates how to enable the PROXY protocol on NGINX listen directives within both HTTP and Stream server blocks. Adding the 'proxy_protocol' parameter allows NGINX to correctly parse PROXY protocol headers from upstream proxies or load balancers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/using-proxy-protocol.md#_snippet_0

LANGUAGE: nginx
CODE:
```
http {
    #...
    server {
        listen 80   proxy_protocol;
        listen 443  ssl proxy_protocol;
        #...
    }
}

stream {
    #...
    server {
        listen 12345 proxy_protocol;
        #...
    }
}
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: Reload the NGINX configuration to apply the new settings without interrupting active connections, ensuring continuous service availability.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/admin-guide/authentication/oidc/microsoft-entra-setup.md#_snippet_5

LANGUAGE: bash
CODE:
```
sudo nginx -s reload
```

----------------------------------------

TITLE: Configure NGINX Global Settings
DESCRIPTION: This snippet shows essential global directives for NGINX's main configuration file, `nginx.conf`. It defines the user, worker processes, error logging, PID file location, and worker connection limits within the events block. These settings are fundamental for NGINX operation and performance.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_24

LANGUAGE: nginx
CODE:
```
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log info;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

# If using the standard configuration scheme, the 'http' and 'stream' blocks are
# usually placed here and enclose 'include' directives that refer to files in
# the conf.d directory.
```

----------------------------------------

TITLE: Define NGINX Health Check Match Criteria
DESCRIPTION: This configuration defines a `match` directive in the `http` context, specifying the criteria a server must meet to be considered healthy. It requires a 200 status code, a 'Content-Type' header of 'text/html', and a response body matching the regular expression 'Apache Tomcat/8'.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_29

LANGUAGE: nginx
CODE:
```
# In the 'http' block
match health_check {
    status 200;
    header Content-Type = text/html;
    body ~ "Apache Tomcat/8";
}
```

----------------------------------------

TITLE: Protect NGINX Location with Entra ID OIDC
DESCRIPTION: This NGINX configuration snippet demonstrates how to protect a specific location with Entra ID OIDC. The `auth_oidc` directive points to the 'entra' configuration, which should be defined in an `oidc_provider {}` context as specified in an earlier setup step.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/entra-id.md#_snippet_8

LANGUAGE: nginx
CODE:
```
# ...
location / {

         auth_oidc entra;

         # ...

         proxy_pass http://127.0.0.1:8080;

}
```

----------------------------------------

TITLE: NGINX Custom Header Value Prefixes Reference
DESCRIPTION: This table details the available prefixes for custom header values in NGINX configurations, specifying how different types of data (NGINX variables, client headers, client IP, static strings, or JWT token values) can be passed to the backend.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/how-to/policies/proxy-request-headers.md#_snippet_1

LANGUAGE: APIDOC
CODE:
```
Prefix | Example | Description
---|---|---
`var` | `var.content_length` | Pass a [valid NGINX variable](http://nginx.org/en/docs/varindex.html).
`header` | `header.referrer` | Pass a header from the client request.
`client` | `client.IP` | Pass a value from the client if a Basic Auth or API Key policy has been configured.
`stringValue` | `stringValue.MyString` | Pass a static string.
`token` | `token.sub` | Pass a value from the JSON Web Token (JWT) if the OAuth2 JWT Assertion policy has been configured.
```

----------------------------------------

TITLE: Configuring NGINX Health Check with Custom Match Conditions
DESCRIPTION: This example shows how to define specific conditions within an NGINX `match` block, such as a status code range (200-399) and the absence of 'maintenance mode' in the response body. It also illustrates how to reference this `match` block from the `health_check` directive within a `location` block.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-health-check.md#_snippet_9

LANGUAGE: nginx
CODE:
```
http {
    #...
    match server_ok {
        status 200-399;
        body   !~ "maintenance mode";
    }
    server {
        #...
        location / {
            proxy_pass   http://backend;
            health_check match=server_ok;
        }
    }
}
```

----------------------------------------

TITLE: Configure Nginx HTTP Global Settings and Logging
DESCRIPTION: This snippet sets up global HTTP parameters within Nginx, including a custom log format, the path for access logs, connection timeouts for keepalive and proxy reads, TCP nodelay for efficient data transfer, and an include directive for a separate status configuration file.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_60

LANGUAGE: nginx
CODE:
```
http {
    log_format main '$remote_addr - $remote_user [$time_local]
                    "$request" $status $body_bytes_sent "$http_referer"
                    "$http_user_agent" $upstream_addr';
    access_log /var/log/nginx/access.log main;
    keepalive_timeout 3h;
    proxy_read_timeout 3h;
    tcp_nodelay on;

    # If this file serves as the main nginx.conf file (contains your entire
    # site configuration), this 'include' directive reads in the
    # configuration file for live activity monitoring. If creating a
    # separate conf.d/exchange-http.conf file, put this directive in the main
    # nginx.conf file instead.
    include conf.d/status.conf;
```

----------------------------------------

TITLE: Include NGINX Configuration File in HTTP Block
DESCRIPTION: Example of adding an `include` directive within the `http` block of the main `nginx.conf` file. This allows incorporating function-specific configuration files from the `conf.d` directory, promoting a modular setup.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_4

LANGUAGE: nginx
CODE:
```
http {
    include conf.d/weblogic-(basic|enhanced).conf;
}
```

----------------------------------------

TITLE: NGINX: Configure Proxy Pass for HTTPS Upstream
DESCRIPTION: This NGINX configuration snippet shows how to configure the `proxy_pass` directive to use the `https` protocol. This ensures that NGINX forwards requests to an upstream server over an encrypted SSL/TLS connection.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/securing-http-traffic-upstream.md#_snippet_0

LANGUAGE: nginx
CODE:
```
location /upstream {
    proxy_pass https://backend.example.com;
}
```

----------------------------------------

TITLE: Configure NGINX Session Persistence with Custom Hash ($remote_addr)
DESCRIPTION: This NGINX configuration snippet illustrates how to implement session persistence using the `hash` load-balancing method, basing the hash on the full client IP address (`$remote_addr`). This provides an alternative to `ip_hash` for scenarios where more granular control over the hashing key is desired, allowing for custom combinations of text and NGINX variables.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_13

LANGUAGE: nginx
CODE:
```
# In the 'http' block
upstream weblogic {
    hash $remote_addr;
    server 192.168.25.33:7001;
    server 192.168.25.69:7001;
}
```

----------------------------------------

TITLE: Reload NGINX Plus Configuration
DESCRIPTION: Command to apply changes to the NGINX Plus configuration after modifications have been made.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nginx-plus/usage-tracking/agentless-reporting.md#_snippet_4

LANGUAGE: shell
CODE:
```
sudo nginx -s reload
```

----------------------------------------

TITLE: Initial Nginx RateLimit Policy YAML Definition
DESCRIPTION: This YAML defines a Kubernetes `RateLimit` custom resource named `ratelimit-v1`. It specifies `dest-svc` as the destination and `client-v1` as the source, limiting requests to 10 per minute.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/ratelimit-walkthrough.md#_snippet_8

LANGUAGE: yaml
CODE:
```
apiVersion: specs.smi.nginx.com/v1alpha2
kind: RateLimit
metadata:
  name: ratelimit-v1
  namespace: default
spec:
  destination:
    kind: Service
    name: dest-svc
    namespace: default
  sources:
  - kind: Deployment
    name: client-v1
    namespace: default
  name: 10rm
  rate: 10r/m
```

----------------------------------------

TITLE: Configure NGINX Unit for Flask Application Deployment
DESCRIPTION: This JSON configuration snippet sets up NGINX Unit to serve the Flask application. It defines a listener on port 80 that passes requests to the 'flask' application. The application configuration specifies the Python version, the path to the WSGI module, the virtual environment's home directory, and the module and callable names for the Flask app.
SOURCE: https://github.com/nginx/documentation/blob/main/content/unit/howto/frameworks/flask.md#_snippet_2

LANGUAGE: json
CODE:
```
{
   "listeners": {
      "*:80": {
         "pass": "applications/flask"
      }
   },
   "applications": {
      "flask": {
         "type": "python 3.Y",
         "type_comment": "Must match language module version and virtual environment version",
         "path": "/path/to/app/",
         "path_comment": "Path to the WSGI module",
         "home": "/path/to/app/venv/",
         "home_comment": "Path to the virtual environment, if any",
         "module": "wsgi",
         "module_comment": "WSGI module filename with extension omitted",
         "callable": "app",
         "callable_comment": "Name of the callable in the module to run"
      }
   }
}
```

----------------------------------------

TITLE: Enable Automatic Sidecar Injection for Namespace
DESCRIPTION: This command applies a label to a Kubernetes namespace, enabling automatic sidecar proxy injection for all pods within that namespace. This simplifies the management of sidecars across multiple resources.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/guides/inject-sidecar-proxy.md#_snippet_0

LANGUAGE: bash
CODE:
```
kubectl label namespaces <namespace name> injector.nsm.nginx.com/auto-inject=enabled
```

----------------------------------------

TITLE: Attach NginxProxy to Gateway via parametersRef
DESCRIPTION: This YAML snippet shows the `infrastructure.parametersRef` configuration that needs to be added to a Gateway's `spec`. It specifies the `group`, `kind`, and `name` of the `NginxProxy` resource to be attached, linking the Gateway to its custom configuration.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/how-to/data-plane-configuration.md#_snippet_11

LANGUAGE: yaml
CODE:
```
infrastructure:
    parametersRef:
        group: gateway.nginx.org
        kind: NginxProxy
        name: ngf-proxy-config
```

----------------------------------------

TITLE: Configure NGINX App Protect DoS API and Dashboard
DESCRIPTION: This section provides a series of NGINX configuration examples to activate and secure the NGINX App Protect DoS REST API and enable the DoS Dashboard. These steps demonstrate defining server blocks, creating API locations, applying access restrictions, implementing basic authentication, and setting up the dashboard HTML location.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/monitoring/live-activity-monitoring.md#_snippet_0

LANGUAGE: nginx
CODE:
```
http {
    server {
        # insert your API configuration here
    }
}
```

LANGUAGE: nginx
CODE:
```
http {
    # ...
    server {
        listen 192.168.1.23;
        # ...
        location /api {
            app_protect_dos_api;
            # ...
        }
    }
}
```

LANGUAGE: nginx
CODE:
```
http {
    # ...
    server {
        listen 192.168.1.23;
        # ...
        location /api {
            app_protect_dos_api;
            allow 192.168.1.0/24;
            deny all;
        }
    }
}
```

LANGUAGE: nginx
CODE:
```
http {
    # ...
    server {
        listen 192.168.1.23;
        # ...
        location /api {
            limit_except GET {
                auth_basic "NGINX Plus API";
                auth_basic_user_file /path/to/passwd/file;
            }
            app_protect_dos_api;
            allow 192.168.1.0/24;
            deny  all;
        }
    }
}
```

LANGUAGE: nginx
CODE:
```
http {
    # ...
    server {
        listen 192.168.1.23;
        # ...
        location /api {
            limit_except GET {
                auth_basic "NGINX Plus API";
                auth_basic_user_file /path/to/passwd/file;
            }
            app_protect_dos_api;
            allow 192.168.1.0/24;
            deny  all;
        }
        location = /dashboard-dos.html {
            root   /usr/share/nginx/html;
        }
    }
}
```

----------------------------------------

TITLE: Dockerfile for NGINX App Protect WAF on Alpine Linux
DESCRIPTION: This Dockerfile provides instructions for building a Docker image with NGINX App Protect WAF on Alpine Linux. It includes steps for adding NGINX signing keys, configuring NGINX Plus and App Protect repositories, installing the WAF package, forwarding logs, and copying configuration files.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v4/admin-guide/install.md#_snippet_189

LANGUAGE: dockerfile
CODE:
```
# Download and add the NGINX signing keys:
RUN wget -O /etc/apk/keys/nginx_signing.rsa.pub https://cs.nginx.com/static/keys/nginx_signing.rsa.pub \
 && wget -O /etc/apk/keys/app-protect-security-updates.rsa.pub https://cs.nginx.com/static/keys/app-protect-security-updates.rsa.pub

# Add NGINX Plus repository:
RUN printf "https://pkgs.nginx.com/plus/alpine/v`egrep -o '^[0-9]+\\.[0-9]+' /etc/alpine-release`/main\n" | tee -a /etc/apk/repositories

# Add NGINX App Protect repository:
RUN printf "https://pkgs.nginx.com/app-protect/alpine/v`egrep -o '^[0-9]+\\.[0-9]+' /etc/alpine-release`/main\n" | tee -a /etc/apk/repositories \
 && printf "https://pkgs.nginx.com/app-protect-security-updates/alpine/v`egrep -o '^[0-9]+\\.[0-9]+' /etc/alpine-release`/main\n" | tee -a /etc/apk/repositories

# Update the repository and install the most recent version of the NGINX App Protect WAF package (which includes NGINX Plus):
RUN --mount=type=secret,id=nginx-crt,dst=/etc/apk/cert.pem,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/apk/cert.key,mode=0644 \
    apk update && apk add app-protect

# Forward request logs to Docker log collector:
RUN ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Copy configuration files:
COPY nginx.conf custom_log_format.json /etc/nginx/
COPY entrypoint.sh /root/

CMD ["sh", "/root/entrypoint.sh"]
```

----------------------------------------

TITLE: NGINX: Simple Backend Application for OIDC Claims
DESCRIPTION: This NGINX server block defines a simple backend application listening on port 8080. It returns a plain text response that includes the authenticated user's name, email, and subject identifier, which are received as HTTP headers from the upstream NGINX proxy. This demonstrates how the backend consumes OIDC claims.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/cognito.md#_snippet_7

LANGUAGE: nginx
CODE:
```
server {
    listen 8080;

    location / {
        return 200 "Hello, $http_name!\nEmail: $http_email\nSub: $http_sub\n";
        default_type text/plain;
    }
}
```

----------------------------------------

TITLE: Nginx: Complete Example for IP Restriction and Basic Auth
DESCRIPTION: This comprehensive Nginx configuration example demonstrates how to protect a specific location (`/api`) by combining IP address restrictions and HTTP basic authentication. It uses `satisfy all` to require both conditions to be met for access, and includes server-level configuration for listening on a specific IP and port, and defining the document root.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-http-basic-authentication.md#_snippet_7

LANGUAGE: nginx
CODE:
```
http {
    server {
        listen 192.168.1.23:8080;
        root   /usr/share/nginx/html;

        location /api {
            api;
            satisfy all;

            deny  192.168.1.2;
            allow 192.168.1.1/24;
            allow 127.0.0.1;
            deny  all;

            auth_basic           "Administrator’s Area";
            auth_basic_user_file /etc/apache2/.htpasswd;
        }
    }
}
```

----------------------------------------

TITLE: NGINX App Protect WAF GraphQL Policy with Alarm-Only Violations
DESCRIPTION: This JSON configuration defines a NGINX App Protect WAF policy named 'graphql_policy'. It sets the enforcement mode to 'blocking' but specifically configures the new GraphQL violations (format, malformed, introspection query, and error response) to 'alarm: true' and 'block: false'. This allows the WAF to detect and log these violations without immediately blocking the associated requests, contributing to the Violation Rating instead.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/nap-waf/config/common/graphql-violations.md#_snippet_0

LANGUAGE: JSON
CODE:
```
{
    "name": "graphql_policy",
    "template": {
        "name": "POLICY_TEMPLATE_NGINX_BASE"
    },
    "applicationLanguage": "utf-8",
    "caseInsensitive": false,
    "enforcementMode": "blocking",
    "blocking-settings": {
        "violations": [
            {
                "name": "VIOL_GRAPHQL_FORMAT",
                "alarm": true,
                "block": false
            },
            {
                "name": "VIOL_GRAPHQL_MALFORMED",
                "alarm": true,
                "block": false
            },
            {
                "name": "VIOL_GRAPHQL_INTROSPECTION_QUERY",
                "alarm": true,
                "block": false
            },
            {
                "name": "VIOL_GRAPHQL_ERROR_RESPONSE",
                "alarm": true,
                "block": false
            }
        ]
    }
}
```

----------------------------------------

TITLE: NGINX Custom Hash Load Balancing for Session Persistence
DESCRIPTION: This NGINX configuration snippet illustrates the use of the `hash` directive for session persistence, allowing the hash to be based on a specified NGINX variable. In this example, it uses `$remote_addr` (client IP address) to hash requests, ensuring that a client's requests are directed to the same upstream server, similar to `ip_hash` but offering more flexibility for custom hashing criteria.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/wildfly.md#_snippet_15

LANGUAGE: nginx
CODE:
```
# In the 'http' block
upstream jboss {
    hash $remote_addr;
    server 192.168.33.11:8080;
    server 192.168.33.12:8080;
}
```

----------------------------------------

TITLE: Enable NGINX Server Slow Start in Upstream Group
DESCRIPTION: This snippet demonstrates how to configure the `slow_start` parameter for servers within an NGINX `upstream` block. This feature gradually increases traffic to a recovering or new server, preventing it from being overwhelmed during startup.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-weblogic-server.md#_snippet_26

LANGUAGE: nginx
CODE:
```
# In the 'upstream' block
server 192.168.25.33:7001 slow_start=30s;
server 192.168.25.69:7001 slow_start=30s;
```

----------------------------------------

TITLE: NGINX Global Policy: Log Format
DESCRIPTION: Generates detailed access logs in JSON (default) or syslog format. Allows fine-tuning of logged content, setting log destination, and adjusting log severity levels. This policy is applied by default to both HTTP and gRPC environments and affects outbound traffic.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/acm/about/global-policies.md#_snippet_1

LANGUAGE: APIDOC
CODE:
```
Policy Name: Log Format
HTTP Environment: Supported (Default)
gRPC Environment: Supported (Default)
Applied On: Outbound
Description: Use the Log Format global policy to generate detailed access logs in JSON (default) or syslog format. Among the settings you can select, use the filter to fine-tune what gets logged, set the log destination, and adjust the log severity level to specify the type of errors to log.
```

----------------------------------------

TITLE: Verify and Reload NGINX Configuration
DESCRIPTION: These shell commands are used to manage the NGINX service. `nginx -t` tests the syntax of the NGINX configuration files for any errors, ensuring the configuration is valid. `nginx -s reload` then gracefully reloads the NGINX service, applying the new configuration without interrupting active connections.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/amazon-web-services/route-53-global-server-load-balancing.md#_snippet_4

LANGUAGE: shell
CODE:
```
nginx -t
nginx -s reload
```

----------------------------------------

TITLE: Configure Traffic Split to Shift Traffic to Target App v2.1
DESCRIPTION: Modifies the `trafficsplit.yaml` configuration to direct all traffic (100% weight) to `target-v2-1` and zero traffic (0% weight) to `target-v1-0`. This allows for a quick rollback if needed by simply changing weights.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/trafficsplit-deployments.md#_snippet_14

LANGUAGE: yaml
CODE:
```
apiVersion: split.smi-spec.io/v1alpha3
kind: TrafficSplit
metadata:
  name: target-ts
spec:
  service: target-svc
  backends:
  - service: target-v1-0
    weight: 0
  - service: target-v2-1
    weight: 100
```

----------------------------------------

TITLE: Update APT Repository Information on Debian/Ubuntu
DESCRIPTION: This command refreshes the package index files from all configured repositories. It is a crucial step after adding new repositories or before installing new packages, ensuring that the system has the latest information about available software on Debian and Ubuntu systems.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/installing-nginx/installing-nginx-plus.md#_snippet_6

LANGUAGE: shell
CODE:
```
sudo apt update
```

----------------------------------------

TITLE: Pass OIDC Claims as Headers in NGINX
DESCRIPTION: This NGINX configuration shows how to extract OIDC claims (like subject, email, and name) from the ID token and pass them as custom HTTP headers to the backend application using `proxy_set_header`. This allows the application to access authenticated user information.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/active-directory-federation-services.md#_snippet_7

LANGUAGE: nginx
CODE:
```
# ...
location / {

         auth_oidc adfs;

         proxy_set_header sub   $oidc_claim_sub;
         proxy_set_header email $oidc_claim_email;
         proxy_set_header name  $oidc_claim_name;

         proxy_pass http://127.0.0.1:8080;
}
```

----------------------------------------

TITLE: Nginx Full Configuration for Enhanced Load Balancing
DESCRIPTION: This Nginx configuration snippet provides a complete setup for an Nginx server, including user and worker process definitions, error logging, and PID file location. It also configures event settings for worker connections and offers guidance on integrating the HTTP block for load balancing, either directly in nginx.conf or in a separate conf.d file.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_59

LANGUAGE: nginx
CODE:
```
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log info;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

# If placing all directives in the main nginx.conf file, copy the following
# 'http' block into it, including the initial and final lines ('http { ... }')
# which open and close the 'http' context.

# If creating a separate conf.d/exchange-http.conf file, either exclude the
# initial and final lines from the copied region, or copy them but comment
```

----------------------------------------

TITLE: Secure NGINX Plus API Access with IP and Basic Auth
DESCRIPTION: Enhances API security by restricting access to localhost (127.0.0.1) and enforcing HTTP basic authentication for non-GET methods (PATCH, POST, DELETE) to a specified set of users.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/denylisting-ip-addresses.md#_snippet_4

LANGUAGE: nginx
CODE:
```
# ...
server {
    listen 80;
    server_name www.example.com;

    location /api {
        api   write=on;

        allow 127.0.0.1;
        deny  all;

        limit_except GET {
            auth_basic "NGINX Plus API";
            auth_basic_user_file /path/to/passwd/file;
        }
    }
}
```

----------------------------------------

TITLE: Dockerfile for NGINX App Protect WAF on RHEL UBI9
DESCRIPTION: This Dockerfile outlines the process to create a Docker image with NGINX App Protect WAF on Red Hat Universal Base Image 9. It covers installing prerequisites, adding NGINX Plus and App Protect repositories, installing WAF, configuring log forwarding, and copying application files.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v4/admin-guide/install.md#_snippet_100

LANGUAGE: dockerfile
CODE:
```
# syntax=docker/dockerfile:1
# For RHEL ubi9:
FROM registry.access.redhat.com/ubi9/ubi

# Install prerequisite packages:
RUN dnf -y install wget ca-certificates

# Add NGINX Plus repo to Yum:
RUN wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/plus-9.repo

# Add NGINX App-protect & dependencies repo to Yum:
RUN wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/app-protect-9.repo
RUN wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/dependencies.repo \
    # You can use either of the dependencies or epel repo
    # && rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm \
    && dnf clean all

# Install NGINX App Protect WAF:
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    dnf install --enablerepo=codeready-builder-for-rhel-9-x86_64-rpms -y app-protect \
    && dnf clean all \
    && rm -rf /var/cache/dnf

# Forward request logs to Docker log collector:
RUN ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Copy configuration files:
COPY nginx.conf custom_log_format.json /etc/nginx/
COPY entrypoint.sh /root/

CMD ["sh", "/root/entrypoint.sh"]
```

----------------------------------------

TITLE: Dockerfile for NGINX App Protect WAF on Amazon Linux 2023
DESCRIPTION: This Dockerfile outlines the process to install NGINX App Protect WAF on Amazon Linux 2023. It covers installing prerequisites, adding NGINX Plus and App Protect repositories, installing the WAF, cleaning up, forwarding logs, and copying necessary configuration files.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v4/admin-guide/install.md#_snippet_190

LANGUAGE: dockerfile
CODE:
```
# syntax=docker/dockerfile:1
# For Amazon Linux 2023:
FROM amazonlinux:2023

# Install prerequisite packages:
RUN dnf -y install wget ca-certificates

# Add NGINX Plus repo:
RUN wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/plus-amazonlinux2023.repo

# Add NAP dependencies repo:
RUN wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/dependencies.amazonlinux2023.repo

# Add NGINX App-protect repo:
RUN wget -P /etc/yum.repos.d https://cs.nginx.com/static/files/app-protect-amazonlinux2023.repo

# Install NGINX App Protect WAF:
RUN --mount=type=secret,id=nginx-crt,dst=/etc/ssl/nginx/nginx-repo.crt,mode=0644 \
    --mount=type=secret,id=nginx-key,dst=/etc/ssl/nginx/nginx-repo.key,mode=0644 \
    dnf -y install app-protect \
    && dnf clean all \
    && rm -rf /var/cache/yum

# Forward request logs to Docker log collector:
RUN ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log

# Copy configuration files:
COPY nginx.conf custom_log_format.json /etc/nginx/
COPY entrypoint.sh /root/

CMD ["sh", "/root/entrypoint.sh"]
```

----------------------------------------

TITLE: Executing Entrypoint Script and Keeping Container Alive
DESCRIPTION: This snippet defines the default command to run when the Docker container starts. It executes the 'entrypoint.sh' script and then uses 'tail -f /dev/null' to keep the container running indefinitely, preventing it from exiting immediately.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/deployment-guide/learn-about-deployment.md#_snippet_165

LANGUAGE: Dockerfile
CODE:
```
CMD /root/entrypoint.sh && tail -f /dev/null
```

----------------------------------------

TITLE: Verify NGINX Open Source status using curl
DESCRIPTION: This command sends an HTTP HEAD request to the local NGINX instance to confirm that it is actively serving requests. A successful response with a `200 OK` status indicates NGINX is running correctly.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/installing-nginx/installing-nginx-open-source.md#_snippet_72

LANGUAGE: shell
CODE:
```
curl -I 127.0.0.1
```

----------------------------------------

TITLE: Verifying Docker Container Status
DESCRIPTION: Lists all currently running Docker containers to confirm that a specific container, such as 'my-app-protect-dos', is active and operational.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/deployment-guide/learn-about-deployment.md#_snippet_146

LANGUAGE: shell
CODE:
```
docker ps
```

----------------------------------------

TITLE: NGINX Global Policy: OpenID Connect Relying Party
DESCRIPTION: Secures API access by configuring the API gateway proxy as a relying party for authenticating users with an OIDC provider. This policy is supported for HTTP environments but not gRPC, and it applies to inbound traffic.
SOURCE: https://github.com/nginx/documentation/blob/main/content/includes/acm/about/global-policies.md#_snippet_2

LANGUAGE: APIDOC
CODE:
```
Policy Name: OpenID Connect Relying Party
HTTP Environment: Supported
gRPC Environment: Not Supported
Applied On: Inbound
Description: Secure access to your APIs with an OpenID Connect (OIDC) policy. This policy configures the API gateway proxy as a relying party for authenticating users with an OIDC provider.
```

----------------------------------------

TITLE: Differentiate JWT Authentication and Authorization Errors in NGINX Plus
DESCRIPTION: This snippet shows how to use multiple 'auth_jwt_require' directives to differentiate between authentication and authorization failures. By assigning a custom error code (e.g., 403) to a specific 'auth_jwt_require' directive, NGINX Plus can provide distinct error responses for different validation stages.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/configuring-jwt-authentication.md#_snippet_14

LANGUAGE: nginx
CODE:
```
    location /products/ {
        auth_jwt          "API";
        auth_jwt_key_file conf/api_secret.jwk;
        auth_jwt_require  $valid_app_id $valid_issuer $valid_scope;
        auth_jwt_require  $valid_scope error=403;
        proxy_pass        http://api_server;
    }
```

----------------------------------------

TITLE: Full NGINX Configuration with App Protect WAF Integration
DESCRIPTION: This comprehensive `nginx.conf` file demonstrates a complete NGINX configuration, including the integration of NGINX App Protect WAF. It defines worker processes, error logging, event settings, HTTP context with MIME types, access logging, and the `app_protect_enforcer_address`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v5/admin-guide/deploy-on-docker.md#_snippet_4

LANGUAGE: NGINX
CODE:
```
user  nginx;
worker_processes  auto;

# NGINX App Protect WAF
load_module modules/ngx_http_app_protect_module.so;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    # NGINX App Protect WAF
    app_protect_enforcer_address waf-enforcer:50000;

    include /etc/nginx/conf.d/*.conf;
}
```

----------------------------------------

TITLE: Test NGINX Plus Configuration Syntax
DESCRIPTION: Command to verify the syntax of the NGINX Plus configuration file after making changes.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/dynamic-modules/geoip2.md#_snippet_2

LANGUAGE: shell
CODE:
```
nginx -t
```

----------------------------------------

TITLE: Configure NGINX Plus Server for OIDC Protected Application
DESCRIPTION: Set up an NGINX `server` block with SSL and a `location` block that proxies requests to the OIDC-protected application, typically running on a local address like `http://127.0.0.1:8080`. This server will handle incoming requests and apply OIDC protection.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/keycloak.md#_snippet_6

LANGUAGE: nginx
CODE:
```
http {
    # ...

    server {
        listen      443 ssl;
        server_name demo.example.com;

        ssl_certificate     /etc/ssl/certs/fullchain.pem;
        ssl_certificate_key /etc/ssl/private/key.pem;

        location / {

            # ...

            proxy_pass http://127.0.0.1:8080;
        }
    }
    # ...
}
```

----------------------------------------

TITLE: Configure HTTPRoute for Redirect and Backend Routing
DESCRIPTION: This YAML defines two Kubernetes HTTPRoute resources. The first, 'cafe-tls-redirect', enforces an HTTP to HTTPS redirect for 'cafe.example.com'. The second, 'coffee', routes requests with the '/coffee' path prefix on the HTTPS listener to the 'coffee' backend service.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/https-termination.md#_snippet_8

LANGUAGE: yaml
CODE:
```
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: cafe-tls-redirect
spec:
  parentRefs:
  - name: cafe
    sectionName: http
  hostnames:
  - "cafe.example.com"
  rules:
  - filters:
    - type: RequestRedirect
      requestRedirect:
        scheme: https
        port: 443
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: coffee
spec:
  parentRefs:
  - name: cafe
    sectionName: https
  hostnames:
  - "cafe.example.com"
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /coffee
    backendRefs:
    - name: coffee
      port: 80
```

----------------------------------------

TITLE: Configuring Azure VNet Peering with Terraform HCL
DESCRIPTION: This Terraform HCL snippet configures bidirectional virtual network peering between a primary and a secondary VNet in Azure. It ensures that resources in one VNet can communicate with resources in the other, which is crucial for cross-region NGINXaaS deployments to access backend servers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginxaas-azure/disaster-recovery.md#_snippet_5

LANGUAGE: HCL
CODE:
```
resource "azurerm_virtual_network_peering" "primary_vnet_to_secondary_vnet" {
  name                      = "peering-primary-vnet-to-secondary-vnet"
  resource_group_name       = var.primary_resource_group
  virtual_network_name      = azurerm_virtual_network.primary_virtual_network.name
  remote_virtual_network_id = azurerm_virtual_network.secondary_virtual_network.id
}

resource "azurerm_virtual_network_peering" "secondary_vnet_to_primary_vnet" {
  name                      = "peering-secondary-vnet-to-primary-vnet"
  resource_group_name       = var.resource_group_secondary
  virtual_network_name      = azurerm_virtual_network.secondary_virtual_network.name
  remote_virtual_network_id = azurerm_virtual_network.primary_virtual_network.id
}
```

----------------------------------------

TITLE: Manage NGINX Controller Process
DESCRIPTION: Commands to start, stop, restart, and check the status of the NGINX Controller process using the `helper.sh` script, providing essential control over the NGINX Controller service.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/admin-guides/install/install-nginx-controller.md#_snippet_9

LANGUAGE: bash
CODE:
```
/opt/nginx-controller/helper.sh controller start
/opt/nginx-controller/helper.sh controller stop
/opt/nginx-controller/helper.sh controller restart
/opt/nginx-controller/helper.sh controller status
```

----------------------------------------

TITLE: Mapping Citrix ADC Virtual Server Configuration to NGINX Plus
DESCRIPTION: This snippet illustrates the conversion of virtual server configurations from Citrix ADC CLI to NGINX Plus. It shows how Citrix ADC uses IP address and port, while NGINX Plus's "server" block can also incorporate Host header matching via the "server_name" directive.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/migrate-hardware-adc/citrix-adc-configuration.md#_snippet_0

LANGUAGE: none
CODE:
```
add lb vserver myvserver HTTP 10.0.0.99 80
```

LANGUAGE: nginx
CODE:
```
server {
    listen 10.0.0.99:80;
    server_name .example.com;
    #...
}
```

----------------------------------------

TITLE: Configure Nginx Server for HTTP to HTTPS Redirection
DESCRIPTION: This Nginx server block is configured to listen on port 80 for incoming HTTP requests. Its sole purpose is to redirect all HTTP traffic to their corresponding HTTPS URLs, ensuring that all communication with the Exchange services is secure and encrypted.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/microsoft-exchange.md#_snippet_63

LANGUAGE: nginx
CODE:
```
    server {
        listen 80;

        location / {
            return 301 https://$host$request_uri;
        }
    }
```

----------------------------------------

TITLE: Harden NGINX App Protect WAF Security with Fail-Closed Directives
DESCRIPTION: This example shows how to configure NGINX App Protect WAF to 'fail-closed' by adding HTTP snippets to the Gateway API. It sets 'app_protect_failure_mode_action', 'app_protect_compressed_requests_action', and 'app_protect_request_buffer_overflow_action' directives to 'drop', ensuring application traffic is dropped under specific conditions for enhanced security.
SOURCE: https://github.com/nginx/documentation/blob/main/content/controller/app-delivery/security/concepts/extend-app-security-snippets.md#_snippet_2

LANGUAGE: json
CODE:
```
{
    "metadata": {
        "name": "gateway-name"
    },
    "desiredState": {
        "configSnippets": {
            "httpSnippet": {
                "directives": [
                    {
                        "directive": "app_protect_failure_mode_action",
                        "args": ["drop"]
                    },
                    {
                        "directive": "app_protect_compressed_requests_action",
                        "args": ["drop"]
                    },
                    {
                        "directive": "app_protect_request_buffer_overflow_action",
                        "args": ["drop"]
                    }
                ]
            }
        },
        "ingress": {
            "uris": {
                "http://example.com:8000": {}
            },
            "placement":  {
                "instanceRefs": [
                    {
                        "ref": "/infrastructure/locations/unspecified/instances/<instance-name>"
                    }
                ]
            }
        }
    }
}
```

----------------------------------------

TITLE: Docker Compose Configuration for NGINX App Protect WAF
DESCRIPTION: This YAML configuration defines the Docker Compose setup for deploying NGINX App Protect WAF. It includes services for `waf-enforcer` and `waf-config-mgr`, specifying their images, ports, volumes, and network configurations. Users should replace version tags with their specific release.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v5/admin-guide/install.md#_snippet_40

LANGUAGE: yaml
CODE:
```
services:
  waf-enforcer:
    container_name: waf-enforcer
    image: waf-enforcer:5.2.0
    environment:
      - ENFORCER_PORT=50000
    ports:
      - "50000:50000"
    volumes:
      - /opt/app_protect/bd_config:/opt/app_protect/bd_config
    networks:
      - waf_network
    restart: always

  waf-config-mgr:
    container_name: waf-config-mgr
    image: waf-config-mgr:5.2.0
    volumes:
      - /opt/app_protect/bd_config:/opt/app_protect/bd_config
      - /opt/app_protect/config:/opt/app_protect/config
      - /etc/app_protect/conf:/etc/app_protect/conf
    restart: always
    network_mode: none
    depends_on:
      waf-enforcer:
        condition: service_started

networks:
  waf_network:
    driver: bridge
```

----------------------------------------

TITLE: NGINX Match Directive for Specific Status, Header, and Body Content
DESCRIPTION: This NGINX `match` directive example demonstrates how to combine conditions for a health check: requiring a 200 status code, an exact `Content-Type` header value of `text/html`, and the presence of 'Welcome to nginx!' in the response body using a regular expression.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/http-health-check.md#_snippet_10

LANGUAGE: nginx
CODE:
```
match welcome {
    status 200;
    header Content-Type = text/html;
    body   ~ "Welcome to nginx!";
}
```

----------------------------------------

TITLE: Reload NGINX Configuration
DESCRIPTION: These commands illustrate how to instruct NGINX Open Source or NGINX Plus to apply updated configuration files without stopping the service. The `nginx -s reload` command is a direct NGINX control, while `service nginx reload` uses the system's service manager.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_11

LANGUAGE: Shell
CODE:
```
root# nginx -s reload
```

LANGUAGE: Shell
CODE:
```
root# service nginx reload
```

----------------------------------------

TITLE: Example JWT Claims Payload
DESCRIPTION: This JSON snippet illustrates a sample JWT payload structure, including top-level claims like 'scope', 'roles' (as an array), 'sub', and a nested 'address' object. It serves as a reference for understanding how claims are structured before being processed by authorization rules.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-waf/v4/configuration-guide/configuration.md#_snippet_6

LANGUAGE: json
CODE:
```
{
    "scope": "top-level:read",
    "roles": [
        "inventory-manager",
        "price-editor"
    ],
    "sub": "joe@doe.com",
    "address": {
        "country": "US",
        "state": "NY",
        "city": "New York",
        "street": "888 38th W"
    }
}
```

----------------------------------------

TITLE: Analyzing NGINX TLS Log File with Shell Script
DESCRIPTION: This shell command processes the `/tmp/sslparams.log` file to analyze the distribution of SSL ciphers used by clients. It extracts the cipher field, sorts and counts unique ciphers, then sorts them by frequency in reverse numerical order. Finally, it uses a Perl one-liner to format the output, displaying each cipher and a visual representation of its count using equals signs, helping identify low-volume or less secure ciphers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/monitoring/logging.md#_snippet_7

LANGUAGE: shell
CODE:
```
cat /tmp/sslparams.log | cut -d ' ' -f 2,2 | sort | uniq -c | sort -rn | perl -ane 'printf "%30s %s\n", $F[1], "="x$F[0];'
```

----------------------------------------

TITLE: Configure NGINX Plus Reverse Proxy
DESCRIPTION: Creates the /etc/nginx/conf.d/proxy.conf file to configure a virtual server that listens on port 80, proxies all requests to http://localhost:8085, and sets the Host header. This configuration requires disabling any other virtual servers listening on port 80.
SOURCE: https://github.com/nginx/documentation/blob/main/content/modsec-waf/admin-guide/nginx-plus-modsecurity-waf-installation-logging.md#_snippet_6

LANGUAGE: nginx
CODE:
```
server {
    listen 80;
    location / {
        proxy_pass http://localhost:8085;
        proxy_set_header Host $host;
    }
}
```

----------------------------------------

TITLE: Configure NGINX Location Blocks for Proxying and Redirection
DESCRIPTION: This NGINX configuration snippet, intended for an HTTPS 'server' block, defines two 'location' blocks. The first proxies requests for paths starting with '/webapp/' to the 'nodejs' upstream group. The second performs a temporary redirect (302) of root ('/') requests to '/webapp/', funneling all initial traffic to the web application.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_15

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
location /webapp/ {
    proxy_pass http://nodejs;
}

location = / {
    return 302 /webapp/;
}
```

----------------------------------------

TITLE: Populate NGINX Upstream Groups with Servers
DESCRIPTION: This snippet demonstrates how to add individual server entries within 'upstream' blocks, specifying their hostnames or IP addresses and port numbers for both TCP ('stream_backend') and UDP ('dns_servers') services.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/tcp-udp-load-balancer.md#_snippet_6

LANGUAGE: nginx
CODE:
```
stream {

    upstream stream_backend {
        server backend1.example.com:12345;
        server backend2.example.com:12345;
        server backend3.example.com:12346;
        # ...
    }

    upstream dns_servers {
        server 192.168.136.130:53;
        server 192.168.136.131:53;
        # ...
    }

    # ...
}
```

----------------------------------------

TITLE: Complete NGINX Plus OIDC Integration with Ping Identity
DESCRIPTION: This comprehensive NGINX configuration example demonstrates a full setup for OIDC integration with Ping Identity. It includes defining an OIDC provider, configuring SSL, protecting a location with "auth_oidc", forwarding OIDC claims, and setting up a simple backend application to display authenticated user details.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/ping-identity.md#_snippet_10

LANGUAGE: nginx
CODE:
```
http {
    # Use a public DNS resolver for Issuer discovery, etc.
    resolver 10.0.0.1 ipv4=on valid=300s;

    oidc_provider ping {
        # The issuer is typically something like:
        # https://auth.pingone.com/<environment_id>/as
        issuer https://auth.pingone.com/<environment_id>/as;

        # Your Ping Identity Client ID and Secret
        client_id <client_id>;
        client_secret <client_secret>;
    }

    server {
        listen 443 ssl;
        server_name demo.example.com;

        ssl_certificate /etc/ssl/certs/fullchain.pem;
        ssl_certificate_key /etc/ssl/private/key.pem;

        location / {
            # Enforce OIDC with Ping Identity
            auth_oidc ping;

            # Forward OIDC claims as headers if desired
            proxy_set_header sub $oidc_claim_sub;
            proxy_set_header email $oidc_claim_email;
            proxy_set_header name $oidc_claim_name;

            proxy_pass http://127.0.0.1:8080;
        }
    }

    server {
        # Simple backend application for demonstration
        listen 8080;

        location / {
            return 200 "Hello, $http_name!\nEmail: $http_email\nSub: $http_sub\n";
            default_type text/plain;
        }
    }
}
```

----------------------------------------

TITLE: Configure NGINX Destination Service Port
DESCRIPTION: This YAML example demonstrates how to configure the port for an NGINX destination service across a Kubernetes Deployment, ConfigMap, and Service. It shows updating the container port, the NGINX listen port in the ConfigMap, and the Service port to ensure consistent communication.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/ratelimit-walkthrough.md#_snippet_32

LANGUAGE: yaml
CODE:
```
---
kind: Deployment
spec:
  template:
    spec:
      containers:
      - name: example
        - containerPort: 55555
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: dest-svc
data:
  nginx.conf: |-
    events {}
    http {
      server {
        listen 55555;
        location / {
          return 200 "destination service\n";
        }
      }
    }
---
kind: Service
spec:
  ports:
  - port: 55555
```

----------------------------------------

TITLE: Modify Server Parameter in NGINX Plus Upstream Group via REST API (curl)
DESCRIPTION: This `curl` command demonstrates how to modify parameters for an existing server within the `appservers` upstream group using the NGINX Plus REST API. It sends an HTTP PATCH request with a JSON payload to update specific attributes, such as setting the `down` parameter to `true` for the server with ID `0`.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/dynamic-configuration-api.md#_snippet_7

LANGUAGE: shell
CODE:
```
curl -X PATCH -d '{ "down": true }' -s 'http://127.0.0.1/api/9/http/upstreams/appservers/servers/0'
```

----------------------------------------

TITLE: NGINX: Enable and Secure API Location for Dynamic Upstream Management
DESCRIPTION: Add a `location` block for the NGINX Plus API within the `server` block to enable dynamic reconfiguration and other features. It's strongly recommended to restrict access to this API location using `allow` and `deny` directives for security.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_35

LANGUAGE: nginx
CODE:
```
# In the 'server' block for HTTPS traffic
location /api {
    api write=on;
    allow 127.0.0.1;
    deny all;
}
```

----------------------------------------

TITLE: NGINX Basic DNS Resolution for Upstream Servers
DESCRIPTION: This snippet demonstrates basic NGINX configuration for DNS resolution within the 'http' block and an upstream definition for Tomcat servers. It uses the 'resolver' directive to specify a DNS server and the 'resolve' parameter in the 'server' directive to enable dynamic DNS resolution for upstream servers.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_40

LANGUAGE: nginx
CODE:
```
# In the 'http' block
resolver <IP-address-of-DNS-server>;

upstream tomcat {
    zone tomcat 64k;
    server example.com resolve;
}
```

----------------------------------------

TITLE: Configure NGINX HTTPS Server for SSL Termination
DESCRIPTION: This configuration block demonstrates how to set up an HTTPS server in NGINX. It specifies listening on port 443 with SSL enabled, defines the server name, and points to the server certificate and private key files. It also sets strong SSL protocols and ciphers for secure communication.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/terminating-ssl-http.md#_snippet_0

LANGUAGE: nginx
CODE:
```
server {
    listen              443 ssl;
    server_name         www.example.com;
    ssl_certificate     www.example.com.crt;
    ssl_certificate_key www.example.com.key;
    ssl_protocols       TLSv1.2 TLSv1.3;
    ssl_ciphers         HIGH:!aNULL:!MD5;
    #...
}
```

----------------------------------------

TITLE: Configure NGINX Access Log Rate Limiting for DoS Protection
DESCRIPTION: This NGINX configuration snippet demonstrates how to limit the rate of access log entries during a DoS attack. It defines a custom log format, sets a `$loggable` variable within a location block, and then uses this variable with the `if=$loggable` condition in the `access_log` directive to control logging based on the variable's value.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nap-dos/monitoring/access-log.md#_snippet_2

LANGUAGE: nginx
CODE:
```
http {
    log_format security_dos 'request_time=$request_time client_ip=$remote_addr,'
                            'request="$request", status=$status,'
                            'dos_policy=$app_protect_dos_policy_name, dos_protected_object=app_protect_dos_vs_name'
                            'dos_action=$app_protect_dos_outcome, dos_action_reason=$app_protect_dos_outcome_reason';

    server {
        location / {
            set $loggable 1;
            access_log /var/log/nginx/access.log security_dos if=$loggable;;
            ...
        }
    }
}
```

----------------------------------------

TITLE: Configure NGINX Rate Limit with No Delay (nodelay)
DESCRIPTION: This YAML configuration defines an NGINX RateLimit resource named 'ratelimit-burst'. It specifies a rate limit of 1 request per second with a burst of 2, and crucially sets 'delay: nodelay' to ensure that any requests exceeding the rate limit are immediately forwarded to the destination service without queuing.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/ratelimit-walkthrough.md#_snippet_28

LANGUAGE: yaml
CODE:
```
apiVersion: specs.smi.nginx.com/v1alpha2
kind: RateLimit
metadata:
  name: ratelimit-burst
  namespace: default
spec:
  destination:
    kind: Service
    name: dest-svc
    namespace: default
  sources:
  - kind: Deployment
    name: bursty-client
    namespace: default
  name: ratelimit-burst
  rate: 1r/s
  burst: 2
  delay: nodelay
```

----------------------------------------

TITLE: Define Kubernetes Ingress for Bookinfo Application
DESCRIPTION: This YAML defines a Kubernetes Ingress resource named `bookinfo-ingress`. It configures NGINX Ingress to route traffic for `bookinfo.example.com` to the `productpage` service on port 9080, optionally using `ingressClassName` for Kubernetes v1.18.0+.
SOURCE: https://github.com/nginx/documentation/blob/main/content/mesh/tutorials/kic/ingress-walkthrough.md#_snippet_5

LANGUAGE: yaml
CODE:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: bookinfo-ingress
spec:
  ingressClassName: nginx # use only with k8s version >= 1.18.0
  tls:
  rules:
  - host: bookinfo.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: productpage
            port:
              number: 9080
```

----------------------------------------

TITLE: Configure Access Control Routing Policy via API
DESCRIPTION: This JSON snippet demonstrates how to define an access control routing policy within the 'policies' section. It specifies conditions for allowing access, such as requiring a 'token.role' of 'admin' and a 'token.sub' matching a regex, specifically for 'GET' HTTP methods. Multiple match conditions within a 'when' array are treated as an AND operation.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nms/acm/how-to/policies/access-control-routing.md#_snippet_0

LANGUAGE: json
CODE:
```
"policies": {
    "access-control-routing": [
            {
                "action": {
                    "conditions": [
                        {
                            "allowAccess": {
                                "httpMethods": ["GET"]
                            },
                            "when": [
                                {
                                    "key": "token.role",
                                    "matchType": "STRING",
                                    "matchOneOf": {
                                        "values": [
                                            "admin"
                                        ]
                                    }
                                },
                                {
                                    "key": "token.sub",
                                    "matchType": "REGEX",
                                    "matchOneOf": {
                                        "values": [
                                            "^.*test.com"
                                        ]
                                    }
                                }
                            ]
                        }
                    ]
                }
            }
        ]

```

----------------------------------------

TITLE: Complete NGINX Configuration for Geolocation-Based Server Routing
DESCRIPTION: A comprehensive NGINX configuration example demonstrating how to combine GeoIP2, map module, and upstream definitions to implement dynamic server selection based on client continent. This setup can be applied within both `http` and `stream` contexts.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/controlling-access-by-geoip.md#_snippet_15

LANGUAGE: nginx
CODE:
```
# can be either "http {}" or "stream {}"
#...
geoip2 GeoIP2/GeoLite2-Country.mmdb {
    $geoip2_data_continent_code continent code;
}

map $geoip2_data_continent_code $nearest_server {
    default all;
    EU      eu;
    NA      na;
    AS      as;
    AF      af;
}

server {
    listen 12346;
    proxy_pass http://$nearest_server;
    }

upstream all {
    server all1.example.com:12345;
    server all2.example.com:12345;
}

upstream eu {
    server eu1.example.com:12345;
    server eu2.example.com:12345;
}

upstream na {
    server na1.example.com:12345;
    server na2.example.com:12345;
}
```

----------------------------------------

TITLE: Enable NGINX Agent mTLS using CLI Flags
DESCRIPTION: This command-line snippet demonstrates how to enable mutual TLS (mTLS) for NGINX Agent by passing TLS configuration parameters directly as CLI flags. It specifies the paths for the client certificate, key, and CA certificate using "--tls-cert", "--tls-key", and "--tls-ca" respectively, and explicitly enables TLS with "--tls-enable".
SOURCE: https://github.com/nginx/documentation/blob/main/content/agent/configuration/encrypt-communication.md#_snippet_1

LANGUAGE: bash
CODE:
```
nginx-agent --tls-cert "path-to-cert" --tls-key "path-to-key" --tls-ca "path-to-ca-cert" --tls-enable
```

----------------------------------------

TITLE: Configure NGINX Upstream with IP Hash Load Balancing
DESCRIPTION: This NGINX configuration snippet demonstrates how to set up an upstream block using the `ip_hash` load-balancing method. This method ensures session persistence by distributing requests based on the client's IP address, directing all requests from the same client to the same server. It is typically placed within the 'http' block.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/node-js.md#_snippet_16

LANGUAGE: nginx
CODE:
```
upstream nodejs {
    ip_hash;
    server 192.168.33.11:8080;
    server 192.168.33.12:8080;
}
```

----------------------------------------

TITLE: Configuring NGINX stub_status Module using Bash
DESCRIPTION: This snippet provides a step-by-step guide to enable the `stub_status` module in NGINX. It involves navigating to the NGINX configuration directory, verifying include directives, creating a `stub_status.conf` file with a server block to expose metrics on `127.0.0.1:80/nginx_status`, and finally testing the NGINX configuration syntax. This configuration is crucial for the F5 NGINX Amplify Agent to collect key NGINX metrics.
SOURCE: https://github.com/nginx/documentation/blob/main/content/amplify/nginx-amplify-agent/configuring-metric-collection.md#_snippet_0

LANGUAGE: bash
CODE:
```
# cd /etc/nginx

# grep -i include\.*conf nginx.conf
    include /etc/nginx/conf.d/*.conf;

# cat > conf.d/stub_status.conf
server {
    listen 127.0.0.1:80;
    server_name 127.0.0.1;
    location /nginx_status {
        stub_status on;
        allow 127.0.0.1;
        deny all;
    }
}
<Ctrl-D>

# ls -la conf.d/stub_status.conf
-rw-r--r-- 1 root root 162 Nov  4 02:40 conf.d/stub_status.conf

# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

----------------------------------------

TITLE: Restrict NGINX Dashboard Access by IP Address
DESCRIPTION: Configures IP address-based access control lists (ACLs) in NGINX to restrict access to the live activity monitoring dashboard. Only specified IP ranges are allowed, and all others are denied.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/oracle-e-business-suite.md#_snippet_37

LANGUAGE: nginx
CODE:
```
allow 10.0.0.0/8;
deny all;
```

LANGUAGE: APIDOC
CODE:
```
allow address | CIDR | unix: | all;
deny address | CIDR | unix: | all;

Context: http, server, location, limit_except
Purpose: Restricts access to specified networks or addresses.
```

----------------------------------------

TITLE: Enable NGINX Upstream Keepalive Connections for a Service
DESCRIPTION: This snippet illustrates how to create an UpstreamSettingsPolicy to enable and configure keepalive connections for a specific service (e.g., coffee). It provides commands to apply the policy, confirm its acceptance, and verify the keepalive directive in the NGINX configuration.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-management/upstream-settings.md#_snippet_12

LANGUAGE: yaml
CODE:
```
kubectl apply -f - <<EOF
apiVersion: gateway.nginx.org/v1alpha1
kind: UpstreamSettingsPolicy
metadata:
  name: upstream-keepalives
spec:
  targetRefs:
  - group: core
    kind: Service
    name: coffee
  keepAlive:
    connections: 32
EOF
```

LANGUAGE: shell
CODE:
```
kubectl describe upstreamsettingspolicies.gateway.nginx.org upstream-keepalives
```

LANGUAGE: text
CODE:
```
Status:
  Ancestors:
    Ancestor Ref:
      Group:      gateway.networking.k8s.io
      Kind:       Gateway
      Name:       gateway
      Namespace:  default
    Conditions:
      Last Transition Time:  2025-01-07T20:06:55Z
      Message:               Policy is accepted
      Observed Generation:   1
      Reason:                Accepted
      Status:                True
      Type:                  Accepted
    Controller Name:         gateway.nginx.org/nginx-gateway-controller
Events:                      <none>
```

LANGUAGE: shell
CODE:
```
kubectl exec -it -n <NGINX-pod-namespace> $NGINX_POD_NAME -- nginx -T
```

LANGUAGE: text
CODE:
```
upstream default_coffee_80 {
    random two least_conn;
    zone default_coffee_80 1m;

    server 10.244.0.14:8080;
    keepalive 32;
}

upstream default_tea_80 {
    random two least_conn;
    zone default_tea_80 1m;

    server 10.244.0.15:8080;
}
```

----------------------------------------

TITLE: Configure NGINX SSL Termination for Instance Manager
DESCRIPTION: This NGINX configuration snippet demonstrates how to set up SSL termination for NGINX Instance Manager. It configures a server to listen on port 443 with SSL, specifies SSL protocols, ciphers, session settings, and points to the SSL certificate, key, and client certificate for verification.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nim/system-configuration/secure-traffic.md#_snippet_0

LANGUAGE: nginx
CODE:
```
# Main external HTTPS server, needs port 443
server {
    listen 443 ssl;
    http2  on;
    root   /var/www/nms;

    server_name _;

    ssl_protocols       TLSv1.1 TLSv1.2;
    ssl_ciphers         HIGH:!aNULL:!MD5;
    ssl_session_cache   shared:SSL:10m;
    ssl_session_timeout 10m;

    ssl_certificate         /etc/nms/certs/manager-server.pem;
    ssl_certificate_key     /etc/nms/certs/manager-server.key;
    ssl_client_certificate  /etc/nms/certs/ca.pem;

```

----------------------------------------

TITLE: Create Private Key for Certificate Signing Request (CSR)
DESCRIPTION: This command generates a new RSA private key that will be used to create a Certificate Signing Request (CSR). The key is saved to a .key file in your home directory.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/load-balance-third-party/apache-tomcat.md#_snippet_3

LANGUAGE: shell
CODE:
```
root# openssl genrsa -out ~/example.com.key 2048
```

----------------------------------------

TITLE: Create Kubernetes ConfigMap for CA Certificate
DESCRIPTION: This snippet shows how to create a Kubernetes ConfigMap named 'backend-cert' to store the CA certificate required for verifying self-signed certificates used by the backend application. This ConfigMap will be referenced by the BackendTLSPolicy to enable trust for the backend's TLS.
SOURCE: https://github.com/nginx/documentation/blob/main/content/ngf/traffic-security/secure-backend.md#_snippet_7

LANGUAGE: yaml
CODE:
```
kubectl apply -f - <<EOF
kind: ConfigMap
apiVersion: v1
metadata:
  name: backend-cert
data:
  ca.crt: |
    -----BEGIN CERTIFICATE-----
    MIIDbTCCAlWgAwIBAgIUPA3fFnkLl63GZ7noUjb5NoLhSYkwDQYJKoZIhvcNAQEL
    BQAwRjEfMB0GA1UEAwwWc2VjdXJlLWFwcC5leGFtcGxlLmNvbTELMAkGA1UEBhMC
    VVMxFjAUBgNVBAcMDVNhbiBGcmFuc2lzY28wHhcNMjQwMTE4MTgwMTAxWhcNMjUw
    MTA4MTgwMTAxWjBGMR8wHQYDVQQDDBZzZWN1cmUtYXBwLmV4YW1wbGUuY29tMQsw
    CQYDVQQGEwJVUzEWMBQGA1UEBwwNU2FuIEZyYW5zaXNjbzCCASIwDQYJKoZIhvcN
    AQEBBQADggEPADCCAQoCggEBAJGgn81BrqzmI4aQmGrg7RgkO5oYwlThQ9X/xVHB
    YVFptjRPAZz9g92g5birI/NZ43C6nEbZrJrSCqN3wgvV84jJmBAgpAvW+LhF4caa
    nhAnecJCcTbwrd542vCDoDRsNV5ffbpESgC4FxPGkRVbSa0KHQz8qCLqS2+uaB7X
    t76iw6y4pQ3klobVp1XtUpzZMGMBqZFnsAdl+PWMmSTvqjixkSlfcUY6Crnk9W6d
    Sns5cpzKdUs+2ZkBe6VkBgSs8xbaz8Y2YC1GhRqGlxYLT3WBaIlSCKPuRrGjwE3r
    AsW6gSL919H1O1a+MjQuLuQ4lnCbCpNzM9OV1JISMWfwifMCAwAQAaNTMFEwHQYD
    VR0OBBYEFOEzjs7FrQr1bW3mKkUgI+5Fo9XaMB8GA1UdIwQYMBaAFOEzjs7FrQr1
    bW3mKkUgI+5Fo9XaMA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEB
    AG/eX4pctINIrHvRyHOusdac5iXSJbQRZgWvP1F2p95qoIDESciAU1Sh1oJv+As5
    IlJOZPJNuZFpDLjc8kzSoEbc1Q5+QyTBlyNNsagWYYwK0CEJ6KJt80vytffmdOIg
    z8/a+2Ax829vcn1w1SUi5V6ea/l8K74f2SL/zSSHgtEiz8V0TlvT7J6wurgmnk4t
    yQRmsXlDGefuijMNCVf7jWwLx2BODfKoEA1pJkthnNvdizlikmz+9elxhV9bRf3Y
    NnubytWPfO1oeHjVGvxVjCouIYine+VlskvwHmMi/dYod6yd7aFYu4CU3g/hjwKo
    LY2WNv5j3JhDnEYK9Zj3z7A=
    -----END CERTIFICATE-----
EOF
```

----------------------------------------

TITLE: Specifying Trusted Proxies with set_real_ip_from
DESCRIPTION: This NGINX configuration snippet shows how to use the 'set_real_ip_from' directive to specify the IP address or CIDR range of your trusted TCP proxy or load balancer. This tells NGINX which addresses to expect PROXY protocol headers from, ensuring the correct client IP is identified.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/load-balancer/using-proxy-protocol.md#_snippet_2

LANGUAGE: nginx
CODE:
```
server {
       #...
       set_real_ip_from 192.168.1.0/24;
      #...
   }
```

----------------------------------------

TITLE: NGINX SSL/TLS Reverse Proxy with Upstream Load Balancing and Client Authentication
DESCRIPTION: This NGINX configuration demonstrates setting up a reverse proxy with SSL/TLS for secure communication to upstream backend servers. It includes directives for client certificate authentication, SSL/TLS protocol and cipher selection, certificate verification, and session reuse for faster connection establishment. It also shows how to configure backend servers for client certificate verification.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/admin-guide/security-controls/securing-http-traffic-upstream.md#_snippet_7

LANGUAGE: nginx
CODE:
```
http {
    #...
    upstream backend.example.com {
        server backend1.example.com:443;
        server backend2.example.com:443;
   }

    server {
        listen      80;
        server_name www.example.com;
        #...

        location /upstream {
            proxy_pass                    https://backend.example.com;
            proxy_ssl_certificate         /etc/nginx/client.pem;
            proxy_ssl_certificate_key     /etc/nginx/client.key;
            proxy_ssl_protocols           TLSv1.2 TLSv1.3;
            proxy_ssl_ciphers             HIGH:!aNULL:!MD5;
            proxy_ssl_trusted_certificate /etc/nginx/trusted_ca_cert.crt;

            proxy_ssl_verify        on;
            proxy_ssl_verify_depth  2;
            proxy_ssl_session_reuse on;
        }
    }

    server {
        listen      443 ssl;
        server_name backend1.example.com;

        ssl_certificate        /etc/ssl/certs/server.crt;
        ssl_certificate_key    /etc/ssl/certs/server.key;
        ssl_client_certificate /etc/ssl/certs/ca.crt;
        ssl_verify_client      optional;

        location /yourapp {
            proxy_pass https://url_to_app.com;
        #...
        }

    server {
        listen      443 ssl;
        server_name backend2.example.com;

        ssl_certificate        /etc/ssl/certs/server.crt;
        ssl_certificate_key    /etc/ssl/certs/server.key;
        ssl_client_certificate /etc/ssl/certs/ca.crt;
        ssl_verify_client      optional;

        location /yourapp {
            proxy_pass https://url_to_app.com;
        #...
        }
    }
}
```

----------------------------------------

TITLE: Protect NGINX Location with AD FS OIDC
DESCRIPTION: This NGINX configuration snippet demonstrates how to protect a specific location using the `auth_oidc` directive, pointing to a pre-configured AD FS OIDC provider. It ensures that requests to this location are authenticated via AD FS before being proxied.
SOURCE: https://github.com/nginx/documentation/blob/main/content/nginx/deployment-guides/single-sign-on/active-directory-federation-services.md#_snippet_6

LANGUAGE: nginx
CODE:
```
# ...
location / {

         auth_oidc adfs;

         # ...

         proxy_pass http://127.0.0.1:8080;

}
```